[ { "title": "Kafka - 인덱스", "url": "/posts/Kafka_Index/", "categories": "Study", "tags": "Kafka, Index, Page_Cache", "date": "2023-12-19 00:00:00 +0900", "snippet": "여기서 이야기하고자 하는 인덱스란, 카프카의 OffsetIndex, TimeIndex이다.해당 인덱스들은 모두 파일로 관리되는데, 카프카의 로그 파일(baseoffset.log) 마다 한 벌씩 생성된다.각각의 파일은 baseoffset.index, baseoffset.timeindex이다. 위의 baseoffset은 10자리의 숫자로 구성되며, 각 로그 파일의 시작 레코드 offset이다.카프카의 로그 파일이 커지면 특정 레코드를 찾기 위해 로그 파일 전체를 뒤져야 하는데, 이는 효율이 떨어진다.한 로그 파일 안에서 특정 레코드를 효율적으로 찾기 위해서 사용하는 방법이 인덱스다.각 인덱스의 용도는 다음과 같다. OffsetIndex는 레코드의 Offset으로 로그 파일의 Position 찾기 TimeIndex는 레코드의 Timestamp로 레코드의 Offset 찾기다음 그림을 보면 각 인덱스와 로그 파일의 대략적인 관계를 알수 있다.(출처: https://strimzi.io/blog/2021/12/17/kafka-segment-retention)그림과 같이 인덱스를 통해서 timestamp나 레코드 offset을 기준으로 로그 파일의 position을 찾을 수 있다.단, 인덱스 파일은 모든 레코드의 인덱스를 포함하진 않고 카프카 설정값(index.interval.bytes)을 기준으로 최소 간격을 유지하며 인덱스를 생성한다.그래서 인덱스를 통해 찾은 position 위치 부터 로그 파일에서 찾고자 하는 Offset의 레코드를 찾는다.인덱스와 캐시카프카 인덱스는 기본적으로 이진탐색 알고리즘을 사용한다.하지만 일반적인 이진탐색 알고리즘은 캐시에 적합하지 않다.여기서 캐시는 OS의 페이지 캐시이다.페이지 캐시와 카프카 인덱스의 특징 몇 가지만 간단히 보자. 카프카 인덱스 접근 패턴 대부분 인덱스의 마지막에서 발생 추가는 카프카는 인덱스의 끝에서 발생 검색은 대부분 카프카의 인덱스 끝 부분에서 발생 오래된 로그를 소비할 수 있지만, 시간이 지나면 최신 로그를 소비하게 됨 카프카 인덱스는 파일 Memory Mapped Files로 메모리에 사상 OS 페이지 캐시 대상 OS의 페이지 캐시 LRU 형태의 교체 알고리즘 사용 카프카 인덱스 접근 패턴은 LRU 교체 알고리즘과 잘 맞는다.하지만 이진탐색 알고리즘은 오래된 인덱스도 조회하게 되어 문제가 발생한다.하지만 카프카 인덱스는 이진탐색 알고리즘을 사용해 페이지 캐시 히트율을 높게 유지하며 검색을 지원한다.Warm Section캐시에 적합한 검색의 핵심은 Warm Section이다.Warm Section은 자주 조회해서 해당 부분의 페이지가 페이지 캐시에 최대한 존재하도록 한 부분이다. 마지막 N개의 Index Entry를 의미 OS 페이지 캐시에 최대한 올라가 있도록 유도된 구간 크기는 8192 Byte로 고정 Index Entry 개수 : 8192 / ENTRY_SIZE Entry Size : 8 Byte(OffsetIndex)와 12 Byte(TimeIndex) index.interval.bytes 설정값이 커버하는 로그 범위에 영향 최소 해당 설정값 간격으로 Index Entry 생성 기본값은 4096로 4 KB 기본값일 때, 각 인덱스의 대략적인 로그 파일 커버 범위 OffsetIndex : 4 MB TimeIndex : 2.7 MB 검색카프카는 Warm Section인 부분과 아닌 부분을 나누어 이진탐색을 수행한다.int firstHotEntry = Math.max(0, entries - 1 - warmEntries()); // warm section 조회 if (compareIndexEntry(parseEntry(idx, firstHotEntry), target, searchEntity) &amp;lt; 0) { return binarySearch(..., firstHotEntry, entries - 1); } ... // 그 외 조회 return binarySearch(..., 0, firstHotEntry); Warm Section 조회 시, indexEntry(end), indexEntry(end-N), indexEntry((end*2 -N)/2)의 페이지 조회 parseEntry(idx, entry) 코드가 파일을 메모리로 사상한 영역을 접근하여 페이지 히트 indexEntry(end-N)은 Warm Section 구분을 위해 매번 조회 indexEntry((end*2 -N)/2)은 이진탐색 시작 시 매번 접근 indexEntry(end)은 인덱스 추가 및 탐색 시 접근 대부분의 Processor의 최소 페이지 크기는 4096 byte(2018년도 기준이라 함) Warm Section은 고정 8192 Byte 크기 Warm Section 범위의 Page는 3개 이하 Warm Section 조회 시, 모든 Warm Section 구간이 페이지 케시에 올라오도록 유도됨 binarySearch는 기본적인 이진탐색 구현결론카프카의 인덱스 검색 연산은 Warm Section과 아닌 Section을 나누어서 이진탐색을 수행한다.모든 삽입연산은 인덱스의 끝 부분에서 발생하고, 대부분의 검색은 Warm Section에서 발생하게 된다.결과적으로 카프카 인덱스 파일 영역을 Memory Mapped Files를 통해서 접근하고, 8192 byte의 Warm Section으로 구분해 해당 Section이 OS 페이지 캐시를 최대한 활용하도록 설계되었다.참고 자료 카프카 코드 https://strimzi.io/blog/2021/12/17/kafka-segment-retention" }, { "title": "DDIA - 파티셔닝", "url": "/posts/DDIA-CH6/", "categories": "Study, Book", "tags": "Data, Applicationn, System", "date": "2022-06-10 00:00:00 +0900", "snippet": "Table of Contents 파티셔닝과 복제 Key-Value 데이터 파티셔닝 키 범위 기준 파티셔닝 키의 해시값 기준 파티셔닝 참고 쏠린 작업부하와 핫스팟 완화 파티셔닝과 보조 색인 문서 기준 보조 색인 파티셔닝 용어 기준 보조 색인 파티셔닝 파티션 재균형화 재균형화 전략 쓰면 안 되는 방법: hash mod N 파티션 개수 고정 동적 파티셔닝 노드 비례 파티셔닝 운영: 자동 재균형화와 수동 재균형화 요청 라우팅 병렬 질의 실행 데이터셋이 매우 크거나 질의 처리량이 매우 높다면 복제만으로는 부족하다.데이터를 파티셔닝으로 나눌 필요가 있다.파티셔닝은 샤딩이라고도 한다.파티셔닝을 하는 주요한 이유는 확장성 이다.비공유 클러스터(shared-nothing cluster)에서 파티션들은 서로 다른 노드에 저장될 수 있다.그래서 대용량 데이터셋은 여러 디스크로 분산될 수 있고 질의 부하도 여러 프로세서로 분산될 수 있다.각 노드는 자신의 파티션 질의를 독립적으로 실행할 수 있기에 노드를 추가하는 것만으로 질의 처리량을 확장할 수 있다.크고 복잡한 질의는 여러 노드에서 병렬로 실행도 가능하다.하지만 이런 크고 복잡한 질의는 더욱 복잡하고 어려워진다.파티셔닝과 복제일반적으로 파티셔닝과 복제를 함께 사용한다.복제를 통해서 각 파티션의 복사본을 여러 노드에 저장하게 되고 내결함성 을 보장할 수 있다.복제에 관한 모든 내용은 파티션의 복제에도 동일하게 적용된다.복제와 파티셔닝의 조합에 대한 예를 살펴보자.예제와 같이 한 노드에 여러 파티션을 저장할 수도 있다.또한 각 노드는 어떤 파티션에게는 리더이면서 다른 파티션에게는 팔로워가 될 수 있다.Key-Value 데이터 파티셔닝파티셔닝의 목적 : 데이터와 질의 부하를 노드 사이에 고르게 분산시키는 것용어 설명 쏠림(skewed)파티셔닝으로 여러 노드 사이에 데이터가 고르게 나눠지지 않는다면데이터가 많거나 질의를 많이 받는 파티션이 생기게 되는데 이때 쏠렸다고 말한다. 핫스팟(hot spot)불균형하게 다른 파티션보다 부하가 높은 파티션데이터베이스에서 파티셔닝을 사용했을 때, 실제 데이터를 어떤 노드에 저장할지에 대해 알아보자.키 범위 기준 파티셔닝각 파티션에 연속된 범위의 키를 할당하는 것이다.특징 키 범위 크기가 반드시 동일할 필요가 없음 데이터를 고르게 분산시키려면 파티션 경계를 데이터에 맞춰 조정해야 함 파티션 경계는 수동 혹은 자동으로 선택 가능 각 파티션 내에서는 정렬된 순서로 키를 저장할 수 있음장점 어떤 키가 어느 파티션에 속하는지 쉽게 찾을 수 있음 적절한 노드로 요청을 직접 보낼 수 있음 4번 특징으로 범위 스캔이 쉬움 키를 결합 색인(concatenated index)로 간주해서 질의 하나로 관련 레코드 여러 개를 읽어올 수 있음단점 특정한 접근 패턴이 핫스팟을 유발키의 해시값 기준 파티셔닝쏠림과 핫스팟의 위험 때문에 많은 분산 데이터스토어는 키의 파티션을 정하는 데 해시 함수를 사용한다.각 파티션에 해시값 범위를 할당한다.해시 함수를 통해 키를 해시 값을 구하고 해당 해시 값이 파티션의 범위에 속하면 해당 파티션에 할당하면 된다.파티션용 해시 함수의 특징 좋은 해시 함수는 쏠린 데이터를 받아 균일하게 분산되도록 할 수 있음 암호적으로 강력할 필요가 없음장점 키를 파티션 사이에 균일하게 분산시키는 데 좋음 파티션 경계를 크기가 동일하도록 나눌 수도 있고 무작위에 가깝게 선택할 수도 있음단점 범위 질의가 효율적이지 않음범위 질의를 효율적으로 하기 위해 카산드라는 키 범위 기준과 키의 해시값 기준 두 가지 파티셔닝 전략 사이에서 타협한다.테이블을 선언할 때 여러 컬럼을 포함하는 복합 기본키를 지정할 수 있다. 키의 첫 부분에만 해싱을 적용하고 파티션 결정에 사용 나머지 컬럼은 카산드라의 SS테이블에서 데이터를 정렬하는 결합 색인으로 사용연쇄된 색인을 사용하면 일대다 관계를 표현하는 우아한 데이터 모델을 만들 수 있다.참고이런 기법을 일관성 해싱이라고 부르기도 한다.일관성 해싱은 CDN 같은 인터넷 규모의 캐시 시스템에서 부하를 균등하게 분산시키는 방법이다.중앙 제어나 분산 합의가 필요하지 않도록 파티션 경계를 무작위로 선택한다.카산드라의 파티셔닝 기법이 일관성 해싱의 원래 정의에 가장 가깝게 대응한다.쏠린 작업부하와 핫스팟 완화키의 해시값 기준 파티셔닝을 사용하면 핫스팟을 줄이는 데 도움이 된다.하지만 핫스팟을 완벽히 제거할 수는 없다.항상 동일한 키를 읽고 쓰는 극단적인 상황에서는 모든 요청이 동일한 파티션으로 쏠리게 된다.현대 데이터 시스템은 대부분 크게 쏠린 작업부하를 자동으로 보정하지 못한다.그래서 애플리케이션에서 쏠림을 완화해야 한다.예로 간단한 해결책은 각 키의 시작이나 끝에 임의의 숫자를 붙이는 것이다.시작에 2개의 숫자를 붙인다면 “[0-9][0-9]키 -&amp;gt; 해시 함수 적용” 와 같다. 같은 키라도 100개의 다른 키로 균등하게 나뉘어지며 다른 파티션으로 분산될 수 있음 다른 키에 쪼개서 쓰면 읽기를 실행할 때 추가적인 작업이 필요100개의 키에 해당 하는 데이터를 읽어서 조합해야 하기 때문 추가적으로 저장해야 할 정보도 있다. 요청이 몰리는 소수의 키에만 적용하는 게 좋음쓰기 처리량이 낮은 대다수의 키에도 적용하면 불필요한 오버헤드가 발생 어떤 키가 쪼개졌는지 추적할 방법 필요파티셔닝과 보조 색인보조 색인은 보통 레코드를 유일하게 식별하는 용도가 아니라 특정한 값이 발생한 항목을 검색하는 수단이다.많은 키-값 저장소에서는 구현 복잡도가 추가되는 것을 피하기 위해 파티션에서 보조 색인을 지원하지 않는다.하지만 보조 색인은 데이터 모델링에 매우 유용하며, 솔라나 엘라스틱서치 같은 검색 서버에게는 존재 이유이기도 하다.보조 색인은 파티션에 깔끔하게 대응되지 않는 문제점이 있다.이제 파티셔닝에서 보조 색인을 사용하는 대표적인 2가지 방법에 대해 살펴보자.문서 기준 보조 색인 파티셔닝보조 색인을 살펴보기 위해 중고차를 판매하는 웹사이트를 운영한다고 가정하고 예제를 살펴보자.각 항목에는 문서 ID(document ID)라 불리는 고유 ID가 있고 데이터베이스를 *문서 ID 기준(키 범위 기준 파티셔닝)으로 파티셔닝한다.각 파티션은 완전히 독립적으로 동작하며 보조 색인은 자신이 속한 파티션의 문서만 담당한다.그래서 문서 기준 보조 색인 파티셔닝은 지역 색인(local index)라고도 한다.특징 보조색인을 통해 질의하고 싶다면, 모든 파티션으로 질의를 해야 함그리고 얻은 결과를 모두 합쳐야 한다.이런 방법을 스캐터/개더(scatter/gather)라고 한다. 질의를 병렬 실행 가능 보조색인을 사용한 읽기 질의는 큰 비용이 들 수 있음병렬 실행을 하더라도 꼬리 지연 시간 증폭이 발생하기 쉬움용어 기준 보조 색인 파티셔닝용어란 문서에 등장하는 모든 단어를 말한다.용어라는 이름은 전문 색인에서 나왔다.위의 그림을 보면 color와 make란 속성의 black, red, silver, yellow, audi 등 용어가 존재한다.또한 파티션 별로 용어는 겹치지 않고 각 파티션에 고유한 용어가 할당되어 있다.즉, 용어 기준으로 파티셔닝 됐다고 한다.각 보조 색인들은 해당 파티션의 문서 ID 뿐만 아니라 다른 파티션의 문서 ID도 포함한다.그래서 전역 색인 이라고 부른다.여기서 색인을 파티셔닝할 때, 키-값 데이터 파티셔닝과 동일하게 파티셔닝할 수 있다.여기서는 키가 용어라고 생각하면 된다. 키(용어) 범위 기준 파티셔닝 키(용어)의 해시값 기준 파티셔닝위의 단어는 키-값 데이터 파티셔닝의 방식과 쉽게 매칭하기 위해 단어를 그대로 사용했다.실제 단어는 아닐 수 있다.특징 문서 기준 보조색인 파티셔닝 대비 읽기가 효율적스캐터/개더를 실행할 필요 없이 대상 파티션에 요청 가능 쓰기가 느리고 복잡하다단일 문서를 쓸 때 여러 파티션에 영향을 줄 수 있음이상적으로는 색인은 항상 최신 상태를 유지해야 한다.이를 위해서는 용어 파티셔닝 색인을 사용할 때 쓰기에 영향 받는 모든 파티션에 걸친 분산 트랜잭션을 실행해야 한다.하지만 모든 데이터베이스에서 분산 트랙잭션을 지원하지 않는다.현실에서는 전역 보조 색인은 대개 비동기로 갱신된다.이로 인해서 쓰기를 수행 후 바로 색인이 반영되지 않을 수도 있다.파티션 재균형화시간이 지나면 데이터베이스에 변화가 생긴다. 질의 처리량이 증가해 CPU를 추가하고 싶다. 데이터셋 크기가 증가해 디스크와 램을 추가하고 싶다. 장비에 장애가 발생해 역활을 다른 장비로 옮기고 싶다.이런 변화가 생기면 데이터와 요청이 한 노드에서 다른 노드로 옮겨져야 한다.클러스터에서 한 노드가 담당하던 부하를 다른 노드로 옮기는 과정을 재균형화(rebalancing) 라고 한다.재균형화가 실행될 때 보통 만족시킬 것으로 기대하는 최소 요구사항 재균형화 후, 부하가 클러스터 내에 있는 노드들 사이에 균등하게 분배돼야 한다. 재균형화 중, 읽기 쓰기 요청을 받을 수 있어야 한다. 재균형화가 빨리 완료되고 네트워크와 디스크 I/O 부하를 최소화할 수 있도록노드 사이에 데이터가 필요 이상으로 옮겨서는 안 된다.재균형화 전략쓰면 안 되는 방법: hash mod N모드 N 방식의 문제는 노드 개수 N이 바뀌면 대부분의 키가 노드 사이에 옮겨져야 한다는 점이다.키가 자주 이동하면 재균형화 비용이 지나치게 커진다.데이터를 필요 이상으로 이동하지 않는 방법이 필요 하다.파티션 개수 고정상당히 간단한 해결책으로 파티션을 노드 대수보다 많이 만들고 각 노드에 여러 파티션을 할당하는 것이다.클러스터에 새로운 노드가 추가된 경우, 신규 노드는 파티션이 다시 균일하게 분배가 될 때까지 기존의 노드에서 파티션 몇 개를 가져올 수 있다.클러스터에서 노드가 제거된 경우, 이 과정을 반대로 수행하면 된다.클러스터에 새로운 노드가 추가된 경우의 과정은 아래 그림을 참고하자특징 노드 사이에서 파티션은 통째로 이동 시키며, 파티션의 개수와 파티션에 할당된 키도 변경되지 않음유일한 변화는 노드에 어떤 파티션이 할당되는가 뿐이다. 보통 데이터베이스가 처음 구축될 때 파티션 개수가 고정되고 이후에 변하지 않음전체 데이터셋의 크기 변동이 심하다면 적절한 파티션 개수를 정하기 어렵다.파티션이 너무 크면 재균형화를 실행할 때와 노드 장애로부터 복구할 때 비용이 커진다.하지만 파티션이 너무 작으면 오버헤드가 너무 커진다.동적 파티셔닝파티션 경계와 개수가 고정돼 있는 게 매우 불편할 수 있다.처음에 절적한 파티션 개수를 정하기 어려운데, 잘 못 지정할 경우 쏠림 현상이 발생할 수 있다.또한 파티션 경계를 수동으로 재설정하는 것은 매우 성가시다.이런 이유로 동적 파티셔닝을 지원하는 데이터베이스들이 있다.(HBase, 리싱크DB 등)동적 파티셔닝은 설정 값을 기준으로 동적으로 파티션을 나누거나 합친다. 파티션 크기가 설정된 값을 넘어서면파티션을 두 개로 나누고 대략 반의 데이터를 각각 나눠 가진다. 데이터가 많이 삭되어 임계값 아래로 떨어지면인접한 파티션과 합쳐질 수 있다.특징 큰 파티션이 쪼개진 후 부하의 균형을 맞추기 위해 분할된 파티션 중 하나가 다른 노드로 이동될 수 있다. 파티션 개수가 전체 데이터 용량에 맞춰 조정(장점)데이터 양이 적으면 파티션 개수가 적어 오버헤드도 적다 키 범위 파티셔닝과 해시 파티셔닝 모두 사용 가능문제점으로 시작할 때는 파티션이 하나라는 점이다.이 문제를 완화하기 위해 HBase와 몽고DB는 빈 데이터베이스에 초기 파티션 집합을 설정할 수 있게 한다.이것을 사전 분할(pre-splitting)이라 한다.노드 비례 파티셔닝고정 파티셔닝과 동적 파티셔닝 모두 파티션 개수는 노드 대수와 독립적이다.반면 해당 방법은 노드 대수에 비례하게 하는 것이다.즉, 노드당 할당되는 파티션 개수를 고정한다.노드의 수가 변함 없는 동안은 개별 파티션 크기가 데이터셋 크기에 비례해서 증가한다.노드 수를 늘리면 파티션 크기는 다시 작아진다.일반적으로 데이터 용량이 클수록 데이터를 저장하는 노드도 많이 필요하므로 이 방법을 쓰면 개별 파티션 크기도 상당히 안정적으로 유지된다.새 노드가 클러스터에 추가되면 고정된 개수의 파티션을 무작위로 선택해 분할하고각 분할된 파티션의 절반은 그대로 두고 다른 절반은 새 노드에 할당한다. 파티션을 무작위로 선택해서 균등하지 않은 분할이 생길 수 있다.카산드라 3.0에는 대안적인 재균형화 알고리즘이 추가됨파티션 경계를 무작위로 선택하려면 해시 기반 파티셔닝을 사용해야 한다.운영: 자동 재균형화와 수동 재균형화완전 자동 재균형화는 손이 덜 들어 편리하지만 예측하기 어렵다.재균형화는 요청 경로를 재설정해야 하고 대량의 데이터를 노드 사이에 이동해야 해서 비용이 큰 연산이다.즉, 재균형화 중에는 다른 요청의 성능이 저하될 수 있다.이런 자동화는 자동 장애 감지와 조합되면 위험해질 수도 있다.그래서 재균형화 과정에 사람이 개입하는 게 좋을 수도 있다.요청 라우팅파티션에는 클라이언트는 어느 노드로 접속해야 하는지 알아야 하는 문제가 있다.또한 재균형화 후에는 노드에 할당되는 파티션이 바뀐다.이 문제는 데이터베이스에 국한되지 않은 더욱 일반적인 문제인 서비스 찾기(service discovery) 의 일종이다.상위 수준에서 보면 이 문제는 몇 가지 다른 접근법이 있다. 클라이언트가 아무 노드에 접속해당 노드에 마침 요청 대상 파티션이 있다면 요청을 직접 처리그렇지 않다면 요청을 올바른 노드로 전달해서 응답을 받고 클라이언트에게 응답을 전달 클라이언트가 모든 요청을 라우팅 계층으로 먼저 전달라우팅 계층에서 각 요청을 처리할 노드를 알아내서 해당 노드로 요청을 전달 클라이언트가 파티셔닝 방법과 파티션이 어떤 노드에 할당됐는지 알고 있게 한다.바로 대상 노드로 접속모든 경우에 핵심 문제는 라우팅 결정을 내리는 구성요소가 노드에 할당된 파티션의 변경 사항을 어떻게 아느냐다.많은 분산 데이터 시스템은 클러스터 메타데이터를 추적하기 위해 주키퍼 같은 별도의 코디네이션 서비스를 사용한다.각 노드는 주키퍼에 자신을 등록하고 주키퍼는 파티션과 노드 사이의 신뢰성 있는 할당 정보를 관리한다.라우팅 계층이나 파티션 인지 클라이언트 같은 다른 구성요소들은 주키퍼에 있는 정보를 구독할 수 있다.실제 사용 사례들 라우팅 계층 + 외부 코디네이션 서비스(2번)링크드인의 에스프레소는 헬릭스(Helix)를 사용해서 클러스터를 관리하며 위의 그림의 라우팅 계층을 구현한다.헬릭스는 다시 주키퍼에 의존한다.몽고 DB도 아키텍처는 비슷하지만 자체적인 설정 서버 구현에 의존하고 몽고스(mongos) 데몬을 라우팅 계층으로 사용한다. 노드가 라우팅 정보 관리(1번)가십 프로토콜(gossip protocol)을 사용해서 클러스터 상태 변화를 노드 사이에 퍼뜨린다.(카산드라와 리악이 사용하는 방식)아무 노드나 요청을 받을 수 있고 요청을 받은 노드는 요청을 처리할 파티션을 가진 올바른 노드로 요청을 전달한다.데이터베이스 노드에 복잡성을 더하지만 외부 코디네이션 서비스에 의존하지 않는다. 라우팅 계층(2번)카우치베이스에서는 보통 클러스터 노드로부터 변경된 라우팅 정보를 알아내는 목시(moxi)라는 라우팅 계층을 사용한다. 클라이언트는 라우팅 계층을 사용하거나 임의의 노드로 요청을 보낼 때도 접속할 IP 주소를 알아내야 한다.IP 주소는 노드에 할당된 파티션 정보만큼 자주 바뀌지 않으므로 보통은 DNS로 충분하다.병렬 질의 실행지금까지는 단일 키를 읽거나 쓰는 매우 간단한 질의에 대해서만 설명했다.그러나 분석용으로 자주 사용되는 대규모 병렬 처리(massively parallel processing, MPP) 관계형 데이터베이스 제품은 훨씬 복잡한 종류의 질의를 지원한다.전형적인 데이터 웨어하우스 질의는 조인(join), 필터링(filtering), 그룹화(grouping), 집계(aggregation) 연산을 몇 개 포함한다.MPP 질의 최적화기는 복잡한 질의를 여러 실행 단계와 파티션으로 분해하며 이들 중 다수는 데이터베이스 클러스터 내의 서로 다른 노드에서 병렬적으로 실행될 수 있다.데이터셋의 많은 부분을 스캔하는 연산을 포함하는 질의는 특히 병렬 실행의 혜택을 받는다." }, { "title": "DDIA - 복제_다중 리더와 리더 없음", "url": "/posts/DDIA-CH5-2/", "categories": "Study, Book", "tags": "Data, Applicationn, System", "date": "2022-06-03 00:00:00 +0900", "snippet": "Table of Contents 다중 리더 복제 다중 리더 복제의 사용 사례 다중 데이터센터 운영 오프라인 작업을 하는 클라이언트 쓰기 충돌 다루기 동기 대 비동기 충돌 감지 충돌 회피 일관된 상태 수렴 사용자 정의 충돌 해소 로직 자동 충돌 해소 다중 리더 복제 토폴리지 리더 없는 복제 노드가 다운됐을 때 데이터베이스에 쓰기 읽기 복구와 안티 엔트로피 읽기와 쓰기를 위한 정족수 정족수 일관성의 한계 최신성 모니터링 느슨한 정족수와 암시된 핸드오프 다중 데이터센터 운영 동시 쓰기 감지 최종 쓰기 승리(동시 쓰기 버리기) “이전 발생” 관계와 동시성 이전 발생 관계 파악하기 동시에 쓴 값 병합 버전 벡터 다중 리더 복제리더 기반 복제의 주요한 단점은 리더가 하나만 존재하고 모든 쓰기는 해당 리더를 거쳐야 한다는 것이다.그래서 리더 기반 복제 모델은 쓰기를 허용하는 노드(리더)를 하나 이상 두는 것으로 자연스럽게 확장된다.이 방식을 다중 리더 (마스터 마스터, 액티브/액티브 복제) 설정이라 부른다.이 설정에서 각 리더는 동시에 다른 리더의 팔로워 역활도 한다.다중 리더 복제의 사용 사례단일 데이터센터 내에 다중 리더 설정은 복잡도에 비해 이점이 크지 않기에 적절하지 않다.하지만 몇 가지 상황에서는 합리적인데 관련해서 알아보자.다중 데이터센터 운영다중 리더 설정은 각 데이터센터마다 리더가 있을 수 있다.각 데이터센터 내에는 보통의 리더 팔로워 복제 를 사용한다.데이터센터 간에는 각 데이터센터의 리더가 다른 데이터센터의 리더에게 변경 사항을 복제한다.간략화한 구성도는 아래와 같다.단일 리더 설정 VS 다중 리더 설정 (다중 데이터 센터에서) 성능 단일 리더모든 쓰기는 클라이언트에서 인터넷을 통해 리더가 있는 데이터센터로 이동지연 시간 증가의 원인 다중 리더모든 쓰기는 로컬 데이터센터에서 처리 -&amp;gt; 비동기 방식으로 다른 데이터센터로 복제사용자가 인지하는 성능이 더 좋을 수 있다. 데이터센터 중단 내성 단일 리더리더의 데이터센터가 고장 나면 장애 복구를 위해 다른 데이터센터에서 한 팔로워를 리더로 승진 다중 리더각 데이터센터는 서로 독립적으로 동작고장 난 데이터센터가 온라인으로 돌아왔을 때 복제를 따라잡는다. 네트워크 문제 내성 단일 리더데이터센터 간 연결의 쓰기는 동기식이기에 데이터센터 간 연결 문제에 매우 민감 다중 리더데이터센터 간 연결의 쓰기를 비동기식을 사용하기에 네트워크 문제에 보다 잘 견딤.일시적인 네트워크 중단에도 쓰기 처리는 진행되기 때문 다중 리더 복제의 큰 단점 쓰기 충돌이 발생할 수 있고, 반드시 해소해야 한다.다중 리더 복제는 설정상의 실수나 다른 데이터베이스 기능과의 뜻밖의 상호작용이 있다.예를 들어 자동 증가 키, 트리거, 무결성 제약은 문제가 될 소지가 많다.이런 이유로 다중 리더 복제는 가능하면 피해야 하는 위험한 영역으로 간주되곤 한다.오프라인 작업을 하는 클라이언트다중 리더 복제가 적절한 또 다른 상황은 인터넷 연결이 끊어진 동안 애플리케이션이 계속 동작해야 하는 경우이다.이 경우 모든 디바이스(클라이언트)에는 리더처럼 동작하는 로컬 데이터베이스가 있다.특징 모든 디바이스 상에서 복제 서버 간 다중 리더 복제를 비동기 방식으로 수행하는 프로세스가 존재 복제 지연은 사용자가 인터넷이 가능해진 시점에 따라 몇 시간에서 몇일 이상 소요아키텍처 관점에서 이 설정은 근본적으로 데이터센터 간 다중 리더 복제와 동일하다.쓰기 충돌 다루기다중 리더 복제에서 제일 큰 문제는 쓰기 충돌이 발생한다는 점이다.쓰기 충돌에 대한 간단한 예제를 아래 그림으로 확인하자.동기 대 비동기 충돌 감지다중 리더 설정은 복제를 비동기식으로 동작한다고 했다.비동기 충돌 감지 동시에 발생한 쓰기는 모두 성공 충돌은 이후 특정 시점에서 비동기로만 감지 이 시점에 사용자에게 충돌 해소 요청은 너무 늦을 수도 있다.동기 충돌 감지 이론적으로 가능 다중 리더 복제의 주요 장점을 상실각 복제 서버가 독립적으로 쓰기를 허용 단일 리더 복제를 사용하는 편이 좋음다중 리더 복제의 주요 장점을 상실하기 때문충돌 회피충돌을 처리하는 제일 간단한 전략특정 레코드의 모든 쓰기가 동일한 리더를 거치도록 애플리케이션이 보장한다면 충돌은 발생하지 않는다란 개념이다.한 가지 예특정 사용자의 요청을 동일한 데이터센터로 항상 라우팅한다.그래서 해당 데이터센터 내 리더를 사용해 읽기와 쓰기를 하게끔 보장하는 것이다.한 사용자 관점에서 보면 구성은 기본적으로 단일 리더이다.하지만 여러가지 이유(특정 데이터센터 장애 등)로 지정된 리더를 변경하고 싶을 수도 있다.이런 상황에서 충돌 회피가 실패한다.그러면 다른 리더에서 동시 기록 가능성을 대처 해야 한다.일관된 상태 수렴다중 리더 설정에서는 쓰기 순서가 정해지지 않아 최종 값이 무엇인지 명확 하지 않다.어떤 순서도 다른 순서보다 “더 정확”하지 않다.이런 순서와 관련된 내용은 &quot;이전 발생&quot; 관계와 동시성 에서 살펴본다.단순하게 각 복제 서버가 쓰기를 본 순서대로 적용한다면 데이터베이스는 결국 일관성 없는 상태가 된다.모든 복제 계획은 모든 복제 서버가 최종적으로 동일하다는 사실을 보장해야 한다.따라서 데이터베이스는 수렴 (convergent) 방식으로 충돌을 해소해야 한다.수렴 방식 : 모든 변경이 복제돼 모든 서버에 동일한 최종 값이 전달되게 해야 한다수렴 충돌 해소를 달성하는 방법 각 쓰기에 고유 ID를 부여, 가장 높은 ID를 가진 쓰기를 선택가장 높은 ID(winner)를 선택하고, 다른 쓰기는 버린다.TimeStamp를 사용하면 최종 쓰기 승리(last write wins, LWW)라 부른다.대중적이지만 데이터 유실 위험이 존재 각 복제 서버에 고유 ID를 부여, 가장 높은 ID의 복제 서버에서 생긴 쓰기를 우선 적용위와 유사하지만 대상이 복제 서버이고 위는 각 쓰기데이터 유실 위험 존재 어떻게든 값을 병합 명시적 데이터 구조에 충돌을 기록해 모든 정보를 보존충돌을 해소하는 애플리케이션 코드가 필요사용자 정의 충돌 해소 로직충돌을 해소하는 가장 적합한 방법은 애플리케이션에 따라 다르다.따라서 대부분의 다중 리더 복제 도구는 애플리케이션 코드를 사용해 충돌 해소 로직을 수행한다.사용자 정의 충돌 해소 로직은 쓰기나 읽기 수행 중 실행될 수 있다. 쓰기 수행 중복제된 변경 사항 로그에서 데이터베이스 시스템이 충돌을 감지하자마자 충돌 핸들러를 호출백그라운드 프로세스에서 빠르게 실행돼야 함 읽기 수행 중충돌을 감지하면 모든 충돌 쓰기를 저장데이터를 읽을 때 여러 버전의 데이터를 에플리케이션에 반환그리고 애플리케이션은 사용자에게 충돌 내용을 보여주거나 자동으로 충돌을 해소 후 결과를 데이터베이스에 기록충돌 해소는 보통 전체 트랜잭션이 아니라 개별 로우나 문서 수준에서 적용된다.자동 충돌 해소 충돌 없는 복제 데이터타입(Conflict-free replicated datatype, CRDT)셋, 맵, 정렬 목록, 카운터 등을 위한 데이터 구조의 집합으로 동시에 여러 사용자가 편집할 수 있고 합리적인 방법으로 충돌을 자동 해소이중 병합(two-way merge) 사용리악 2.0에서 일부 구현CRDT vs OT 참고 병합 가능한 영속 데이터 구조(mergeable persistent data structure)깃 버전 제어 시스템과 유사하게 명시적으로 히스토리를 추적하고 삼중 병합 함수(three-way merge function)를 사용 운영 변환(operational transformation)협업 편집 애플리케이션의 충돌 해소 알고리즘CRDT vs OT 참고다중 리더 복제 토폴리지복제 토폴로지 : 쓰기를 한 노드에서 다른 노드로 전달하는 통신 경로를 설명원형 토폴로지(Circular topology)와 별 모양 토폴로지(Star topology) 모든 복제 서버에 도달하기 전에 여러 노드를 거쳐야 함 무한 복제 로프를 방지하기 위한 각 노드 별 고유 식별자 사용복제 로그에서 각 쓰기는 지나온 모든 노드의 식별자가 태깅자신의 식별자가 태깅된 경우, 데이터 변경 사항을 무시 하나의 노드에 장애가 발생하면 다른 노드 간 복제 메시지 흐름에 방해를 줌장애 노드를 회피하게끔 재설정 가능하지만 보통 수동으로 수행해야 함전체 연결 토폴로지(All-to-all topology) 가장 일반적인 토폴로지 빽빽하게 연결되어 내결함성이 더 좋음 네트워크 연결 간 속도 차이로 일부 복제 메시지가 다른 메시지를 “추월”할 수 있음리더 없는 복제모든 복제 서버가 클라이언트로부터 쓰기를 직접 받을 수 있게 허용하는 접근 방식이다.리더 없는 복제는 아마존이 내부 다이나모(Dynamo) 시스템에서 사용한 후 다시 유행했다.다이나모에서 영감을 얻은 리더 없는 복제 모델의 오픈 소스 데이터스토어를 다이나모 스타일 이라 하며, 리악, 카산드라, 볼드모트가 존재한다.전송 방식 클라이언트가 여러 복제 서버에 직접 전송 방식 코디네이터 노드가 중간에서 복제 서버에 전송하는 방식특정 순서로 쓰기를 수행하지는 않음노드가 다운됐을 때 데이터베이스에 쓰기여러 복제 서버 중 하나를 사용할 수 없어도 장애 복구가 필요하지 않다.복제 서버 3이 다운된 동안 발생한 모든 쓰기는 해당 노드에서 누락됐다.결과적으로 클라이언트가 복제 서버 3에서 데이터를 읽는다면 오래된(outdated) 값을 얻을 수 있다.이 문제를 해결하기 위해서 읽기 요청을 병렬로 여러 노드에 전송 한다.이때 받은 여러 요청의 결과 중 버전 숫자를 사용해서 어떤 값이 최신 내용인지 결정한다.읽기 복구와 안티 엔트로피위의 그림에서 복제서버 3이 누락된 쓰기를 따라잡는 방법이 여러가지 있다.그 중 두 가지 메커니즘이 주로 사용된다. 읽기 복구클라이언트는 복제 서버 3의 값이 오래된 값이라는 사실을 버전 값을 사용해 알게 된다.그리고 클라이언트는 해당 복제 서버에 새로운 값을 다시 기록한다. 안티 엔트로피 처리백그라운드 프로세스를 두고 복제 서버 간 데이터 차이를 지속적으로 찾아 누락된 데이터를 하나의 복제 서버에서 다른 서버로 복제한다.특정 순서로 쓰기를 복사하기 때문에 데이터가 복사되기까지 상당한 지연이 있을 수 있다.읽기와 쓰기를 위한 정족수정족수란 몇 개의 서버로 부터 읽기 요청과 쓰기 요청을 어느 범위까지 허용할지에 대한 내용이다.일반화해서 보자면 아래와 같다.n : 복제 서버(클러스터에 n개 이상의 노드가 있을 수 있음)w : 모든 쓰기는 최소 w개의 노드에서 성공r : 모든 읽기는 최소 r개의 노드에서 질의w + r &amp;gt; n이면 읽을 때 최신 값을 얻은 것으로 기대한다.다이나모 스타일 데이터베이스에서는 n, w, r 파라미터는 대개 설정 가능하다.정족수 일관성의 한계w + r &amp;gt; n인 경우에 오래된 값을 반환하는 에지 케이스가 존재한다. 느슨한 정족수를 사용한다면 w개의 쓰기는 r개의 읽기와 다른 노드에서 수행될 수 있다.r개의 노드와 w개의 노드가 겹치는 것을 보장하지 않음느슨한 정족수 : 정족수를 만족하지 않더라도 쓰기를 받아들이고 홈 노드에 속하지 않지만 연결할 수 있는 노드로써 기록 두 개의 쓰기가 동시에 발생하면 어떤 쓰기가 먼저 일어났는지 분명하지 않음해결책으로 동시 쓰기를 합치는 방법(“쓰기 충돌 다루기” 참고)승자를 타임스탬프 기반으로 결정한다면 시계 스큐(clock skew)로 인해 쓰기가 유실될 수 있음 쓰기가 읽기와 동시에 발생하면 읽기가 최신 값을 반환하는지 불분명쓰기가 일부 복제 서버에만 반영될 수 있기 때문 쓰기가 w보다 적은 서버에서 성공하더라도 성공한 복제 서버에서는 롤백하지 않음이어지는 읽기에 해당 쓰기 값이 반환될 수도 있고 아닐 수도 있다. 새 값을 가진 노드가 고장나면, 이전 값을 가진 노드가 이전 값을 전파하여 복원되는 경우새로운 값을 저장한 복제 서버 수가 w보다 낮아져 정족수 조건이 깨질 수 있음 모든 과정이 올바르게 동작해도 시점 문제로 에지 케이스가 존재할 수 있음즉, 매개변수 w와 r로 오래된 값을 읽는 확률을 조정할 수 있지만 절대적으로 보장할 수는 없다.“복제 지연 문제”에서 설명한 보장을 대개 받을 수 없기에 관련된 이상 현상이 발생할 수 있다.견고한 보장은 일반적으로 트랜잭션이나 합의가 필요하다.최신성 모니터링운영 관점에서 데이터베이스가 최신 결과를 반환하는지 여부를 모니터링하는 일은 중요하다.복제 형식에 따른 분류 리더 기반 복제데이터베이스는 일반적으로 복제 지연에 대한 지표를 노출하며 이 지표는 모니터링 시스템에 제공된다.현재 위치에서 팔로워의 현재 위치를 빼면 복제 지연량을 측정할 수 있다. 리더 없는 복제쓰기가 적용된 순서를 고정할 수 없어서 모니터링이 조금 더 어려움데이터베이스가 읽기 복구만 사용한다면 자주 읽히지 않는 값이 얼마나 오래된 것인지에 대한 제한이 없다.최종적 일관성은 의도적으로 모호한 보장이지만 운용성을 위해서는 “최종적”을 정량화할 수 있어야 한다.느슨한 정족수와 암시된 핸드오프적절히 설정된 정족수가 있는 데이터베이스는 장애 복구 없이 개별 노드 장애를 용인한다.요청은 w나 r개 노드가 응답할 때 반환할 수 있어 개별 노드의 응답이 느려지는 것도 허용 가능하다.리더 없는 복제가 매력적인 경우 높은 가용성과 낮은 지연 시간이 필요한 경우 오래된 값 읽기를 허용하는 경우노드가 n개 이상인 대규모 클러스터에서 클라이언트는 네트워크 장애 상황에서 정족수 구성에 들어가지 않는 데이터베이스 노드에 연결될 가능성이 있다.이 경우 데이터베이스 설계자는 트레이드오프에 직면한다. w나 r 노드 정족수를 만족하지 않는 모든 요청에 오류를 반환 일단 쓰기를 받아들이고 값이 보통 저장되는 “홈” 노드에 속하지 않지만 연결할 수 있는 노드에 기록2번을 느슨한 정족수 라고 한다.쓰기와 읽기는 여전히 w와 r의 성공 응답이 필요하지만 값을 위해 지정된 n개의 “홈” 노드에 없는 노드가 포함될 수 있다.네트워크 장애 상황이 해제 되면 한 노드가 다른 노드를 위해 일시적으로 수용한 모든 쓰기를 해당 “홈” 노드로 전송한다.이것을 암시적 핸드오프 라고 한다.느슨한 정족수는 쓰기 가용성 및 지속성을 높이는 데 특히 유용하다.이는 모든 일반적인 다이나모 구현에서 선택 사항이다.다중 데이터센터 운영리더 없는 복제도 동시 쓰기 충돌, 네트워크 중단, 지연 시간 급증을 허용하기에 다중 데이터센터 운영에 적합하다.카산드라와 볼드모트는 일반적인 리더 없는 모델에 다중 데이터센터 지원을 구현했다. n개의 복제 서버 수에는 모든 데이터센터의 노드가 포함 각 데이터센터마다 n개의 복제 서버 중 몇 개를 보유할지를 지정 클라이언트의 각 쓰기는 데이터센터 상관없이 모든 복제 서버에 전송 데이터센터 간 연결의 지연과 중단에 영향을 받지 않음클라이언트는 보통 로컬 데이터센터 안에서 정족수 노드의 확인 응답을 기다리기 때문보통 쓰기는 비동기로 처리리악의 경우 n은 하나의 데이터센터 안에 있는 복제 서버 수 데이터센터 간 복제는 백그라운드에서 비동기방식은 다중 리더 복제와 유사동시 쓰기 감지다이나모 스타일 데이터베이스는 여러 클라이언트가 동시에 같은 키에 쓰는 것을 허용한다.그래서 엄격한 정족수를 사용하더라도 충돌이 발생한다.이런 상황은 다중 리더 복제의 “쓰기 충돌 다루기”와 유사하다.또한 읽기 복구나 암시된 핸드오프 중에도 발생할 수 있다.문제는 이벤트가 다른 노드에 다른 순서로 도착할 수 있다는 것 이다.이는 다양한 네트워크 지연과 부분적인 장애 때문이다.다른 순서로 쓰기 이벤트가 도착하거나 순간적인 노드 장애로 인해 노드간의 데이터가 서로 달라진 상황을 아래 그림에서 확인할 수 있다.최종적인 일관성을 달성하기 위해 애플리케이션 개발자는 데이터베이스 내부에서 충돌을 어떻게 다루는지 잘 알아야 한다.최종 쓰기 승리(동시 쓰기 버리기)“예전” 값을 버리고 가장 “최신” 값으로 덮어쓰는 방법이다.어떤 쓰기가 “최신”인지 명확하게 결정할 수 있는 한 모든 쓰기는 최종적으로 모든 복제 서버에 복사되므로 복제본은 최종적으로 동일한 값으로 수렴한다.여기에서 “최신”은 확실하게 구분하기 힘든 경우가 많다.이렇게 “최신”이 확실하지 않다면 이벤트의 순서를 정할 수 없기에 동시 쓰기라 해야 한다.비록 쓰기는 자연적인 순서가 없지만 임의로 순서를 정할 수 있다.예를 들어 쓰기에 타임스탬프를 붙여서 최종 쓰기 승리(LWW)라 부르는 충돌 해소 알고리즘을 사용할 수도 있다.LWW는 최종적 수렴 달성이 목표이지만 지속성을 희생한다.결국 여러 쓰기 중 최신의 쓰기가 남고 그외의 쓰기는 버리기 때문이다.손실 데이터를 허용하지 않는다면 LWW는 충돌 해소에 적합하지 않다.보통 캐싱과 같이 손실된 쓰기를 허용하는 경우가 있다.LWW로 데이터베이스를 안전하게 사용하는 유일한 방법은 키를 한번 만 사용하는 것이다.(이후 불변)이 방법은 같은 키를 동시에 갱신하는 상황을 방지한다.“이전 발생” 관계와 동시성두 가지 작업이 동시에 수행됐는지 여부에 대해 어떻게 결정되는지 알아보자.몇 가지 예를 살펴보자. 두 개의 쓰기에 순서가 존재하는 경우(클라이언트 시점)A(1 입력) -&amp;gt; B(A++)인 경우B는 A에 인과성이 있다.(causally dependent) 두 개의 쓰기가 동시에 수행된 경우(클라이언트 시점)각 클라이언트가 작업을 시작할 때 다른 클라이언트가 동일한 키에 대한 작업을 수행했는지 알지 못한다.따라서 작업 간에 인과성이 없다.작업 A가 다른 작업 B 보다 이전 발생(happens-before)라고 말하는 경우는 아래와 같다. 작업 B가 작업 A에 대해서 아는 경우 작업 B가 작업 A에 의존 하는 경우 작업 B가 작업 A를 기반으로 작업 하는 경우즉, 한 작업이 다른 작업 이전에 발생했는지가 동시성을 의미를 정의하는 핵심이다.한 작업이 다른 작업보다 먼저 발생(happens-before)하지 않으면 단순히 동시 작업 이라 말한다.두 작업이 동시성인지 아닌지 알 수 있는 알고리즘이 필요하다.한 작업이 다른 작업 전에 발생했다면 나중 작업은 이전 작업을 덮어쓸 수 있다.하지만 작업이 동시에 발생하면 충돌을 해소해야 한다.이전 발생 관계 파악하기두 작업이 동시성인지 아닌지 여부를 결정하는 알고리즘을 살펴보자.여기서는 상황을 단순하게 만들기 위해 하나의 복제본을 가진 데이터베이스에서 시작한다.위의 그림의 작업 간 데이터플로를 아래에서 도표로 보여준다.화살표는 어떤 작업이 다른 작업 이전에 발생했는지와 나중 작업이 이전 작업에 수행된 작업을 알거나 의존했다는 사실이다.서버는 버전 번호를 보고 두 작업이 동시에 수행됐는지 여부를 결정할 수 있다.값 자체가 데이터 구조인 셈이다.해당 알고리즘은 다음과 같이 동작한다. 서버가 모든 키에 대한 버전 번호를 유지, 키를 기록할 때마다 버전 번호를 증가 클라이언트가 키를 읽을 때 서버는 최신 버전과 덮어쓰지 않은 모든 값을 반환클라이언트는 쓰기 전에 키를 읽어야 한다. 클라이언트가 키를 기록할 때 이전 읽기 버전 번호를 포함또한 이전 읽기에서 받은 모든 값을 합쳐야 한다. 서버가 특정 버전 번호를 가진 쓰기를 받을 때 해당 버전 이하 모든 값을 덮어쓸 수 있다.하지만 높은 버전 번호의 모든 값은 유지동시에 쓴 값 병합해당 알고리즘은 어떤 데이터도 자동으로 삭제되지 않음을 보장한다.하지만 클라이언트가 추가적으로 작업을 해줘야 한다.여러 작업이 동시에 발생하면 클라이언트는 동시에 쓴 값을 합쳐 정리해야 한다.리악은 이런 동시 값을 형제(sibling) 값이라 한다.형제 값 병합은 다중 리더 복제에서 충돌을 해소하는 문제와 본질적으로 같다.위의 장바구니 예제에서 형제를 병합하는 합리적인 접근 방식은 합집합을 취하는 것이다.하지만 상품을 제거도 할 수 있게 하려면 합집합으로는 올바른 결과를 얻을 수 없다.단순히 삭제하는 것으로는 상품을 제거할 수 없다.제거된 상품이 다시 나타날 수 있다.이를 위해서 툼스톤 이라는 방법을 사용한다.형제를 병합할 때, 상품이 제거됐음을 나타내는 표시를 해당 버전에 남기는 것이다.애플리케이션 코드에서 형제 병합은 복잡하고 오류가 발생하기 쉽다.이런 것을 자동으로 수행하기 위한 몇 가지 노력이 있다.예를 들어서 리악은 CRDT라는 방법을 사용한다.버전 벡터장바구니 예제는 단일 복제본을 사용했다.다중 복제본인 경우 살펴보자.장바구니 예제는 의존성 파악을 위해 단일 버전을 사용했다.다중 복제본인 경우 키당 버전 번호 뿐만 아니라 복제본당 버전 번호 도 사용해야 한다.모든 복제본의 버전 번호 모음을 버전 벡터(version vector) 라고 부른다.이를 변경한 몇 가지 방법 중 도티드 버전 벡터(dotted version vector) 란 것도 있다.버전 벡터를 사용하면 데이터베이스는 덮어쓰기와 동시 쓰기를 구분할 수 있다.참고 : version vector" }, { "title": "DDIA - 복제_단일 리더", "url": "/posts/DDIA-CH5-1/", "categories": "Study, Book", "tags": "Data, Applicationn, System", "date": "2022-05-27 00:00:00 +0900", "snippet": "Table of Contents 리더와 팔로워 동기식 대 비동기식 복제 새로운 팔로워 설정 노드 중단 처리 팔로워 장애: 따라잡기 복구 리더 장애: 장애 복구 리더 기반 복제 로그 구현 구문 기반 복제 Write-ahead log(WAL) 기반 복제 논리적(로우 기반) 로그 복제 트리거 기반 복제 복제 지연 문제 자신이 쓴 내용 읽기 단조 읽기 일관된 순서로 읽기 복제 지연을 위한 해결책 복제는 네트워크로 연결된 여러 장비에 동일한 데이터의 복사본을 유지한다는 의미이다.복제가 필요한 이유 지리적으로 사용자와 가깝게 데이터를 유지 -&amp;gt; 지연 시간 단축 가용성 읽기 처리량 향상복제의 어려움 복제된 데이터의 변경 처리복제를 위한 세 가지 대표적인 복제 알고리즘 단일 리더(single-leader) 다중 리더(multileader) 리더 없는(leaderless)복제에는 고려해야 할 많은 트레이드오프가 있다. 동기식 &amp;amp; 비동기식 복제 잘못된 복제본 처리 방법 …복제 서버(replica)는 데이터베이스의 복사본을 저장하는 각 노드를 의미한다.데이터베이스의 모든 쓰기는 모든 복제 서버에서 처리돼야 한다.리더와 팔로워가장 일반적인 방식으로 리더 기반 복제(leader-based replication)이다.능동(active)/수동(passive), 마스터(master) 슬레이브(slave) 복제라고도 한다.구성 리더(leader) 또는 마스터, 프라이머리클라이언트가 데이터베이스에 쓰기를 할 때 요청을 리더에게 보내야 함리더는 먼저 로컬 저장소에 새로운 데이터를 기록 팔로워(follower) 또는 읽기 복제 서버(read replica), 슬레이브, 2차(secondary), 핫 대기(hot standby)리더가 새로운 데이터를 기록할 때마다 데이터 변경을 복제 로그(replication log)나 변경 스트림(change stream)의 일부로 팔로워에게 전송받은 로그로 리더가 처리한 것과 동일한 순서로 적용해 로컬 복사본을 갱신클라이언트가 데이터베이스로부터 읽기를 할 때는 리더 또는 임의 팔로워에게 질의할 수 있다.하지만 쓰기는 리더에게만 허용된다.리더 기반 복제동기식 대 비동기식 복제하나의 동기식 팔로워, 하나의 비동기식 팔로워의 리더 기반 복제동기식 복제 장점 팔로워가 리더와 일관성 있게 최신 데이터 복사본을 가지는 것을 보장 단점 동기 팔로워가 응답하지 않는다면 쓰기가 처리될 수 없음때문에 모든 팔로워가 동기식인 상황은 비현실적 현실적으로 동기식 복제를 사용하려면 반동기식 복제 방식이 있다.반동기식(semi-synchronous)팔로워 하나는 동기식, 나머지는 비동기식으로 하는 것을 의미적어도 두 노드에 데이터의 최신 복사본이 있는 것을 보장완전한 비동기식장점 모든 팔로워가 잘못되더라도 리더가 쓰기 처리를 계속 할 수 있음단점 클라이언트에게 응답을 받은 경우에도 지속성을 보장하지 않음리더가 잘못되고 복구할 수 없으면 팔로워에 아직 복제되지 않은 모든 쓰기는 유실많은 팔로워가 있거나 지리적으로 분산됐다면 비동기식 복제를 널리 사용하며, 리더 기반 복제의 일반적인 구성이다.새로운 팔로워 설정중단 없이 새로운 팔로워가 리더의 데이터 복제본을 일관성 있게 만드는 과정을 개념적으로 살펴보자. 가능한 전체 데이터베이스를 잠그지 않고 리더의 데이터베이스 스냅숏을 일정 시점에 가져온다. 시냅숏을 새로운 팔로워 노드에 복사 팔로워는 리더에 연결해 스냅숏 이후 발생한 모든 데이터 변경을 요청(리더 복제 로그의 정확한 위치 필요)포스트그레스큐엘의 로그 일련번호(log sequence number)MySQL의 이진로그 좌표(binlog coordinate), GTID(Global Transaction Identifiers) 팔로워가 스냅숏 이후 데이터 변경의 미처리분(backlog)을 모두 처리이때 팔로워는 리더를 따라잡았다고 한다.노드 중단 처리중단 시간 없이 개별 노드를 재시작할 수 있다는 점은 운영과 유지보수에 큰 장점이다.리더 기반 복제에서 고가용성을 달성하는 방법에 대해서 알아보자.팔로워 장애: 따라잡기 복구 리더로부터 받은 데이터 변경 로그를 로컬 디스크에 보관 장애 발생 후, 로컬에 보관된 로그에서 장애 전에 처리한 마지막 트랜잭션을 확인(binlog coordinate, GTID 등) 마지막 트랜잭션 부터 변경분 요청리더 장애: 장애 복구장애 복구(failover) 과정 팔로워 중 하나를 새로운 리더로 승격 클라이언트는 새로운 리더로 쓰기 전송을 위해 재설정 다른 팔로워는 새로운 리더로부터 데이터 변경을 요청 시작장애 복구는 수동 또는 자동으로 진행한다.자동 장애 복구 과정 리더가 장애인지 판단무엇이 잘못됐는지 발견할 수 있는 확실한 방법이 없음그래서 대부분 타임아웃으로 단순하게 확인 새로운 리더를 선택선출 과정 또는 제어 노드(controller node)가 새로운 리더 임명새로운 리더로 가장 적합한 후보는 보통 최신 데이터 변경사항을 가진 복제 서버 새로운 리더 사용을 위한 시스템을 재설정이런 장애 복구 과정은 문제가 발생할 것 투성이다. 비동기식 복제의 경우 새로운 리더는 이전 리더의 쓰기를 일부 수신하지 못할 수 있다.이런 경우 가장 일반적인 해결책은 복제되지 않은 쓰기를 단순히 폐기하는 방법이 방법은 내구성에 대한 클라이언트의 기대를 저버리게 된다. 쓰기를 폐기하는 방법은 데이터베이스 외부의 다른 저장소 시스템이 데이터베이스 내용에 맞춰 조정돼야 한다면 특히 위험(깃허브 사례, 책 확인) 특정 결함 시나리오에서 신규 리더와 이전 리더 모두 자신이 리더라고 믿을 수 있다.이를 스플릿 브레인(split brain)이라 한다. 적절한 타임아웃의 애매함이런 문제에 대한 쉬운 해결책은 없다.그래서 보통 운영팀은 수동으로 장애 복구를 수행하는 방식을 선호한다.노드 장애, 불안정한 네트워크, 복제 서버 일관성과 관련된 트레이드오프, 지속성, 가용성, 지연시간 등의 문제는 분산 시스템에서 발생하는 근본적인 문제이다.리더 기반 복제 로그 구현구문 기반 복제 리더는 모든 쓰기 요청을 구문(statement)으로 기록 쓰기를 실행 구문 로그를 팔로워에게 전송 팔로워는 구문 로그를 파싱하고 실행여기에서 구문은 모든 INSERT, UPDATE, DELETE 구문이다.문제점 비결정적 함수를 포함한 모든 구문은 서버 마다 다른 값을 생성할 수 있다.예: NOW(), RAND() 등 자동 증가 컬럼, 데이터베이스의 데이터에 의존하는 구문은 정확히 같은 순서로 실행해야 한다.이는 동시에 여러 트랜잭션이 수행되는 것을 제한 부수효과를 가진 구문은 부수 효과가 완벽하게 결정적이지 않으면 다른 서버에서 다른 부수 효과가 발생할 수 있다.예: 트리거, 스토어드 프로시저, 사용자 정의 함수해당 문제들의 해결책으로 리더의 모든 비결정적 함수 호출을 고정 값을 반환하게끔 대체하는 것이다.하지만 여기에도 문제가 있기 때문에 다른 복제 방법을 선호한다.Write-ahead log(WAL) 기반 복제팔로워가 이 로그를 처리하면 리더와 정확히 동일한 데이터 구조의 복제본을 만들 수 있다.이 복제 방식은 포스트그레스큐엘과 오라클 등에서 사용된다.단점 제일 저수준의 데이터를 기술 어떤 디스크 블록에서 어떤 바이트를 변경했는지 같은 상제 정보를 포함 저장소 엔진과 밀접하게 엮임 같은 저장소라도 버전에 영향을 받을 수도 있음 복제 프로토콜의 버전 불일치 허용 여부에 따른 저장소 업그레이드 시 중단 시간이 필요할 수 있음논리적(로우 기반) 로그 복제논리적 로그 : 복제 로그를 저장소 엔진의 데이터 표현과 다른 형식을 사용하는 것 삽입된 로우의 로그는 모든 칼럼의 새로운 값을 포함(insert) 삭제된 로우의 로그는 로우를 고유하게 식별하는 데 필요한 정보를 포함(delete)보통 기본키이지만 없다면 모든 컬럼의 값을 로깅 갱신된 로우의 로그는 로우를 고유하게 식별하는 데 필요한 정보와 적어도 변경된 칼럼의 새로운 값을 포함(update) 여러 로우를 수정하는 트랜잭션은 여러 로그 레코드를 생성 후 트랜잭션이 커밋됐음을 레코드에 표시장점 하위 호환성을 쉽게 유지다른 버전의 데이터베이스 소프트웨어나 다른 저장소 엔진에서도 실행 가능 외부 애플리케이션이 파싱하기가 쉬움(예: CDC)트리거 기반 복제위의 세 가지 복제 방식은 데이터베이스 시스템에 의해 구현된다.보다 더 유연성이 필요한 상황 에서 복제를 애플리케이션 층으로 옮겨야 한다.예: 서브셋만 복제, 다른 종류의 데이터베이스로 복제, 충돌 해소 로직 등보통 이 경우에 트리거나 스토어드 프로시저를 사용한다.오라클의 경우 골든게이트 같은 도구를 제공한다.트리거 기반 복제의 단점 다른 복제 방식보다 많은 오버헤드 내장된 복제보다 버그나 제한 사항이 많음복제 지연 문제지금까지 복제를 하는 이유는 노드 내결함성, 지연시간, 확장성 이 있었다.읽기 확장(read-scaling) 아키텍처에서 간단히 팔로워를 더 추가해 읽기 전용 요청을 처리하기 위한 용량을 늘릴 수 있다.하지만 이 방식은 실제로 비동기식 복제에서만 동작 한다.비동기 팔로워에서 데이터를 읽을 때 지난 정보를 읽을 수도 있다.(팔로워가 뒤쳐진다면)하지만 이런 불일치는 일시적인 상태이다.복제 지연 시간 동안 기다리면 팔로워는 결국 리더와 일치하게 된다.이런 효과를 최종적 일관성 이라고 한다.하지만 애플리케이션에서 지연이 매우 크면 문제가 된다.이제 부터 비동기식 복제에서 복제 지연이 있을 때 발생할 수 있는 세 가지 사례와 해결 방법에 대해서 살펴보자.자신이 쓴 내용 읽기그림과 같은 상황에서는 쓰기 후 읽기 일관성(자신의 쓰기 읽기 일관성)이 필요하다.리더 기반 복제 시스템에서 쓰기 후 읽기 일관성에 대한 몇 가지 기법 사용자가 수정한 내용을 읽을 때는 리더에서 읽기그 외 팔로워에서 읽기 여러 사용자가 수정을 하는 내용의 경우리더에서 읽는 기준을 다른 기준을 사용예 : 마지막 갱신 시간, 팔로워 복제 지연 시간 모니터링을 통한 일정 시간 지연된 팔로워에 대한 질의 제외 클라이언트 기준 쓰기 타임스탬프 이용해당 타임스탬프 보다 최신의 복제서버에 질의 혹은 대기 복제 서버가 여러 데이터센터에 분산된 경우(복잡도 증가)리더가 제공해야 하는 모든 요청은 리더가 포함된 데이터센터로 라우팅동일한 사용자가 여러 디바이스로 서비스를 접근할 경우 또 다른 문제가 발생한다.이 경우 디바이스 간(cross-device) 쓰기 후 읽기 일관성이 제공돼야 한다. 클라이언트 기준 쓰기 타임스탬프 방식은 더 어려움해당 정보를 중앙집중식으로 관리 복제 서버가 여러 데이터센터 간에 분산된 경우여러 디바이스 연결이 동일한 데이터센터로 라우팅된다는 보장이 없다.리더에서 읽어야 할 필요가 있는 접근법이면 먼저 사용자 디바이스의 용청을 동일한 데이터센터로 라우팅해야 함단조 읽기해당 케이스는 사용자가 각기 다른 복제 서버에서 여러 읽기를 수행 때 발생할 수 있다.단조 읽기(monotonic read)는 그림과 같은 상황이 발생하지 않음을 보장한다.이는 강한 일관성보다는 덜한 보장이지만 최종적 일관성보다는 강한 보장이다.한 가지 방법 : 각 사용자의 읽기가 항상 동일한 복제 서버에서 수행되게끔 하는 것예 : 사용자 ID의 해시를 기반으로 복제 서버를 선택일관된 순서로 읽기그림과 같은 현상은 파티셔닝된 데이터베이스에서 발생하는 특징적인 문제다.이런 종류의 이상 현상을 방지하기 위해 일관된 순서로 읽기(Consistent Prefix Read) 같은 유형의 보장이 필요하다.일관된 순서로 읽기는 일련의 쓰기가 특정 순서로 발생한다면 이 쓰기를 읽는 모든 사용자는 같은 순서로 쓰여진 내용을 보게 됨을 보장한다.한 가지 방법 : 서로 인과성이 있는 쓰기는 동일한 파티션에 기록이런 방법은 일부 애플리케이션에서 효율적이지 않다.인과성을 명시적으로 유지하기 위한 알고리즘 또한 있다.복제 지연을 위한 해결책최종적 일관성 시스템으로 작업할 때 복제 지연에 따른 애플리케이션이 어떻게 동작할지 생각해 볼 가치가 있다.결과가 문제가 없다면 좋지만 쓰기 후 읽기와 같은 강한 보장을 제공하게끔 시스템을 설계해야 할 수도 있다.해결 방안은 복제가 비동기식으로 동작하지만 동기식으로 동작하는 척 하는 것이다.그래서 위에서 몇 가지 케이스와 해결책에 대한 대략적인 내용에 대해서 살펴 봤다.애플리케이션이 기본 데이터베이스보다 더 강력한 보장을 제공하는 방법이 있다.하지만 애플리케이션 코드가 너무 복잡해지고 잘못되기 쉽다.그래서 트랜잭션이 필요하다.오랫동안 단일 노드 트랜잭션이 존재 했지만 분산 데이터베이스로 전환하는 과정에서 많은 시스템이 트랜잭션을 포기했다.성능과 가용성 측면에서 비용이 너무 비싸고 확장 가능한 시스템에서는 어쩔 수 없이 최종적 일관성을 사용해야 한다는 주장이 있다.이 주장은 일부 사실이지만 지나치게 단순화됐다.트랜잭션, 일관성과 합의 2개의 챕터와 파생 데이터 파트에서 여러 대안 메커니즘에 대해서 알아본다." }, { "title": "DDIA - 부호화와_발전", "url": "/posts/DDIA-CH4/", "categories": "Study, Book", "tags": "Data, Applicationn, System", "date": "2022-05-20 00:00:00 +0900", "snippet": "Table of Contents 데이터 부호화 형식 언어별 형식 JSON과 XML 그리고 이진 변경 이진 부호화 스리프트와 프로토콜 버퍼 스리프트 프로토콜 버퍼 필드 태그와 스키마 발전 데이터타입과 스키마 발전 아브로 쓰기 스키마와 읽기 스키마 스키마 발전 규칙 쓰기 스키마란? 동적 생성 스키마 코드 생성과 동적 타입 언어 스키마의 장점 데이터플로 모드 데이터베이스를 통한 데이터플로 데이터베이스 내 호환성 데이터 덤프 서비스를 통한 데이터플로: REST와 RPC 웹 서비스 원격 프로시저 호출(RPC) 웹 서비스와 RPC 비교 서비스 내 호환성 메시지 전달 데이터플로 애플리케이션은 계속해서 발전하고, 동일한 애플리케이션 간에도 짧든 길든 버전 차이가 발생하게 된다.이렇게 발생하는 버전의 차이는 동일한 애플리케이션이든 클라이언트 서버 관계이든 호환성의 문제가 발생한다.여기서는 대표적인 데이터 부호화 형식들에 대해 간단하게 알아보고 비교해본다.이런 데이터 부호화 형식들에서 호환성의 문제에 대해서 알아본자.또한 프로세스간에 데이터를 전달하는 보편적인 방법에 대해서도 살펴보자.데이터 부호화 형식프로그램은 보통(최소) 두 가지 형태로 표현된 데이터를 사용해 동작 메모리에 데이터 유지객체, 구조체, 목록, 배열 등CPU에서 효율적으로 접근 및 조작에 최적화 일련의 바이트열 형태로 부호화파일에 쓰거나 네트워크를 통해 전송하기 위함보통 메모리에서 사용하는 데이터 구조와 상당히 다름두 가지 표현 사이에 전환 부호화인메모리 표현에서 바이트열로 전환직렬화, 마샬링이라고도 함 복호화바이트열에서 인메모리 표현으로 전환파싱, 역직렬화, 언마샬링언어별 형식많은 프로그래밍 언어는 인메모리 객체를 바이트열로 부호화하는 기능을 내장한다.이는 최소한의 추가 코드로 인메모리 객체를 저장하고 복원할 수 있기 때문에 매우 편리하다.하지만 심각한 문제점 또한 많다.문제점 부호화는 보통 특정 프로그래밍 언어에 의존적다른 언어에서 데이터를 읽기가 매우 어려움 보안 문제의 원인이 되기도 함복호화 과정이 임의의 클래스를 인스턴스화할 수 있어야 하기 때문 데이터 버전관리를 잘 고려하지 않게 됨 효율성도 잘 고려하지 않게 됨JSON과 XML 그리고 이진 변경JSON, XML, CSV는 텍스트 형식이라 어느 정도 가독성이 있다.하지만 피상적인 문법적 문제 외에도 일부 미묘한 문제가 있다.문제점 수의 부호화의 애매함XML과 CSV는 수와 숫자로 구성된 문자열을 구분할 수 없음JSON은 문자열과 수를 구분하지만 정수와 부동소수점 수를 구분하지 않고 정밀도를 지정하지 않음 애매함으로 큰 수를 다룰 때 문제 이진 문자열을 지원하지 않음Base64를 사용해 텍스트로 부호화해 이런 제한을 피함 -&amp;gt; 데이터 크기 33% 증가 XML과 JSON 모두 스키마를 지원하지만 러닝커브가 큼 XML과 JSON 스키마를 사용하지 않는 애플리케이션은 부호화/복호화 로직을 하드코딩해야 할 가능성 존재 CSV는 스키마가 없음로우와 컬럼의 의미를 정의하는 작업을 애플리케이션이 담당이런 결점에도 JSON, XML, CSV는 다양한 용도에 사용하기에 충분하다특히 데이터 교환 형식으로 사용하기에 매우 좋다.그렇다고 읽기 쉽고 효율적이 형식이란 것은 아니다.이진 부호화 { &quot;userName&quot;: &quot;Martin&quot;, &quot;favoriteNumber&quot;: 1337, &quot;interests&quot;: [ &quot;daydreaming&quot;, &quot;hacking&quot; ] }이번 장에서 다양한 형식으로 이진 부호화할 레코드 예JSON용 이진 부호화 형식인 메시지팩을 살펴보자메시지팩 예제위의 그림은 위의 JSON 문서를 메시지팩으로 부호화한 바이트열이다.이진 부호화의 길이는 66바이트로 텍스트 JSON 부호화로 얻은 81바이트보다 작다.JSON의 모든 이진 부호화는 이와 비슷하다.이 같은 작은 공간의 절약이 사람의 가독성을 해칠 만큼 가치가 있는지는 확실치 않다.스리프트와 프로토콜 버퍼아파치 스리프트와 프로토콜 버퍼는 같은 원리를 기반으로 한 부호화 라이브러리다.모두 스키마를 사용한다.스리프트인터페이스 정의 언어(interface definition language, IDL)로 스키마를 정의해야 한다. struct Person { 1: required string userName, 2: optional i64 favoriteNumber, 3: optional list&amp;lt;string&amp;gt; interests }스리프트의 두 가지 다른 이진 부호화 형식 바이너리프로토콜(BinaryProtocol) 컴팩트프로토콜(CompactProtocol)먼저 바이너티프로토콜을 살펴보자스리프트의 바이너리프로토콜을 사용해 부호화 예제메시지팩에서 필드 이름(username, favoriteNumber, interests)를 사용하던 것과 달리 필드 태그(1, 2, 3)을 사용한다.이제 컴팩트프로토콜을 살펴보자스리프트의 컴팩트프로토콜을 사용해 부호화 예제 의미상 바이너리프로토콜과 동일 필드 타입과 태그 숫자를 단일 바이트로 줄임 가변 길이 정수를 사용1바이트 : -64~632바이트 : -8192~8191…동일한 정보를 34바이트로 부호화프로토콜 버퍼프로토콜 버퍼로 정의한 동일한 내용의 스키마이며 스리프트 스키마와 매우 비슷하다. message Person { required string user_name = 1; optional int64 favorite_number = 2; repeated string interests = 3; }스리프트 컴팩트프로토콜과 부호화 형식도 매우 비슷하다.프로토콜 버퍼를 사용해 부호화한 예제스키마에 각 필드에는 required, optional 표시가 있지만 부호화하는 방법에서 차이가 나지 않는다.하지만 required는 필드가 설정되지 않은 경우를 실행 시에 확인할 수 있어 버그를 잡을 때 유용하다.필드 태그와 스키마 발전스키마는 필연적으로 시간이 지남에 따라 변한다. 이를 스키마(schema evolution) 이라고 부른다.스리프트와 프로토콜 버퍼에서 하위 호환성과 상위 호환성을 유지하면서 필드 태그에서 스키마 발전을 하는 것을 살펴본다. 스키마에서 필드 이름은 변경 가능하지만, 필드 태그를 변경할 수 없다. 새로운 필드 추가이전 버전 코드에서 새로운 코드로 기록한 데이터를 읽는 경우, 해당 필드를 무시추가되는 모든 필드는 optional 또는 기본값이 필요 필드를 삭제optional 필드만 삭제 가능같은 태그 번호는 절대 사용할 수 없음데이터타입과 스키마 발전스리프트와 프로토콜 버퍼에서 하위 호환성과 상위 호환성을 유지하면서 데이터타입에서 스키마 발전을 하는 것을 살펴본다. 데이터 타입 변경은 가능하지만, 값이 정확하지 않거나 잘릴 위험이 존재 프로토콜 버퍼에서 optional 필드를 repeated 필드로 변경 가능 이전 데이터를 읽는 새로운 코드는 0이나 1개의 엘리먼트가 있는 목록으로 인식 새로운 데이터를 읽는 이전 코드는 목록의 마지막 엘리먼트만 인식 스리프트는 repeated는 없지만 전용 데이터타입이 존재위의 내용을 지원하지 않지만, 중첩된 목록을 지원한다는 장점이 있음 아브로스리프트가 하둡의 사용 사례에 적합하지 않아 2009년 하둡의 하위 프로젝트로 시작했다.아브로 또한 스키마를 사용하며, 2가지 스키마 언어가 있다. 아브로 IDL(Avro IDL)사람이 편집할 수 있다. record Person { string userName; union { null, long } favoriteNumber = null; array&amp;lt;string&amp;gt; interests; } JSON 기반 언어기계가 더 쉽게 읽을 수 있다. { &quot;type&quot;: &quot;record&quot;, &quot;name&quot;: &quot;Person&quot;, &quot;fields&quot;: [ { &quot;name&quot;: &quot;userName&quot;, &quot;type&quot;: &quot;string&quot; }, { &quot;name&quot;: &quot;favoriteNumber&quot;, &quot;type&quot;: [ &quot;null&quot;, &quot;long&quot; ], &quot;default&quot;: null }, { &quot;name&quot;: &quot;interests&quot;, &quot;type&quot;: { &quot;type&quot;: &quot;array&quot;, &quot;items&quot;: &quot;string&quot; } } ] } 특징 스키마에 태그 번호가 없음 모든 부호화 중 길이가 가장 짧음 필드나 데이터타입을 식별하기 위한 정보가 없음 부호화는 단순히 연결된 값으로 구성 정수는 가변 길이 부호화를 사용해서 부호화 정확히 같은 스키마를 사용하는 경우에만 올바르게 복호화아브로를 이용해 부호화한 예제쓰기 스키마와 읽기 스키마쓰기 스키마(reader’s schema) : 데이터를 아브로로 부호화할 때 사용하는 스키마읽기 스키마(writer’s schema) : 이진 데이터를 복호화할 때 사용하는 스키마아브로의 핵심 아이디어 : 쓰기 스키마와 읽기 스키마가 동일하지 않아도 되며 단지 호환 가능하면 된다 데이터 복호화할 때아브로 라이브러리는 쓰기 스키마와 읽기 스키마를 함께 살펴본 다음 쓰기 스키마에서 읽기 스키마로 데이터를 변환해 그 차이를 해소이를 스키마 해석(schema resolution)이라 함 스키마 해석읽기 스키마에 없고 쓰기 스키마에 존재하는 필드는 무시읽기 스키마에 있고 쓰기 스키마에 없다면 읽기 스키마의 기본값으로 설정스키마 발전 규칙아브로에서 상/하위 호환성의 의미 상위 호환성 : 새로운 버전의 쓰기 스키마와 예전 버전의 읽기 스키마를 가질 수 있음 하위 호환성 : 새로운 버전의 읽기 스키마와 예전 버전의 쓰기 스키마를 가질 수 있음호환성 규칙 호환성을 유지하기 위해서는 기본값이 있는 필드만 추가 및 삭제 기본값이 없는 필드를 추가는 하위 호환성이 깨짐 기본값이 없는 필드를 삭제는 상위 호환성이 깨짐 아브로는 null을 기본값으로 허용하지 않음(버그를 막는데 도움)유니온 타입을 사용해서 null을 허용할 수 있음 필드의 데이터타입 변경 가능타입을 변환할 수 있기 때문 필드 이름 변경도 가능하나 까다로움읽기 스키마는 필드 이름의 별칭을 부여 가능해서 별칭에 예전 쓰기 스키마 필드 이름을 매치할 수 있음즉, 하위 호환성이 있지만 상위 호환성이 없음 비슷하게 유니온 타입에 엘리멘트를 추가하는 것은 하위 호환성은 있지만 상위 호환성은 없다.쓰기 스키마란?아브로는 이진 데이터를 복호화하기 위해서 자신의 읽기 스키마와 부호화에 사용된 쓰기 스키마를 사용해서 스키마 해석을 통해 복호화를 한다.즉, 리더(복호화 하는 주체)는 쓰기 스키마가 필요하다.이진 데이터를 보낼때 마다 쓰기 스키마를 포함 시킨다면 이진 데이터보다 스키마가 클 가능성이 있다.그러면 이진 부호화로 절약한 공간이 의미가 없어진다.아브로는 아래와 같이 해결을 했다. 많은 레코드가 있는 대용량 파일파일의 시작 부분에 한 번만 쓰기 스키마를 포함 개별적으로 기록된 레코드를 가진 데이터베이스데이터베이스의 다양한 레코드들은 다양한 쓰기 스키마를 사용해 서로 다른 시점에 쓰여질 수 있다.가장 간단한 방법으로 모든 부호화된 레코드의 시작 부분에 버전 번호를 포함하고 데이터베이스에 스키마 버전 목록을 관리한다.리더는 레코드를 가져와 버전 번호를 추출 후 데이터베이스에서 버전 번호에 해당하는 쓰기 스키마를 가져온다. 네트워크 연결을 통해 레코드 보내기통신할 때 연결 설정에서 스키마 버전 합의이후 연결을 유지하는 동안 합의된 스키마를 사용아브로 RPC 프로토콜의 동작동적 생성 스키마프로토콜 버퍼와 스리프트 대비 아브로 방식은 한 가지 장점이 있다.스키마에 태그 번호가 없다는 점이다.이 차이는 아브로가 동적 생성 스키마에 더 친숙하다는 점에서 온다.예를 들어 관계형 스키마를 아브로 스키마로 쉽게 생성 가능하며 이 스키마를 이용해 레코드들을 부호화하고 아브로 객체 컨테이너 파일로 모두 덤프할 수 있다.아브로 객체 컨테이너 파일에는 데이터베이스 스키마로 생성한 아브로 스키마를 포함한다.그래서 스키마 변경에 신경 쓸 필요가 없다.이에 반해 스리프트나 프로토콜 버퍼로 이런 용도로 사용한다면 필드 태그를 수동으로 할당해야 한다.아브로는 동적 생성 스키마를 고려한 설계인 반면에 스리프트와 프로토콜 버퍼의 목표는 아닌였을 뿐이다.코드 생성과 동적 타입 언어스리프트와 프로토콜 버퍼는 코드 생성에 의존한다.정적 타입 언어와 동적 타입 언어에서 코드 생성 관점에서 살펴보자정적 타입 언어 효율적인 인메모리 구조 사용 데이터 구조에 접근하는 프로그램 작성 시 유용타입 확인 및 자동완성이 가능해짐동적 타입 언어 컴파일 시점의 타입 검사기가 없음코드 생성이 중요치 않음 동적 생성 스키마의 경우 코드 생성은 데이터를 가져오는 데 불필요한 장애물동적 생성 스키마의 예로 아브로아브로는 코드 생성을 선택적으로 제공 한다.(쓰기 스키마를 포함한)객체 컨테이너 파일이 있다면 코드 생성 없이도 JSON 파일을 보는 것과 같이 데이터를 볼 수 있다.객체 컨테이너 파일 동적 타입 데이터 처리 언어(아파치 피그)와 함께 사용할 때 특히 유용 스키마를 생각하지 않고도 출력 파일에 파생 데이터를 기록할 수 있음스키마의 장점지금까지 살펴본 프로토콜 버퍼와 스리프트, 아브로는 스키마를 사용한다.이 스키마 언어는 XML, JSON 스키마 대비 훨씬 간단 더 자세한 유효성 검사 규칙을 지원 구현과 사용이 더 간단이진 부호화의 좋은 속성 부호화된 데이터에서 필드 이름 생략 가능크기가 작아짐 스키마 자체로 유용한 문서화 형식 스키마 데이터베이스를 유지하면 스키마 변경 전에 상위/하위 호환성을 확인 가능 정적 타입 프로그래밍 언어에서 코드 생성은 유용(위에 참고)데이터플로 모드데이터플로는 매우 추상적인 개념이다.하나의 프로세스에서 다른 프로세스로 데이터를 전달하는 방법이다.데이터를 전달하기 위해서 앞에서 살펴본 바이트열로 부호화와 복호화라는 작업을 하게 된다.여기서는 보편적인 방법에 대해서 살펴본다.데이터베이스를 통한 데이터플로데이터베이스에 기록하는 프로세스는 데이터를 부호화데이터베이스에서 읽는 프로세스는 데이터를 복호화한다.데이터베이스 내 호환성 하위 호환성 필요예전 버전의 코드로 값을 기록, 신규 버전의 코드로 그 값을 읽을 수 있기 때문에 필요 상위 호환성 필요(순회식 업그레이드)신규 버전의 코드로 값을 기록, 예전 버전의 코드로 그 값을 읽을 수 있기 때문에 필요 상위 호환성에서 추가적인 문제점변환 과정에서 알지 못하는 필드가 유실될 수 있음다양한 버전의 애플리케이션이 존재하는 경우 데이터 유실 예제데이터 덤프데이터 덤프는 한 번에 기록하고 이후에는 변하지 않으므로 아브로 객체 컨테이너 파일과 같은 형식이 적합서비스를 통한 데이터플로: REST와 RPC네트워크를 통해 통신해야 하는 프로세스가 있을 때, 가장 일반적으로 클라이언트와 서버 두 역할로 배치한다.여기서 말하는 서비스 는 서버가 공개한 API이다.예전 버전과 새로운 버전의 서버와 클라이언트가 동시에 실행될 수 있기에 서비스 API도 버전 간 호환이 가능해야 한다.웹 서비스웹 서비스는 서비스와 통신하기 위한 기본 프로토콜로 HTTP를 사용한다.대중적인 두 가지 방법 REST HTTP의 원칙을 토대로 한 설계 철학 간단한 데이터 타입을 강조 URL을 사용해 리소스를 식별, 캐시 제어, 인증 등 HTTP 기능을 사용 REST 원칙에 따라 설계된 API를 RESTful이라고 함 SOAP XML 기반 프로토콜 HTTP와 독립적이며 대부분의 HTTP 기능을 사용하지 않음 원격 프로시저 호출(RPC)RPC 모델은 원격 네트워크 서비스 요청을 같은 프로세스 안에서 특정 프로그래밍 언어의 함수를 호출하는 것과 동일하게 사용 가능하게 해준다.문제점 RPC는 네트워크 요청, 따라서 로컬 함수 호출과는 매우 다름 로컬 함수 호출은 예측 가능하지만 네트워크 요청은 예측이 어려움 그래서 RPC는 여러 네트워크 문제에서 자유롭지 못 함현재 방향 차세대 RPC 프레임워크는 원격 요청이 로컬 함수 호출과 다르다는 사실을 더욱 분명히 함웹 서비스와 RPC 비교REST의 장점 네트워크 프로토콜이라는 사실이 잘 들어남 실험과 디버깅에 적합 모든 주요 프로그래밍 언어와 플랫폼이 지원 사용 가능한 다양한 도구 생태계RPC의 장점 이진 부호화 형식을 사용하는 사용자 정의 RPC 프로토콜의 우수한 성능 및 압축서비스 내 호환성 SOAP요청과 응답은 XML 스키마로 지정되며 발전 가능하지만 일부 미묘한 함정이 존재 RESTful API응답에 JSON을 가장 일반적으로 사용선택적 요청 매개변수 추가나 응답 객체의 새로운 필드 추가는 대개 호환성을 유지하는 변경으로 간주 RPC스키마의 상하위 호환 속성은 사용하는 부호화(스리프트, 프로토콜 버퍼, 아브로)로 부터 상속호환성을 깨는 변경이 필요하면 서비스 제공자는 보통 여러 버전의 서비스 API를 함께 유지한다.메시지 전달 데이터플로여기서는 RPC와 데이터베이스 간 비동기 메시지 전달 시스템을 간단히 살펴본다.메시지를 직접 네트워크로 전송하지 않고 메시지를 저장하는 메시지 브로커나 메시지 지향 미들웨어라는 중간 단계를 거쳐 전송한다.RPC 대비 메시지 브로커의 장점 메시지 브로커가 버퍼처럼 동작하여 시스템 안정성 향상 메시지 유실을 방지 송신자가 수신자의 수신 정보를 알 필요가 없음 여러 수신자로 전송 가능 논리적으로 송신자와 수신자가 분리수신자가 받은 메시지를 다시 게시한다면 데이터베이스에서 설명한 데이터 유실 문제가 발생할 수 있다." }, { "title": "DDIA - 저장소와 검색", "url": "/posts/DDIA-CH3/", "categories": "Study, Book", "tags": "Data, Applicationn, System", "date": "2022-05-13 00:00:00 +0900", "snippet": "Table of Contents 들어가기 데이터베이스를 강력하게 만드는 데이터 구조 해시 색인 SS테이블과 LSM 트리 SS테이블 생성과 유지 성능 최적화 모아보기 B 트리 최적화 B 트리와 LSM 트리 비교 LSM 트리의 장점 기타 색인 구조 색인에 값 저장하기 다중 컬럼 색인 전문 검색과 퍼지 색인 모든 것을 메모리에 보관 트랜잭션 처리나 분석? 데이터 웨어하우징 분석용 스키마: 별 모양 스키마와 눈꽃송이 모양 스키마 칼럼 지향 저장소 칼럼 압축 메모리 대역폭과 벡터화 처리 칼럼 저장소의 순서 정렬 다양한 순서 정렬 칼럼 지향 저장소에 쓰기 집계: 데이터 큐브와 구체화 뷰 들어가기해당 챕터에서는 데이터베이스가 데이터를 저장하는 방법, 데이터를 다시 찾는 방법 에 대해서 설명한다.애플리케이션 개발자가 해당 내용을 알아야 하는 이유 애플리케이션에 적합한 엔진을 선택하는 작업이 필요 특정 작업부하 유형에서 저장소 엔진의 성능을 조정저장소 엔진이 내부에서 수행되는 작업에 대한 대략적인 개념을 이해할 필요데이터베이스를 강력하게 만드는 데이터 구조많은 데이터베이스는 내부적으로 추가 전용(append-only) 데이터 파일인 로그를 사용 일반적으로 파일 추가 작업은 매우 효율적반면 로그(append-only)에 많은 레코드가 있고, 로그에서 단순한 조회 처리는 성능이 매우 좋지 않다.(검색 비용 O(n))이렇듯 특정 키의 값을 효율적으로 찾기 위해서는 다른 데이터 구조가 필요한데, 이것이 바로 색인 이다.색인 일반적인 개념은 어떤 부가적인 메타데이터를 유지하는 것이 메타데이터는 이정표 역할을 해서 원하는 데이터의 위치를 찾는 데 도움을 준다. 기본 데이터에서 파생된 추가적인 구조추가적인 구조의 유지보수는 특히 쓰기 과정에서 오버헤드가 발생 -&amp;gt; 쓰기 속도를 느리게 만듬해시 색인매우 일반적이고 더욱 복잡한 색인을 위한 구성 요소로 유용하다.단순히 파일에 추가하는 방식으로 데이터 저장소를 구성한다고 가정해보자.그러면 가장 간단한 색인 전략은 키를 데이터 파일의 바이트 오프셋에 매핑해 인메모리 해시 맵을 유지하는 전략이다.키-값 쌍의 로그, 인메모리 해시 맵으로 색인파일에 항상 추가만 한다면 결국 디스크 공간이 부족해진다. 이 상황은 어떻게 피할 수 있을까?좋은 해결책으로 특정 크기의 세그먼트(segment) 로 로그를 나누는 방식이 있다. 특정 크기에 도달하면 세그먼트 파일을 닫고 새로운 세그먼트 파일에 이후 쓰기를 수행 세그먼트 파일들에 대해 컴팩션을 수행컴팩션은 각 키의 최신 갱신 값만 유지하는 것을 의미 고정된 세그먼트의 병합과 컴팩션은 백그라운드 스레드에서 수행할 수 있다. 컴팩션 동안 이전 세그먼트 파일을 사용해 읽기와 쓰기 요청을 처리 병합 이후, 새로 병합한 세그먼트로 전환(이전 세그먼트 파일은 삭제) 컴팩션과 병합을 동시에 수행조회 처리 과정 최신 세그먼트 해시 맵을 확인 1에서 키가 없다면 두 번째 최신 세그먼트 등을 확인추가 전용 설계의 장점 추가와 세그먼트 병합은 순차 쓰기 작업이므로 보통 무작위 쓰기보다 훨씬 빠르다. 세그먼트 파일이 추가 전용 또는 불변이면 동시성과 고장 복구 측면에서 훨씬 간단하다. 오래된 세그먼트 병합은 조각화되는 데이터 파일 문제를 피할 수 있다.해시 테이블 색인의 제한 사항 메모리에 저장해야 하므로 키가 너무 많으면 문제 비효율적인 범위 질의SS테이블과 LSM 트리지금까지 이야기한 세그먼트 파일의 형식에서 간단한 변경 사항 한 가지를 적용해보자.키-값 쌍을 키로 정렬하는 것 이다.이것을 정렬된 문자열 테이블(Sorted String Table) 또는 짧게 SS테이블이라 부른다.또한 각 키는 각 병합된 세그먼트 파일 내에 한 번만 있어야 한다.SS테이블은 해시 색인을 가진 로그 세그먼트와 비교해 몇 가지 장점 가진다. 세그먼트 병합은 파일이 사용 가능한 메모리보다 크더라도 간단하고 효율적 각 파일의 첫 번째 키를 확인, 가장 낮은 키를 새 병합 세그먼트 파일로 복사를 반복 여러 세그먼트가 동일한 키를 포함한 경우, 가장 최근 세그먼트의 값을 유지하고 오래된 세그먼트의 값은 버린다. SS테이블 세그먼트 병합, 각 키의 최신 값만 유지 특정 키를 찾기 위해 메모리에 모든 키의 색인을 유지할 필요가 없다. 일부 키에 대한 오프셋만 유지한 인메모리 색인(희소 색인)을 가진 SS테이블 레코드들을 블록으로 그룹화하고 디스크에 쓰기 전에 압축 읽기 요청은 요청 범위 내에서 여러 키-값 쌍을 스캔해야 하기 때문 디스크 공간 절약 I/O 대역폭 사용 절약 SS테이블 생성과 유지 쓰기 요청은 인메모리 균형 트리 데이터 구조(red-black tree, AVL tree 등)에 추가memtable이라고도 함 멤테이블이 임계값보다 커지면 SS테이블 파일로 디스크에 기록해당 SS 테이블은 가장 최신 세그먼트디스크에 기록하는 동안 쓰기는 신규 멤테이블에 기록 읽기 요청은 멤테이블, 최신 세그먼트, 다음 세그먼트 … 순으로 진행 가끔 세그먼트들을 병합, 컴팩션 과정을 수행백그라운드에서 수행장애를 대비하기 위해 별도의 로그를 디스크에 작성한다.이 로그는 장애 후, 멤테이블을 복원하기 위해서만 사용하기에 정렬되지 않아도 된다.멤테이블이 SS테이블로 기록되면 해당 로그는 지우고 새로 작성할 수 있다.성능 최적화LSM 트리 알고리즘은 데이터베이스에 존재하지 않는 키를 찾는 경우 느릴 수 있다.해당 경우를 최적화하기 위해 저장소 엔진은 보통 블룸 필터(Bloom filter)를 추가적으로 사용한다.SS테이블을 압축하고 병합하는 순서와 시기를 결정하는 전략은 다양하다.일반적으로 2가지가 존재한다. 크기 계층(size-tiered)상대적으로 최신의 작은 SS테이블을 상대적으로 오래된 큰 SS테이블에 연이어 병합 레벨 컴팩션(leveled compaction)키 범위를 더 작은 SS테이블로 나누고 오래된 데이터는 개별 레벨로 이동그래서 컴팩션을 점직적으로 진행해 디스크 공간을 덜 사용모아보기지금까지 이야기 한 내용의 색인 구조는 로그 구조화 병합 트리(Log-Structured Merge-Tree)라고 불린다.그리고 LSM 트리의 구조를 보면 아래와 같다.SS테이블은 LSM 저장소 엔진의 한 구성 요소이다.이 개념은 데이터셋이 가능한 메모리보다 훨씬 더 크더라도 효과적이다.데이터가 정렬된 순서로 저장돼 범위 질의를 효율적으로 수행할 수 있다.디스크 쓰기는 순차적이기에 매우 높은 쓰기 처리량도 보장한다.출처 : http://kflu.github.io/2018/02/09/2018-02-09-lsm-treeB 트리특징 가장 널리 사용되는 색인 구조이다. 정렬된 키-값 쌍을 유지키-값 검색과 범위 질의에 효율적이다. 고정 크기 블록 혹은 페이지 단위로 읽기 또는 쓰기 리프 페이지는 각 키의 값 혹은 실제 값을 포함한 페이지의 참조를 포함 동시성 제어는 보통 래치(latch)로 트리의 데이터 구조를 보호 WAL 또는 Redo log 데이터 구조 관리데이터 베이스 크래시 상황을 대비해 디스크 상에 쓰기 전 로그(write-ahead log, WAL) 또는 재실행 로그(redo log) 데이터 구조를 관리쓰기 전 로그는 트리 페이지에 변경된 내용을 적용하기 전 모든 B 트리의 변경 사항을 기록하는 추가 전용 파일이다.이 로그는 복구 시에 일관성 있는 상태로 B 트리를 다시 복원하는 데 사용한다.최적화 WAL 대신 일부 데이터베이스는 쓰기 시 복사 방지(copy-on-write scheme)를 사용 키를 축약해 공간을 절약트리 내부 페이지에서 키가 범위 사이의 경계 역할을 할수 있을 정도 리프 페이지를 디스크 상에 연속된 순서로 배치하려고 시도하지만 트리가 커지면 순서를 유지하기가 어려움 트리에 포인터를 추가예를 들어 각 리프 페이지에 양쪽 형제 페이지에 대한 포인터 트랙탈 트리B 트리와 LSM 트리 비교LSM 트리는 보통 쓰기가 빠르지만 B 트리는 보통 읽기가 빠르다.LSM 트리가 보통 읽기가 느린 이유는 각 컴팩션 단계에 있는 여러 가지 데이터 구조와 SS 테이블을 확인해야 하기 때문이다.LSM 트리의 장점B 트리의 장점 로그 구조화 저장소 엔진보다 예측이 쉬운 성능 각 키가 색인의 한 곳에만 정확히 존재 강력한 트랜잭션 시맨틱을 제공하는 데이터베이스에 매력적 많은 작업 부하에 지속적으로 좋은 성능을 제공B 트리 단점 B 트리 색인은 모든 데이터 조각을 최소 2번 기록쓰기 전 로그, 트리 페이지에 최소 1번 기록해야 하기 때문(쓰기 증폭) 페이지 내 몇 바이트만 바뀌어도 전체 페이지를 기록해야 하는 오버헤드 발생 파편화로 인해 사용하지 않는 디스크 공간 일부 낭비LSM 트리의 장점 B 트리 대비 높은 쓰기 처리량상대적으로 낮은 쓰기 증폭컴팩션된 SS 테이블을 파일에 순차적 쓰기 B 트리 대비 높은 압축률컴팩션 및 머지 프로세스를 통해 주기적으로 파편화 제거LSM 트리 단점 SS 테이블의 반복된 컴팩션과 병합으로 여러 번 데이터를 다시 기록(쓰기 증폭) 컴팩션 과정이 때로는 진행 중인 읽기와 쓰기 성능에 영향디스크가 가진 자원의 한계로 인해 발생이로 인해서 상위 백분위 질의의 응답 시간이 때때로 꽤 길다. 데이터베이스가 커질수록 컴팩션을 위해 더 많은 디스크 대역폭이 필요 컴팩션이 유입 쓰기 속도를 못 따라갈 수 있다.디스크 상에 병합되지 않은 세그먼트 수가 디스크 공간이 부족할 때까지 증가할 수 있다.병합되지 않은 세그먼트 수가 늘어나 읽기 속도가 느려진다.컴팩션 설정에 주의가 필요 여러 세그먼트에 같은 키의 다중 복사본이 존재할 수 있다.기타 색인 구조기본키(primary key) 색인 키-값 색인의 대표적인 예 대상 데이터(로우/문서/정점)를 키로 고유하게 식별 및 참조보조 색인(secondary index) 보통 조인을 효율적으로 수행하는 데 결정적인 역할 키가 유일하지 않음보조 색인에서 키가 고유하지 않은 문제를 해결하는 방안(B 트리 &amp;amp; 로그 구조화 색인 모두 사용 가능) 색인의 각 값에 일치하는 로우 식별자 목록을 만드는 방법(전문 색인에서 포스팅 목록과 같음) 로우 식별자를 추가해 각 키를 고유하게 만드는 방법색인에 값 저장하기색인에서 값 실제 로우(문서, 정점) 힙 파일을 가리키는 참조힙 파일 : 로우가 실제로 저장된 파일, 특정 순서 없이 데이터를 저장힙 파일 접근은 일반적인 방식, 여러 보조 색인이 존재할 때 데이터 중복을 피할 수 있기 때문이다.힙 파일 접근 방식 키를 변경하지 않고 값을 갱신할 때 꽤 효율적 새로운 값이 이전 값 보다 많은 공간을 필요로 하지 않으면 레코드를 제자리에 덮어쓸 수 있다. 새로운 값이 많은 공간을 필요로 한다면 새로운 곳으로 위치를 이동 모든 색인이 레코드의 새로운 힙 위치로 갱신 이전 힙 위치에 전방향 포인터 기록 클러스터드 색인(clustered index) 색인 안에 색인된 로우를 저장색인에서 힙 파일로 다시 이동하는 일은 읽기 성능에 불이익이 많기 때문 MySQL의 InnoDB에서 테이블의 기본키가 언제나 클러스터드 색인 MySQL의 InnoDB에서 보조 색인은 기본키를 참조커버링 색인(covering index) 포괄열이 있는 색인(index with included column)으로도 불림 클러스터드 색인과 비클러스터드 색인 사이의 절충안 색인 안에 테이블의 컬럼 일부를 저장모든 종류의 데이터 복제와 마찬가지로 클러스터드 색인과 커버링 색인은 읽기 성능을 높일 수 있다.하지만 추가적인 저장소가 필요하고 쓰기 오버헤드가 발생한다.애플리케이션 단에서 복제로 인한 불일치를 파악할 수 없기 때문에 데이터베이스는 트랜잭션 보장을 강화하기 위해 별도의 노력이 필요하다.다중 컬럼 색인지금까지 이야기한 색인은 하나의 키만 값에 대응한다.그래서 다중 컬럼에 동시에 질의를 해야 한다면 충분하지 않다.결합 색인(concatenated index) 다중 컬럼 색인의 가장 일반적인 유형 하나의 컬럼에 다른 컬럼을 추가하는 방식으로 하나의 키에 여러 필드를 단순히 결합다차원 색인 조금 더 일반적인 방법 지리 공간 데이터에 중요하게 사용되지만 여기에 국한되지 않는다. k-d 트리, 사분 트리, R 트리 등B 트리와 LSM 트리 색인에서도 지리 공간을 처리하는 한 가지 방법으로 공간 채움 곡선(space-filling curve)을 이용해 단일 숫자로 변환한 다음 색인에 사용하는 것이 있다.전문 검색과 퍼지 색인지금까지 설명한 색인들은 키의 정확한 값이나 정렬된 키의 값의 범위를 질의할 수 있다고 가정한다.그래서 유사한 키에 대해서 검색을 할 수 없다.이처럼 애매모호한(fuzzy) 질의에는 다른 기술이 필요하다.루씬은 용어 사전을 위해 SS 테이블 같은 구조를 사용한다.인메모리 색인은 키를 찾는 데 필요한 정렬 파일의 오프셋을 질의에 알려주는 데 사용한다.루씬의 인메모리 색인은 여러 키 내 문자에 대한 유한 상태 오토마톤(finite state automaton)으로 트라이(trie)와 유사하다.이 오토마톤은 레벤슈타인 오토마톤(levenshtein automaton)으로 변환할 수 있다.레벤슈타인 오토마톤은 특정 편집 거리 내에서 효율적인 단어 검색을 제공한다.자세한 내용은 관련해서 찾아보자.모든 것을 메모리에 보관지금까지 설명한 데이터 구조는 모두 디스크 한계에 대한 해결책이다.디스크는 메인 메모리와 비교해 다루기 어렵지만, 디스크는 지속성과 가격면에서 장점이 있다.하지만 램이 점점 저렴해져서 기가바이트당 가격 논쟁도 약해지고 여러 장비 간 분산해서 보관할 수도 있다.이런 이유로 인메모리 데이터베이스가 개발됐다.멤캐시드 같은 일부 인메모리 키-값 저장소는 장비가 재시작되면 데이터 손실을 허용하는 캐시 용도로만 사용된다.하지만 다른 인메모리 데이터베이스는 지속성을 목표로 한다.지속성을 달성하는 방법 특수 하드웨어 사용(배터리 전원 공급 RAM 등) 디스크에 변경 사항 로그 기록 디스크에 주기적 스냅샷 다른 장비에 인메모리 상태를 복제하지만 디스크 기반 저장소 엔진도 충분한 메모리를 가진 경우에 OS의 페이지 캐시, 버퍼 캐시를 통해서 디스크에서 읽을 필요가 없다.오히려 인메모리 데이터 구조를 디스크에 저장하기 위한 형태로 부호화하는 오버헤드를 피할 수 있어 더 빠를 수도 있다.디스크 기반 색인으로 구현하기 어려운 데이터 모델을 제공메모리에 모든 데이터를 유지하기 때문에 레디스의 우선순위 큐와 셋 등과 같이 다양한 구조를 구현하기가 비교적 간단하다.안티 캐싱(anti-caching) 접근 방식LRU 알고리즘과 같이 가장 최근에 사용하지 않은 데이터를 메모리에서 디스크로 적제하는 방식도 있다.하지만 여전히 전체 색인이 메모리에 있어야 한다.트랜잭션 처리나 분석?특성OLTPOLAP주요 읽기 패턴적은 수의 레코드, 키 기준 조회레코드에 대한 집계주요 쓰기 패턴임의 접근, 사용자 입력을 낮은 지연 시간으로 기록Bulk import(ETL) 또는 이벤트 스트림주요 사용처애플리케이션을 통한 최종 사용자/소비자의사결정 지원을 위한 내부 분석가데이터 표현데이터의 최신 상태시간이 지나며 일어난 이벤트 이력데이터셋 크기GB - TBTB - PB과거 OLTP 시스템을 분석 목적으로 사용하지 않고 분석을 수행하기 위한 개별 데이터베이스를 데이터 웨어하우스(data warehouse)라고 불렀다.데이터 웨어하우징OLTP 시스템은 대개 사업 운영에 대단히 중요하기 때문에 일반적으로 높은 가용성과 낮은 지연 시간의 트랜잭션 처리를 기대한다.반대로 데이터 웨어하우스는 분석가들이 OLTP 작업에 영향을 주지 않고 마음껏 질의할 수 있는 개별 데이터베이스다.데이터는 OLTP 데이터베이스에서 추출(extract)하고 분석 친화적인 스키마로 변환(transform)하고 깨끗하게 정리한 다음 데이터 웨어하우스에 적재(load)한다.데이터웨어하우스로 데이터를 가져오는 이 과정을 ETL(Extract-Transform-Load)이라 한다.이 형태의 장점은 분석 접근 패턴에 맞게 최적화할 수 있다는 것이다.분석용 스키마: 별 모양 스키마와 눈꽃송이 모양 스키마분석용 스키마 특징 사용하는 데이터 모델의 종류가 많지 않음 대부분 별 모양 스키마(star schema)로 알려진 정형화된 방식 사용또는 차원 모델링(dimentional modeling)이라고도 불림 보통 테이블의 속성(컬럼)이 매우 많음별 모양 스키마 특징 스키마 중심에 사실 테이블(fact table)이 존재 각 로우는 특정 시각에 발생한 이벤트 보통 개별 이벤트를 저장분석의 유연성 극대화 목적이로 인해서 사실 테이블이 매우 커질 수 있음 사실 테이블의 다른 컬럼은 차원 테이블(dimension table)인 다른 테이블을 가리키는 외래 키 참조 차원은 이벤트 속성인 누가, 언제, 어디서, 무엇을, 어떻게, 왜를 나타냄 차원은 차원 테이블의 로우 눈꽃송이 모양 스키마 대비 작업이 쉬워서 보통 분석가들이 더 선호별 모양 스키마 예제눈꽃송이 모양 스키마 특징 별 모양 스키마의 변경 차원이 하위 차원으로 더 세분화 별 모양 스키마 보다 더 정규화 별 모양 스키마 대비 작업이 더 어려움칼럼 지향 저장소사실 테이블(fact table)은 컬럼이 보통 100개 이상이지만 질의는 한 번에 소수의 칼럼만 접근하며 다른 컬럼은 무시한다.이때 100개의 칼럼 중 5개의 칼럼을 사용한 조건에 부합한 로우를 찾는다고 하자로우 지향 방식의 경우, 조건을 처리하기 위해서 색인을 사용하겠지만 부분적으로 색인이 존재하지 않을 수 있다.그러면 모든 로우를 메모리로 적재해 필요한 조건을 충족하지 않은 로우를 필터링해야 한다.이 작업은 오랜 시간이 걸릴 수 있다.위와 같은 경우 컬럼 지향 저장소의 필요성이 부각될 수 있다.칼럼 지향 저장소 특징 모든 값을 하나의 로우에 함께 저장하지 않는다. 대신 각 칼럼별로 모든 값을 함께 저장한다. 각 칼럼 파일에 포함된 로우가 모두 같은 순서인 점에 의존사실 테이블을 컬럼 단위로 저장칼럼 압축칼럼 지향 저장소는 대개 압축에 적합한데, 데이터를 압축하면 디스크 처리 요청을 더 줄일 수 있다.칼럼의 데이터에 따라 다양한 압축 기법을 사용할 수 있다.그 중 한 가지로 데이터 웨어하우스에서 특히 효과적인 비트맵 부호화(bitmap encoding) 이 있다.비트맵 부호화 &amp;amp; 런랭스 부호화 예제메모리 대역폭과 벡터화 처리수백만 로우를 스캔해야 하는 데이터 웨어하우스 질의는 디스크로부터 메모리로 데이터를 가져오는 대역폭이 큰 병목이다.또한 CPU 주기를 효율적으로 사용하도록 신경 써야 한다.칼럼 저장소 배치는 CPU 주기를 효율적으로 사용하기에 적합하다.칼럼 압축을 사용하면 같은 양의 L1 캐시에 컬럼의 더 많은 로우를 저장할 수 있다.AND와 OR 연산자는 압축된 칼럼 데이터 덩어리를 바로 연산할 수 있게 설계할 수 있다.이런 기법을 벡터화 처리(vectorized processing) 라고 한다.칼럼 저장소의 순서 정렬칼럼 저장소는 삽입된 순서로 저장하는 방식이 가장 쉽지만, 순서가 반드시 중요한 것은 아니다.SS테이블에서 했던 것처럼 순서를 도입해 이를 색인 메커니즘으로 사용할 수 있다.장점 질의 최적화기는 모든 로우를 스캔하기보다 범위 질의에 포함되는 로우만 스캔 가능 칼럼 압축에 도움순서 지정은 여러개를 지정할 수 있지만 압축 효과는 첫 번째 정렬 키에서 가장 효과적이다.다양한 순서 정렬상업용 데이터 웨어하우스인 버티가에서 채택데이터를 잃지 않기 위해 데이터를 여러 장비에 복제해 두는 작업이 필요하다.복제 데이터를 서로 다른 방식으로 정렬 해서 저장하고 질의를 처리할 때 질의 패턴에 가장 적합한 버전 을 사용할 수 있다.칼럼 지향 저장소에 쓰기칼럼 지향 저장소, 압축, 정렬은 모두 읽기 질의를 더 빠르게 하지만 쓰기를 어렵게 한다는 단점이 존재정렬된 테이블의 중간에 있는 로우에 삽입을 해야 하면 모든 칼럼 파일을 재작성해야 한다.LSM 트리에서 이런 문제에 좋은 해결책있고 버티카가 채택한 방식이다.모든 쓰기는 먼저 인메모리 저장소(WOS)에서 정렬된 구조에 추가해 디스크(ROS)에 쓸 준비를 한다.충분한 인메모리 저장소 데이터가 모이면 디스크에 추가한다.(Moveout)이렇게 모인 디스크의 데이터는 병합 하고 새로운 파일에 기록 한다.(Mergeout)Vertica의 ROS와 WOS 참고Vertica의 WOS Deprecation 참고집계: 데이터 큐브와 구체화 뷰데이터 웨어하우스 질의는 보통 SQL의 COUNT, SUM, AVG, MIN, MAX 같은 집계 함수를 포함한다.이렇게 자주 사용되는 집계 함수를 캐시를 하기 위해 구체화 뷰(materialized view) 라는 방법을 사용한다.구체화 뷰는 디스크에 기록된 질의 결과의 실제 복사본 이다.복사본이기에 원본 데이터를 변경하면 구체화 뷰를 갱신해야 한다.이런 갱신 비용이 비싸기 때문에 OLTP 데이터베이스에서는 자주 사용하지 않는다.데이터 웨어하우스는 읽기 비중이 크기 때문에 구체화 뷰를 사용하는 전략은 합리적이다.여기서 이야기할 데이터 큐브(data cube) 또는 OLAP 큐브라고 알려진 구체화 뷰는 일반화된 구체화 뷰의 특별 사례다.합으로 데이터를 집계한 2차원 데이터 큐브예제는 2차원이지만 일반적으로 2차원 이상이다.구체화 데이터 큐브 장점은 특정 질의를 미리 계산했기 때문에 해당 질의를 수행할 때 매우 빠름 단점은 원시 데이터에 질의하는 것과 동일한 유연성이 없다는 점" }, { "title": "DDIA - 데이터 모델과 질의 언어", "url": "/posts/DDIA-CH2/", "categories": "Study, Book", "tags": "Data, Applicationn, System", "date": "2022-05-06 00:00:00 +0900", "snippet": "Table of Contents 들어가기 관계형 모델과 문서 모델 객체 관계형 불일치 다대일과 다대다 관계 문서 데이터베이스는 역사를 반복하고 있나? 네트워크 모델 관계형 모델 문서 데이터베이스와의 비교 관계형 데이터베이스와 오늘날의 문서 데이터베이스 어떤 데이터 모델이 애플리케이션 코드를 더 간단하게 할까? 문서 모델에서의 스키마 유연성 질의를 위한 데이터 지역성 문서 데이터베이스와 관계형 데이터베이스의 통합 데이터를 위한 질의 언어 웹에서의 선언형 질의 맵리듀스 질의 그래프형 데이터 모델 속성 그래프 사이퍼 질의 언어 SQL의 그래프 질의 트리플 저장소와 스파클 스파클 질의 언어 그래프 데이터베이스와 네트워크 모델의 비교 초석: 데이터로그 정리들어가기계층 모델, 관계형 모델, 문서 데이터베이스, 그래프 데이터베이스데이터 모델은 소프트웨어 개발에서 중요한 부분이다. 소프트웨어가 어떻게 작성될지문제를 어떻게 생각해야 하는지에 대해 지대한 영향 각 계층은 명확한 데이터 모델을 제공해 하위 계층의 복잡성을 추상화이런 추상화는 다른 그룹의 사람들이 효율적으로 함께 일할 수 있게끔 함 다양한 유형의 데이터 모델이 존재각 데이터 모델은 사용 방법에 대한 가정을 나타냄 소프트웨어가 할 수 있는 일과 할 수 없는 일에 영향그래서 목적에 적합한 데이터 모델을 선택하는 일은 상당히 중요하다.이제 각 데이터 모델과 질의 언어를 살펴보고 영역별 장단점을 알아본다.이를 통해서 우리는 적합한 데이터 모델을 선택하는 한 척도를 살펴볼 수 있다.관계형 모델과 문서 모델객체 관계형 불일치 임피던스 불일치데이터를 관계형 테이블에 저장하려면 애플리케이션 코드와 데이터베이스 모델 객체 사이에 거추장스러운 전환 계층이 필요하다.이렇듯 데이터베이스 모델과 프로그래밍 언어 모델과의 차이로 인해서 발생하는 문제들을 말하는 단어이다.예제로 나온 이력서를 표현하는 경우사람별로 경력에 넣을 직업이 여러개이며 학력 기간과 연락처 정보도 다양하다.이런 항목들은 일대다 관계이다.관계형 데이터베이스 는 이 관계를 다양한 방법으로 나타낼 수 있다. 관계형 데이터베이스의 일반적인 방법으로 정규화 표현 구조화된 데이터타입과 XML 데이터 사용(SQL 최신 버전) JSON, XML문서로 부호화해 텍스트 컬럼에 저장 -&amp;gt; 애플리케이션에서 처리이력서 같은 데이터 구조는 모든 내용을 갖추고 있는 문서라서 JSON 표현에 매우 적합하다.문서 지향 데이터베이스 는 JSON 데이터 모델을 지원한다.JSON 모델이 임피던스 불일치를 줄인다고 생각하지만, 데이터 부호화 형색으로서 JSON이 가진 문제도 있다.JSON 표현은 관계형 데이터베이스의 다중 테이블 스키마보다 더 나은 지역성을 갖는다.다대일과 다대다 관계데이터베이스 모델에 실제 문자열이 아닌 ID로 주어지는 경우가 있다.ID로 주어진 경우 연관된 테이블에서 조인을 통해서 실제 데이터를 해결한다.ID나 텍스트 문자열의 저장 여부는 중복의 문제다.쓰기 오버헤드와 불일치ID를 사용하는 장점 은 ID 자체는 아무런 의미가 없기 때문에 변경할 필요가 없다.의미를 가지는 경우라면 미래에 언젠가는 변경해야 할 수도 있다.이런 중복을 제거하는 일이 데이터베이스의 정규화 이면에 놓인 핵심 개념이다.중복된 데이터를 정규화하려면 다대일 관계가 필요하지만 문서 모델 에서 다대일 관계는 적합하지 않다. 관계형 데이터베이스조인이 쉽기 때문에 ID로 다른 테이블의 로우를 참조하는 방식은 일반적 문서 데이터베이스일대다 트리 구조를 위해 조인이 필요하지 않지만 조인에 대한 지원이 보통 약하다.데이터베이스 자체에서 조인을 지원하지 않으면 데이터베이스에 대한 다중 질의를 만들어서 애플리케이션 코드에서 조인을 흉내내야 한다.또한 애플리케이션 초기 버전이 조인 없는 문서 모델에 적합하더라도 애플리케이션에 기능을 추가하면서 데이터는 점차 상호 연결되는 경향이 있다.문서 데이터베이스는 역사를 반복하고 있나?1970년대 IBM의 정보 관리 시스템(IMS)는 계층 모델 이라 부르는 상당히 간단한 데이터 모델을 사용했다.계층 모델은 문서 데이터베이스에서 사용하는 JSON 모델과 놀랍게도 비슷하다.문서 데이터베이스처럼 IMS도 일대다 관계에서 잘 동작하며, 다대다 관계 표현은 어려웠고 조인은 지원하지 않았다.계층 모델의 한계를 해결하기 위해 다양한 해결책이 제안됐다. 관계형 모델 네트워크 모델네트워크 모델코다실이라 불리는 위원회에서 표준화했다.레코드 간 연결은 외래 키보다는 프로그래밍 언어의 포인터와 더 비슷하다.레코드에 접근하는 유일한 방법은 접근 경로 로 불리며최상위 레코드에서부터 연속된 연결 경로를 따르는 방법이다.수동 접근 경로 선택은 1970년대에는 매우 제한된 하드웨어 성능을 가장 효율적으로 사용할 수 있었지만데이터베이스 질의와 갱신을 위한 코드가 복잡하고 유연하지 못한 문제가 있었다.관계형 모델단순히 튜플(로우)의 컬렉션이 전부다.얽히고설킨 중첩 구조와 데이터를 찾을 때 따라가야 할 복잡한 접근 경로가 없다.질의 최적화기(Query Optimizer)는 질의의 어느 부분을 어떤 순서로 실행할지를 결정하고 사용할 색인을 자동으로 결정한다.이 선택이 실제로 접근 경로 다.하지만 큰 차이점은 접근 경로를 애플리케이션 개발자가 아니라 질의 최적화기가 자동으로 만든다는 점 이다.새로운 방식으로 데이터를 질의하고 싶은 경우, 새로운 색인을 선언하기만 하면된다.관계형 모델은 애플리케이션에 새로운 기능을 추가하는 작업이 훨씬 쉽다.문서 데이터베이스와의 비교계층 모델과 유사한 점 문서 데이터베이스는 별도의 테이블이 아닌 상위 레코드 내에 중첩된 레코드를 저장계층 모델과 다른 점 다대일과 다대다 관계를 표현할 때 관계형 데이터베이스와 문서형 데이터베이스는 근본적으로 다르지 않다.둘 다 관련 항목은 고유한 식별자로 참조(관계형 모델 = 외래키, 문서 모델 = 문서 참조)관계형 데이터베이스와 오늘날의 문서 데이터베이스데이터 모델의 차이점에만 집중해서 보자. 문서 데이터 모델을 선호하는 이유 스키마 유연성 지역성에 기인한 더 나은 성능 일부 애플리케이션의 경우 애플리케이션에서 사용하는 데이터 구조와 더 가깝기 때문 관계형 모델을 선호하는 이유 조인, 다대일, 다대다 관계를 더 잘 지원함 어떤 데이터 모델이 애플리케이션 코드를 더 간단하게 할까?문서 모델이 더 간단한 경우 애플리케이션의 데이터가 문서와 비슷한 구조일 경우 문서가 너무 깊게 중첩되지 않는 경우(일반적으로)문서 모델은 문서 내 중첩 항목을 바로 참조할 수 없는 제한이 있다. 다대다 관계가 필요 없는 경우미흡한 조인 지원은 애플리케이션에 따라 문제가 아닐 수도 있다.애플리케이션에서 다대다 관계를 사용한다면 문서모델은 매력이 떨어진다.비정규화로 조인의 필요성 줄이기가 가능하지만 애플리케이션 코드에서 추가적인 작업이 필요해진다.이런 경우 문서 모델을 사용해서 더 복잡한 애플리케이션 코드와 나쁜 성능으로 이어질 수 있다.일반적으로 어떤 데이터 모델이 애플리케이션 코드를 더 간단하게 만드는지 말할 수 없다.데이터 항목 간에 존재하는 관계 유형에 따라 다르다.상호 연결이 많은 데이터의 경우 관계형 모델은 무난하며 그래프 모델은 매우 자연스럽다.문서 모델에서의 스키마 유연성보통 문서 데이터베이스와 관계형 데이터베이스에서 지원하는 JSON은 문서의 데이터에 어떤 스키마를 강요하지 않는다.보통 관게형 데이터베이스에서 제공하는 XML은 선택적으로 스키마 유효성 검사를 포함할 수 있다.문서 데이터베이스는 종종 스키마리스(schemaless)로 불리지만 이는 오해의 소지가 있다.데이터를 읽는 코드는 보통 구조의 유형을 어느 정도 가정한다.즉, 암묵적인 스키마가 있지만 데이터베이스는 이를 강요하지 않는다. 쓰기 스키마(schema-on-write)스키마는 명시적이고 데이터베이스는 쓰여진 모든 데이터가 스키마를 따르고 있음을 보장 읽기 스키마(schema-on-read)암묵적이고 데이터를 읽을 때만 해석된다.출처 : https://www.oreilly.com/content/hadoop-what-you-need-to-know이런 접근 방식 차이는 애플리케이션이 데이터 타입을 변경하고자 할 때 특히 뚜렷이 나타난다. 문서 데이터베이스애플리케이션에서 예전 문서를 읽은 경우 처리하는 코드만 있으면 된다. “정적 타입”의 데이터베이스(RDB 등)마이그레이션 작업 필요읽기 스키마 접근 방식은 컬렉션 안의 항목이 어떤 이유로 모두 동일한 구조가 아닐 때 유리하다.질의를 위한 데이터 지역성자주 전체 문서에 접근해야 할 때 저장소 지역성(storage locality) 을 활용하면 성능 이점이 있다. 디스크 탐색이 적게 필요함지역성의 이점은 한 번에 해당 문서의 많은 부분을 필요로 하는 경우에만 적용된다. 적은 부분만 접근해도 전체 문서를 적재해야 함. 문서를 갱신할 때도 보통 전체 문서를 재작성해야 함. (부호화된 문서의 크기를 바꾸지 않는 수정은 쉽게 수행)이런 이유로 일반적으로 문서를 아주 작게 유지하면서 문서의 크기가 증가하는 쓰기를 피하라고 권장한다.지역성을 위해 관련 데이터를 함께 그룹화하는 개념이 문서 모델에만 국한되지 않는다. 구글의 스패너 데이터베이스 오라클의 다중 테이블 색인 클러스터 테이블(multi-table index cluster table) 빅테이블 데이터모델의 컬럼 패밀리(column-family) 개념문서 데이터베이스와 관계형 데이터베이스의 통합두 데이터베이스는 시간이 지남에 따라 점점 더 비슷해지고 있다.데이터를 위한 질의 언어SQL은 선언형 질의언어, IMS와 코다실은 명령형 코드로 질의 한다.일반적으로 많이 사용하는 프로그래밍 언어가 명령형 언어다. function getSharks() { var sharks = []; for (var i = 0; i &amp;lt; animals.length; i++) { if (animals[i].family === &quot;Sharks&quot;) { sharks.push(animals[i]); } } return sharks; }SQL은 관계 대수의 구조를 상당히 유사하게 따랐다. SELECT * FROM animals WHERE family = &#39;Sharks&#39;;SQL이나 관계 대수 같은 선언형 질의 언어는 목표를 달성하기 위한 방법이 아니라알고자 하는 데이터의 패턴, 즉 결과가 충족해야 하는 조건과 데이터를 어떻게 변환할지를 지정하기만 하면 된다.또한 질의의 다양한 부분을 질의 최적화기 가 처리한다.선언형 언어는 간결하고 쉽게 작업할 수 있다.중요한 점 은 데이터베이스 엔진의 상세 구현이 숨겨져 있어,질의를 변경하지 않고도 데이터베이스 시스템의 성능을 향상시킬 수 있다는 점이다.선언형 언어인 SQL은 기능적으로 더 제한적이다.이러한 사실은 데이터베이스가 최적화할 수 있는 여지를 더 많이 준다 는 의미다.선언형 언어는 종종 병렬 실행에 적합 하다.결과를 결정하기 위한 알고리즘을 지정하는 게 아니라 결과의 패턴만 지정하기 때문에 병렬 실행으로 더 빨라질 가능성이 크다.웹에서의 선언형 질의선언형 질의 언어의 장점은 데이터베이스에만 국한되지 않는다.CSS와 XSL이 문서의 스타일을 지정하기 위한 선언형 언어이다.스타일을 적용하려는 엘리멘트의 패턴을 선언하면 된다.명령형인 자바스크립트에서 DOM API를 사용했을 때 보다 코드량이 상당히 줄어들 뿐만 아니라 여러 가지 문제들을 해결해준다.맵리듀스 질의많은 컴퓨터에서 대량의 데이터를 처리하기 위한 프로그래밍 모델이다.많은 문서를 대상으로 읽기 전용 질의를 수행할 때 사용한다.선언형 질의 언어로 완전한 명령형 질의 API도 아닌 그 중간 정도에 있다.질의 로직은 처리 프레임워크가 반복적으로 호출하는 조각 코드로 표현한다.여러 프로그래밍 언어에 있는 map과 reduce 함수를 기반으로 한다.SQL과 비교해보자면 아래와 같다. SELECT date_trunc(&#39;month&#39;, observation_timestamp) AS observation_month, sum(num_animals) AS total_animals FROM observations WHERE family = &#39;Sharks&#39; GROUP BY observation_month;위의 SQL을 몽고DB의 맵리듀스 기능을 이용해 다음과 같이 표현할 수 있다. db.observations.mapReduce( function map() { var year = this.observationTimestamp.getFullYear(); var month = this.observationTimestamp.getMonth() + 1; emit(year + &quot;-&quot; + month, this.numAnimals); }, funcation reduce(key, values) { return Array.sum(values); }, { query: { family: &quot;Sharks&quot; }, out: &quot;monthlySharkReport&quot; } );몽고DB의 map과 reduce 함수는 수행할 때 약간의 제약 사항이 있다. 두 함수는 순수(pure) 함수즉, 입력으로 전달된 데이터만 사용 추가적인 데이터베이스 질의를 수행할 수 없다. 부수 효과가 없어야 한다.이런 제약 사항 때문에 데이터베이스가 임의 순서로 어디서나 이 함수를 실행할 수 있고 장애가 발생해도 함수를 재실행할 수 있다.맵리듀스는 클러스터 환경에서 분산 실행을 위한 저수준 프로그래밍 모델하지만 맵리듀스를 사용하지 않은 분산 SQL 구현도 많다.SQL이 단일 장비에서 수행해야 하는 제한이 없으며 맵리듀스가 분산 질의 실행에 대한 독점권을 가진 것도 아니다. 질의 중간에 자바스크립트 코드를 사용할 수 있다는 점은 고급 질의가 가능한 훌륭한 기능하지만 일부 SQL 데이터베이스도 자바스크립트 함수로 확장될 수 있다.몽고DB의 집계 파이프라인(aggregation pipeline) 선언형 질의 언어 지원 이유 맵리듀스의 사용성 문제 는 map과 reduce 함수를 신중하게 작성해야 한다이는 종종 하나의 질의를 작성하는 것보다 어렵다. 선언형 질의 언어는 질의 최적화기가 질의 성능을 높일 수 있는 기회를 제공집계 파이프라인 언어 표현 측면에서 SQL의 부분 집합과 유사 JSON 기반 구문을 사용(SQL의 영어 문장 스타일 구문과 달리)그래프형 데이터 모델다대다 관계가 매우 일반적이라면,관계형 모델이 단순한 다대다 관계를 다룰 수 있다.데이터 간 연결이 복잡해지면 그래프로 데이터를 모델링하는 편이 더 자연스럽다.그래프는 두 유형의 객체로 이뤄진다. 정점(vertex) = 노드나 엔티티라고도 한다. 간선(edge) = 관계나 호(arc)라고도 한다.일반적으로 그래프 상에서 동작하는 알고리즘은 “자동차 내비게이션 시스템”, “페이지랭크”가 있다.그래프 모델 속성 그래프 모델 : Neo4j, Titan InfiniteGraph 트리플 저장소 모델 : Datomic, Allegrograph그래프용 질의 언어 선언형 질의 언어 : Cypher, SPARQL, Datalog 명령형 질의 언어 : Gremlin그래프 처리 프레임워크 Pregel가 있다.지금부터 속성 그래프 모델, 트리플 저장소 모델, 선언형 질의 언어들에 대해서 살펴본다.아래 그림은 설명에서 사용하는 데이터 예제그림 1출처 : https://oracle-patches.com/en/databases/graph-like-data-models-full-description-with-examples속성 그래프정점을 구성하는 요소 고유한 식별자 유출(outgoing) 간선 집합 유입(incoming) 간선 집합 속성 컬렉션(키-값 쌍)간선을 구성하는 요소 고유한 식별자 간선이 시작하는 정점(꼬리 정점) 간선이 끝나는 정점(머리 정점) 두 정점 간 관계 유형을 설명하는 레이블 속성 컬렉션(키-값 쌍)두 개의 관계형 테이블로 구성된 그래프 저장소를 생각해보면 아래와 같다.예제 1 관계형 스키마를 사용해 속성 그래프 표현 CREATE TABLE vertices ( vertex_id integer PRIMARY KEY, properties json ); CREATE TABLE edges ( edge_id integer PRIMARY KEY, tail_vertex integer REFERENCES vertices (vertex_id), head_vertex integer REFERENCES vertices (vertex_id), label text, properties json ); CREATE INDEX edges_tails ON edges (tail_vertex); CREATE INDEX edges_heads ON edges (head_vertex);이 모델의 중요한 점 정점은 다른 정점과 간선으로 연결특정 유형과 관련 여부를 제한하는 스키마가 없다. 정점이 주어지면 정점의 유입과 유출 간선을 효율적으로 찾고 그래프를 순회 다른 유형의 관계는 서로 다른 label을 사용단일 그래프에 다른 유형의 정보를 저장하면서 데이터 모델을 깔끔하게 유지그림 1과 같이 위의 기능을 통해 그래프는 데이터 모델링을 위한 많은 유연성을 제공한다.또한 그래프는 발전성이 좋아서 데이터 구조 변경을 수용하게끔 그래프를 쉽게 확장할 수 있다.사이퍼 질의 언어속성 그래프를 위한 선언형 질의 언어그림 1을 데이터의 일부를 사이퍼 질의로 표현CREATE (NAmerica:Location {name:&#39;North America&#39;, type:&#39;continent&#39;}), (USA:Location {name:&#39;United States&#39;, type:&#39;country&#39; }), (Idaho:Location {name:&#39;Idaho&#39;, type:&#39;state&#39; }), (Lucy:Person {name:&#39;Lucy&#39; }), (Idaho) -[:WITHIN]-&amp;gt; (USA) -[:WITHIN]-&amp;gt; (NAmerica), (Lucy) -[:BORN_IN]-&amp;gt; (Idaho)예제 2 미국에서 유럽으로 이민 온 사람을 찾는 사이퍼 질의MATCH (person) -[:BORN_IN]-&amp;gt; () -[:WITHIN*0..]-&amp;gt; (us:Location {name:&#39;United States&#39;}), (person) -[:LIVES_IN]-&amp;gt; () -[:WITHIN*0..]-&amp;gt; (eu:Location {name:&#39;Europe&#39;})RETURN person.name위의 질의는 다음과 같은 의미다. person은 어떤 정점을 향하는 BORNIN 유출 간선을 가진다.이 정점에서 name 속성이 “United States”인 Location 유형의 정점에 도달할 때까지 일련의 WITHIN 유출 간선을 따라간다. 같은 person 정점은 LIVESIN 유출 간선도 가진다.이 간선과 WITHIN 유출 간선을 따라가면 결국 name 속성이 “Europe”인 Location 유형의 정점에 도달하게 된다.질의를 실행하는 데는 여러 가지 방법이 있다.(책 참고)하지만 선언형 질의 언어는 질의 최적화기가 효율적이라고 예측한 전략을 자동으로 선택하므로 보통 수행에 대해 자세히 지정할 필요가 없다.SQL의 그래프 질의예제 1에서 관계형 데이터베이스에서 그래프 데이터를 표현했다.그렇다면 그래프 데이터를 관계형 구조로 넣어도 SQL을 사용해서 질의할 수 있을까?가능은 하지만 어렵다.관계형 데이터베이스에서는 보통 질의에 필요한 조인을 미리 알고 있지만그래프 질의에서는 정점을 찾기 위해 가변적인 여러 간선을 순회해야 한다.즉, 조인 수를 고정할 수 없다.문제는 위의 사이퍼 질의에서 () - [:WITHIN*0..]-&amp;gt; () 문에 있다.이는 0회 이상 WITHIN 간선을 따라가라는 의미다. &amp;lt;– 가변적인 여러 간선을 순회SQL:1999 이후로 가변 순회 경로에 대한 질의 개념은 재귀 공통 테이블 식(recursive common table expression)(WITH RECURSIVE 문)을 사용해서 표현할 수 있다. WITH RECURSIVE -- in_usa는 미국 내 모든 지역의 정점 ID 집합이다. in_usa(vertex_id) AS ( SELECT vertexid FROM vertices WHERE properties-&amp;gt;&amp;gt;&#39;name&#39; = &#39;United States&#39; UNION SELECT edges.tail_vertex FROM edges JOIN inusa ON edges.head_vertex = in_usa.vertex_id WHERE edges.label = &#39;within&#39; ), -- in_europe은 유럽 내 모든 지역의 정점 ID 집합이다. in_europe(vertex_id) AS ( SELECT vertexid FROM vertices WHERE properties-&amp;gt;&amp;gt;&#39;name&#39; = &#39;Europe&#39; UNION SELECT edges.tail_vertex FROM edges JOIN ineurope ON edges.head_vertex = in_europe.vertex_id WHERE edges.label = &#39;within&#39; ), -- born_in_usa는 미국에서 태어난 모든 사람의 정점 ID 집합이다. born_in_usa(vertex_id) AS ( SELECT edges.tail_vertex FROM edges JOIN inusa ON edges.head_vertex = in_usa.vertex_id WHERE edges.label = &#39;born_in&#39; ), -- lives_in_europe은 유럽에서 태어난 모든 사람의 정점 ID 집합이다. lives_in_europe(vertex_id) AS ( SELECT edges.tail_vertex FROM edges JOIN ineurope ON edges.head_vertex = in_europe.vertex_id WHERE edges.label = &#39;lives_in&#39; ) SELECT vertices.properties-&amp;gt;&amp;gt;&#39;name&#39; FROM vertices -- 미국에서 태어나 유럽에서 자란 사람을 찾아 조인 JOIN bornin_usa ON vertices.vertex_id = born_in_usa.vertex_id JOIN livesin_europe ON vertices.vertex_id = lives_in_europe.vertex_id;사이퍼 질의 대비 SQL은 매우 길다.이는 다양한 데이터 모델이 서로 다른 사용 사례를 지원하기 위해 설계됐다는 것을 보여준다.따라서 애플리케이션에 적합한 데이터 모델을 선택하는 작업은 중요 하다.트리플 저장소와 스파클속성 그래프 모델과 거의 동일하다.같은 개념을 다른 용어를 사용한다.모든 정보를 (주어(subject), 서술어(predicate), 목적어(object)) 처럼 매우 간단한 세 부분 구문 형식으로 저장한다. 트리플의 주어는 그래프의 정점과 동등하다. 목적어는 다음과 같다. 문자열이나 숫자 같은 원시 데이터 값트리플의 서술어와 목적어는 주어 정점의 속성의 키, 값과 동등 그래프의 다른 정점서술어는 그래프의 간선주어는 꼬리 정점목적어는 머리 정점 그림1의 일부를 Turtle 트리플로 표현@prefix : &amp;lt;urn:example:&amp;gt;._:lucy a :Person._:lucy :name &quot;Lucy&quot;._:lucy :bornIn _:idaho._:idaho a :Location._:idaho :name &quot;Idaho&quot;._:idaho :type &quot;state&quot;._:idaho :within :usa._:usa a :Location._:usa :name &quot;United States&quot;._:usa :type &quot;country&quot;._:usa :within :namerica._:namerica a :Location._:namerica :name &quot;North America&quot;._:namerica :type &quot;continent&quot;. _:주어 서술어 목적어 형식 정점은 _:someName 형식 목적어가 원시 데이터인 경우_:lucy :name “Lucy”:name은 속성 키, “Lucy”는 속성 값 목적어가 다른 정점인 경우_:idaho :within :usa:within은 간선스파클 질의 언어RDF 데이터 모델을 사용한 트리플 저장소 질의 언어예제2와 동일한 질의를 스파클로 표현PREFIX : &amp;lt;urn:example:&amp;gt;SELECT ?personName WHERE { ?person :name ?personName. ?person :bornIn / :within* / :name &quot;United States&quot;. ?person :livesIn / :within* / :name &quot;Europe&quot;.}스파클에서 변수는 물음표로 시작사이퍼와 비교하면 아래와 같이 두 표현식이 동등 (person) -[:BORNIN]-&amp;gt; () -[:WITHIN*0..]-&amp;gt; (location) #사이퍼?person :bornIn / :within* ?location. #스파클 (usa {name:’United States’}) #사이퍼?usa :name “United States”. #스파클그래프 데이터베이스와 네트워크 모델의 비교코다실의 네트워크 모델과 그래프 데이터베이스는 몇 가지 중요한 차이점이 있다. 코다실은 다른 레코드 타입과 중첩 가능한 레코드 타입을 지정하는 스키마가 존재그래프 데이터베이스는 제약 없음 코다실에서 특정 레코드에 도달하는 유일한 방법은 접근 경로를 탐색하는 방식그래프 데이터베이스는 고유 ID를 가지고 임의 정점을 직접 참조 OR 색인을 사용해 빠르게 검색 코다실에서 레코드의 하위 항목은 정렬된 집합그래프 데이터베이스에서 정점과 간선은 정렬하지 않음, 질의 결과를 정렬할 수 있음 코다실은 모든 질의는 명령형그래프 데이터베이스는 명령형과 선언형 질의 모두 제공초석: 데이터로그오래된 언어이지만 이후 질의 언어의 기반이 되는 초석을 제공데이터로그의 데이터 모델은 트리플 저장소 모델과 유사하지만 조금 더 일반화서술어(주어, 목적어) 형식그림1의 일부데이터를 데이터로그 fact로 표현name(namerica, &#39;North America&#39;).type(namerica, continent).name(usa, &#39;United States&#39;).type(usa, country).within(usa, namerica).name(idaho, &#39;Idaho&#39;).type(idaho, state).within(idaho, usa).name(lucy, &#39;Lucy&#39;).born_in(lucy, idaho)예제2와 동일한 질의를 데이터로그로 표현within_recursive(Location, Name) :- name(Location, Name). /* Rule 1 */within_recursive(Location, Name) :- within(Location, Via), /* Rule 2 */ within_recursive(Via, Name).migrated(Name, BornIn, LivingIn) :- name(Person, Name), /* Rule 3 */ born_in(Person, BornLoc), within_recursive(BornLoc, BornIn), lives_in(Person, LivingLoc), within_recursive(LivingLoc, LivingIn).?- migrated(Who, &#39;United States&#39;, &#39;Europe&#39;)./* Who = &#39;Lucy&#39;. */사이퍼와 스파클은 SELECT로 바로 질의하는 반면데이터로그는 단계를 나눠 데이터베이스에 전달하는 규칙을 정의한다. :- 연산자의 오른편에 있는 모든 서술어를 찾으면 규칙이 적용 :- 연산자의 왼편은 데이터베이스에 추가됨(변수는 대응된 값으로 대체)Rule 적용 과정이제 rule 3을 적용해서 최종적으로 남은 사람이 결과가 된다데이터로그 접근 방식은 이전에 설명한 질의 언어와는 다른 사고가 필요하지만 규칙을 결합하거나 재사용할 수 있기 때문에 매우 강력한 접근 방식이다.데이터가 복잡하면 더 효과적으로 대처할 수 있다.정리역사적으로 데이터를 하나의 큰 트리(계층 모델)로 표현하려고 노력했지만 다대다 관계를 표현하기에는 트리 구조가 적절하지 않았다.이 문제를 해결하기 위해 *관계형 모델*이 고안됐다.최근 관계형 모델에도 적합하지 않은 애플리케이션이 있다는 사실을 발견 했고 나온 것이 NoSQL이다.NoSQL은 다음 두 가지 주요 갈래가 있다. 문서 데이터베이스 그래프 데이터베이스한 모델은 다른 모델로 흉내 낼 수 있지만 위에서 확인 했다 싶이 사용이 어렵거나 애플리케이션에서 해결을 해야 하는 등 문제점이 있다.이것이 바로 단일 만능 솔루션이 아닌 각기 목적에 맞는 다양한 시스템을 보유해야 하는 이유다." }, { "title": "Redis - transaction", "url": "/posts/redis-transaction/", "categories": "Study", "tags": "redis, transaction", "date": "2022-04-29 00:00:00 +0900", "snippet": "Table of Contents 사용법 Transaction에서의 Error 왜 Redis는 Roll back을 지원하지 않나? Discarding the command queued Optimistic locking using check-and-set WATCH explained Using WATCH to implement ZPOP Origin DocumentMULTI, EXEC, DISCARD, WATCH 명령어가 Transation 관련 기반이되는 명령어들이다.Transaction은 여러 명령으로 구성된 그룹의 실행을 하나의 단계와 같이 실행해준다.그리고 다음 2가지를 보장한다. Transaction 안에 모든 명령어들은 순서가 있으며, 순차적으로 수행된다.Redis Transaction의 수행 중에 다른 client로 부터 발생한 요청을 처리하지는 않는다.즉, 명령어들을 하나의 동릭된 Operation으로서 실행된다. 모두 실행되거나 하나도 수행되지 않는다. 그래서 Redis Transation은 원자성을 가진다.EXEC 명령이 Transation 안의 모든 명령을 수행을 시작하도록 한다.MULTI를 수행하기 전에 Transaction context 안에서 client가 server와의 연결이 끊긴다면 모든 Operations은 수행되지 않는다.하지만, EXEC 명령이 호출된다면, 모든 Operations은 수행된다.append-only 파일을 사용할 때, Redis는 Transaction을 disk로 쓰기위해서 단일 write syscall을 사용한다.하지만, 만약에 Redis 서버가 크래쉬가 되거나, 관리자에 의해서 종료된다면, Operations 중의 일부만이 실행될 수 있다.Redis는 이러한 상태(Operation이 일부만 실행된 상태?)를 재시작시에 발견할것이고 에러와 함께 종료할것이다.redis-check-aof tool을 사용해서 서버를 다시 재시작 가능한데, 이는 부분적 transation을 제거해서 append only 파일을 고치는 것이다.버전 2.2에서 부터 Redis는 위의 두가지에 대해서 추가적인 보장을 제공한다. check-and-set(CAS) Operation과 매우 유사한 방법으로 Optimistic locking의 형태를 제공한다.해당 내용은 뒤에서 다루도록 한다.사용법Reids Transaction은 MULTI 명령어를 사용해서 진입한다. 해당 명령어는 항상 OK로 대답한다.이 때 사용자는 여러 명령어를 호출할 수 있다. 호출한 명령어들은 실행되는 대신에 해당 명령어들을 queue에 담아둔다.모든 명령어들은 EXEC 명령어가 호출되면 수행된다.EXEC 명령어 호출하는 대신 DISCARD 명령어를 호출하면, 해당 queue를 비우고 해당 Transaction은 종료된다.다음 예제는 foo와 bar 키를 원자적으로 증가 시킨다.&amp;gt; MULTIOK&amp;gt; INCR fooQUEUED&amp;gt; INCR barQUEUED&amp;gt; EXEC1) (INTEGER) 12) (INTEGER) 1위의 예제에서 보시다시피, EXEC는 결과들을 돌려준다. 각 결과들은 transaction안의 단일 명령의 결과 값이다. 결과들은 명령이 호출된 순서와 동일하다Redis connection이 MULTI 명령어 요청의 context 안에 있다면, 모든 명령어들은 QUEUED 문자열로 응답한다.Queue에 들어간 명령어들은 EXEC 명령어가 호출됐을 때, 실행되기 위해서 예약된 상태이다.Transaction에서의 ErrorTransaction 동안에 2가지 종류의 Command Error가 발생할 수 있다. Command가 Queue에 넣는것이 실패할수 있으며, 그럴 경우에 EXEC가 호출되기 전에 Error가 발생한다.예를들어서 Command가 문법적으로 틀렸거나 메모리 부족과 같은 심각한 상태 때문일수도 있다. Command가 EXEC를 호출하고 실해할수 있다. 예를들어서 Key에 대해서 잘못된 Value와 함께 실행시킨 경우이다.EXEC 호출 전에 일어나는 첫번째 종류의 Error는 Queue넣는 Command의 결과값을 확인하므로써 확인할수 있을 것이다.만약에 해당 Command가 QUEUED로 응답한다면, 이것은 정확히 Queue에 들어간것이다. 반대의 경우네는 Error를 반환한다.Command를 Queue에 넣는 동안에 Error가 발생한다면, 대부분의 클라이언트들은 에러가 발생한 Transaction을 종료할것이다.하지만 Redis 2.6.5에서부터 서버는 Commands를 쌓는 동안에 발생한 Error를 기억한다. 그리고 EXEC가 수행되는 동안에 해당 Transaction이 실행되는 것을 막고, 해당 Transaction을 자동적으로 폐기 처리한다.Redis 2.6.5 이전에는 바로 전에 발생한 Error에도 불구하고 EXEC를 호출하면 성공적으로 Queue에 쌓여있는 Command들의 부분집합만 가지고 정상적으로 Transaction을 실행한다.이러한 새로운 행동은 Pipeline으로 Transaction을 섞어 사용하는것을 보다 간단하게 만들어준다. 그래서 이후에 전체 결과를 확인할 필요없이 전체 Transaction을 한번에 보낼수 있게 됐다.대신에 EXEC 이후에 발생한 Error들은 특별한 방법으로 다뤄지지 않는다: 어떤 Command가 Transaction 동안 싫패하더라도 그외 다른 Command들은 모두 실행된다.이것이 Protocol 단계에서 보다 명확하다. 다음 예제는 문법이 맞는데도 불구하고 하나의 명령이 실행중에 실패한다.Trying 127.0.0.1...Connected to localhost.Escape character is &#39;^]&#39;.MULTI+OKSET a abc+QUEUEDLPOP a+QUEUEDEXEC*2+OK-ERR Operation against a key holding the wrong kind of valueEXEC는 2가지 요소의 Bulk string reply를 반환했다. 하나는 OK 다른 하나는 -ERR 응답.이렇게 에러를 센스있게 사용자에게 보여주는것은 전적으로 client library의 몫이다.Command가 실패하더라도 Queue에 있는 모든 다른 명령들이 수행된다는 것을 알아두는것이 매우 중요하다.Redis는 Command들을 처리하는것을 멈추지 않는다.또 다른 예제는 문법 에러가 어떻게 바로 보여지는지 보여준다.MULTI+OKINCR a b c-ERR wrong number of arguments for &#39;incr&#39; command이번에는 문법문제로 인해서 INCR Command는 Queue에 들어가지 않는다.왜 Redis는 Roll back을 지원하지 않나?Redis는 Transaction 중에 명령이 실패할수 있지만, Redis는 Rollback 대신에 나머지 Transaction을 실행한다는 사실이 RDB에 대한 지식이 있는 사람의 입장에서는 매우 이상하게 보일수가 있다.하지만 이러한 행동에 대한 2가지 매우 좋은 의견이 있다. Redis Commands는 잘못된 문법으로 호출됐을 경우나 Key에 대해서 잘못된 Data Type을 가진 경우에만 실패할수 있다(그리고 그 문제는 Command가 Queue에 들어가는 동안에는 발견한수 없다) : 이것은 실제로 Command가 실패하는 것은 프로그래밍 Error의 결과 이고 이런 종류의 에러는 개발 단계에서 발견하기 매우 쉬워진다. Redis는 내부적으로 간단하고 빠르다. 이는 Redis가 Rollback을 하지 않아도 되서 가능하다.Redis에 대한 논쟁들은 위의 Bugs(위의 2가지는 Redis의 스펙 같으나, 해당 부분을 이해하지 못 하고 발생했을때 Bug라고 지칭한듯)들이 발생했을 경우들인다.하지만, 일반적인 경우에서는 Roll back이 Programming Error로부터 당신을 구해줄수 없다는 것을 알아야 한다.예를들어서 만약 Query가 Key를 1이 아닌 2로 증가시킨다거나 잘못된 Key를 증가시킨다면 여기에서는 Rollback이 할수 있는 일이 없다.프로그래머의 실수를 해결해줄수 없고, Redis Command가 실패해야하는 종류의 Error들이 제품으로 나가길 바라지 않는다는 것을 고려한다면, 우리는 Error에서 Rollback을 지원하지 않는 대신에 간단하고 빠른 접근을 선택했다.Discarding the command queuedDISCARD는 Transaction을 종료하기위해서 사용된다. 이런 경우에 어떤 명령도 실행되지 않고 연결 상태도 정상으로 복구된다.&amp;gt; SET foo 1OK&amp;gt; MULTIOK&amp;gt; INCR fooQUEUED&amp;gt; DISCARDOK&amp;gt; GET foo&quot;1&quot;Optimistic locking using check-and-setWATCH는 Redis Transaction에서 check-and-set(CAS)를 제공한다.WATCHed keys는 해당 값의 변경사항을 발견하기 위해서 모니터링된다.만약에 적어도 하나의 Key가 EXEC Command가 수행되기전에 변경이된다면. 전체 Transaction은 종료된다. 그리고 EXEC는 NULL 결과를 반환해서 Transaction이 실패했음을 알려준다.예를들어서 어떤 키의 값을 자동적으로 1씩 증가시켜야한다고 상상해보자(Redis가 INCR이 없다고 가정한다면)우리는 다음과 같이 할 것이다.val = GET mykeyval = val + 1SET mykey $val이것은 우리가 하나의 client가 해당 시간에 작업을 수행한다면 믿을수 있는 작업을 수행할 것이다.만약에 여러 client가 key의 값을 수정하기 위해서 같은 시간에 작업을 한다면, race condition 상태가 될것이다.예를들어서 Client A와 B는 옛날 값을 읽을것이다. 예를들어서 10. 두 Client에 의해서 값은 11로 증가될것이다.그리고 최종적으로 Key의 값으로 SET을 수행할것이다. 그러면, 최종값은 12가 아닌 11이 된다.우리는 이런 문제를 잘 해결해준 WATCH에 감사해야 한다.WATCH mykeyval = GET mykeyval = val + 1MULTISET mykey $valEXEC위의 코드를 사용하면 Race Condition이 발생하고, WATCH와 EXEC 호출 사이에 다른 Client가 val의 결과를 수정하다면, Transaction은 실패할것이다.우리는 이번에는 다른 Race Condition이 발생하지 않기를 바라면서 이 작업을 다시 수행하면된다.이러한 형태의 locking은 optimistic locking이라고 부른다. 이러한 형태는 매우 강력한 형태의 locking이다.많은 UseCases에서 여러 Client는 서로 다른 Key에 접근할 것이다. 그래서 충돌은 일반적이지 않아서 해당 Operation을 반복할 필요는 없을것이다.WATCH explained그래서 WATCH는 뭘까? 이것은 EXEC를 조건적으로 수행하게해주는 Command이다: 우리는 Redis에게 WATCHed Key가 수정된것이 없다면 Transaction을 수행하라고 Redis에게 요청하는것이다.(하지만, 같은 client의해서 Transaction 안에서 수정되는 경우에는 종료하지 않는다 more on this) 다른 경우에는 Transaction은 전혀 진입되지 않는다.(Volatile key를 WATCH를 걸고 Redis가 해당 키를 만료시킨다면, EXEC는 여전히 작동한다. 해당 내용은 more on this)WATCH는 여러번 호출할 수 있다. 간단하게 모든 WATCH 호출은 호출 시점부터 EXEC가 호출되는 시점까지 모든 변화에 대한 감시한다.또한 단일 WATCH 호출에 여러개의 Key들을 보낼수 있다.EXEC가 호출됐을때, 모든 Keys가 UNWATCHED 상태라면, Transaction이 종료되던 말던 상관하지 않는다.또한 Client의 연결이 끊겼을때, 모든것은 UNWATCHed 상태가 된다.또한 UNWATCH Command를(Arguments 없이) 모든 watched keys를 정리하기위해서 사용할수도 있다.때때로는 몇몇 Keys를 Optimistically lock을 할때 매우 유용하다. 이러한 keys을 변경하기 위해서 Transaction을 수행할 필요가 있다. 하지만 현재 keys의 내용을 읽고나서 처리를 하고 싶지 않다이러한 상황일때, 우리는 UNWATCH만 호출하면 해당 Connection은 새로운 Transation을 위해서 자유로워진다.Using WATCH to implement ZPOPWATCH를 설명하기 위해서 Redis에서 제공하는 Atomic Operation 중에서 WATCH를 사용해서 만들수 있는 좋은 예제는 ZPOP이다.해당 Command는 Atomic한 방법으로 정렬된 set에서 lower score의 요소를 배출하는 명령이다.아래가 가장 간단한 구현이다.WATCH zsetelement = ZRANGE zset 0 0MULTIZREM zset elementEXEC만약에 EXEC가 실패한다면, Operation을 반복하면 된다.Origin Documenthttps://redis.io/docs/manual/transactions/" }, { "title": "DDIA - 신뢰할 수 있고 확장 가능하며 유지보수하기 쉬운 애플리케이션", "url": "/posts/DDIA-CH1/", "categories": "Study, Book", "tags": "Data, Applicationn, System", "date": "2022-04-29 00:00:00 +0900", "snippet": "Table of Contents 데이터 시스템에 대한 생각 대부분의 소프트웨어 시스템에서 중요하게 여기는 세 가지 관심사 신뢰성 하드웨어 결함 소프트웨어 오류 인적 오류 확장성 부하 기술하기 성능 기술하기 부하 대응 접근 방식 유지보수성 운용성: 운영의 편리함 만들기 단순성: 복잡도 관리 발전성: 변화를 쉽게 만들기 정리오늘날 많은 애플리케이션은 데이터 중심적이다.이런 경우에 애플리케이션을 제한하는 요소가 데이터의 양, 데이터의 복잡도, 데이터의 변화속도이다.데이터 중심 애플리케이션은 공통으로 필요로 하는 기능을 제공하는 표준 구성 요소로 만든다.이때 많은 애플리케이션은 다음 요소를 필요로 한다. 나중에 다시 데이터를 찾을 수 있게 데이터를 저장(데이터베이스) 읽기 속도 향상을 위해 값비싼 수행 결과를 기억(캐시) 키워드로 데이터를 검색하거나 다양한 방법으로 필터링할 수 있게 제공(검색 색인) 비동기 처리를 위해 다른 프로세스로 메시지 보내기(스트림 처리) 주기적으로 대량의 누적된 데이터를 분석(배치 처리)데이터 시스템이 성공적으로 추상화됐기에 우리는 많은 생각 없이 이런 요소들을 사용할 수 있다.하지만 현실은 애플리케이션마다 요구사항이 다르고 데이터베이스 시스템 또한 다양한 특성을 가지고 있다.따라서 애플리케이션을 만들 때 어떤 도구와 어떤 접근 방식이 목적에 가장 적합한지 생각할 수 있어야 한다.데이터 시스템에 대한 생각일반적으로 데이터베이스, 큐, 캐시 등을 매우 다른 범주에 속하는 도구로 생각한다.하지만 데이터 시스템이라는 포괄적 용어로 묶은 이유 분류 간 경계가 흐려지고 있다.더 이상 전통적인 분류에 딱 들어맞지 않는다.메시지 큐로 사용하는 데이터스토어인 레디스가 있고, 데이터베이스처럼 지속성을 보장하는 메시지 큐인 아파치 카프카도 있다. 많은 애플리케이션이 단일 도구로는 더 이상 데이터 처리와 저장 모두를 만족시킬 수 없는 과도하고 광범위한 요구사항을 갖고 있다.대신 작업은 단일 도구에서 효율적으로 수행할 수 있는 단위로 나누고 다양한 도구들은 애플리케이션 코드를 이용해 서로 연결한다.대부분의 소프트웨어 시스템에서 중요하게 여기는 세 가지 관심사신뢰성일반적인 기대치는 다음과 같다. 애플리케이션은 사용자가 기대한 기능을 수행 시스템은 사용자가 범한 실수나 예상치 못한 소프트웨어 사용법을 허용 시스템 성능은 예상된 부하와 데이터 양에서 필수적인 사용 사례를 충분히 만족 시스템은 허가되지 않은 접근과 오남용을 방지이 모든 것이 “올바르게 동작함”을 의미하는 경우,대략 “무언가 잘못되더라도 지속적으로 올바르게 동작함”을 신뢰성의 의미로 이해할 수 있다.잘못될 수 있는 일을 결함(fault) 이라고 부른다.그리고 결함을 예측하고 대처할 수 있는 시스템을 내결함성(fault-tolerant) 또는 탄력성(resilient) 를 지녔다고 말한다.내결함성이라는 용어는 약간 오해의 소지가 있다.모든 종류의 결함을 견딜 수 있는 시스템을 만들 수 있음을 시사하지만 실제로는 실현 가능하지 않다.특정 유형의 결함 내성에 대해서만 이야기하는 것이 타당하다.결함(fault) 은 장애(failure) 와 다르다. 결함 : 사양에서 벗어난 시스템의 한 구성 요소로 정의 장애 : 사용자에게 필요한 서비스를 제공하지 못하고 시스템 전체가 멈춘 경우결함 확률을 0으로 줄이는 것은 불가능하다.따라서 대개 결함으로 인해 장애가 발생하지 않게끔 내결함성 구조를 설계하는 것이 가장 좋다.이 책에서는 신뢰할 수 없는 여러 부품으로 신뢰할 수 있는 시스템을 구축하는 다양한 기법을 다룬다.하드웨어 결함 소프트웨어 내결함성 기술(예 AWS)을 사용 하드웨어 중복성을 추가해 전체 장비의 손실을 견딜 수 있는 시스템으로 점점 옮겨가고 있다.소프트웨어 오류이 결함은 예상하기 더 어렵고 노드 간 상관관계 때문에 상관관계 없는 하드웨어 결함보다 오히려 시스템 오류를 더욱 많이 유발하는 경향이 있다.소프트웨어의 체계적 오류 문제는 신속한 해결책이 없다. 시스템의 가정과 상호작용에 대해 주의 깊게 생각하기 빈틈없는 테스트 프로세스 격리 죽은 프로세스의 재시작 허용 프로덕션 환경에서 시스템 동작의 측정 모니터링 분석하기인적 오류 오류의 가능성을 최소화하는 방향으로 시스템을 설계 사람이 가장 많이 실수하는 장소(부분)에서 사람의 실수로 장애가 발생할 수 있는 부분을 분리 단위 테스트부터 전체 시스템 통합 테스트와 수동 테스트까지 철저하게 테스트 인적 오류를 빠르고 쉽게 복구할 수 있게 하기 성능 지표와 오류율 같은 상세하고 명확한 모니터링 대책 마련 교육과 실습확장성증가한 부하에 대처하는 시스템 능력을 설명하는 데 사용하는 용어이다.시스템에 부여하는 일차원적인 표식이 아님을 주의하자.“시스템이 특정 방식으로 커지면 이에 대처하기 위한 선택은 무엇인가?”“추가 부하를 다루기 위해 계산 자원을 어떻게 투입할까?”같은 질문을 고려한다는 의미다.부하 기술하기시스템의 부하를 간결하게 기술해야 부하 성장 질문을 논의할 수 있다.부하는 부하 매개변수(load parameter)로 몇 개의 숫자로 나타낼 수 있다.가장 적합한 부하 매개변수 선택은 시스템 설계에 따라 달라진다.성능 기술하기다음 두 가지 방법으로 부하가 증가할 때 어떤 일이 일어나는지 조사할 수 있다. 부하 매개변수를 증가시키고 시스템 자원은 변경하지 않고 유지하면 시스템 성능은 어떻게 영향을 받을까? 부하 매개변수를 증가시켰을 때 성능이 변하지 않고 유지되길 원한다면 자원을 얼마나 많이 늘려야 할까?일괄 처리 시스템은 처리량, 온라인 시스템에서는 응답 시간이 보통 중요한 사항이다.온라인 시스템에 대해서 살펴보자면,응답 시간은 단일 숫자가 아니라 측정 가능한 값의 분포 로 생각해야 한다.일반적으로 응답 시간을 평가할 때, 평균 응답 시간을 살핀다. –&amp;gt; 얼마나 많은 사용자가 지연을 경험했는지 알려주지 않음보통 평균보다는 백분위 를 사용하는 편이 더 좋다.P50(50 백분위수)가 중앙값 인데, 사용자가 보통 얼마나 오랫동안 기다려야 하는지 알고 싶다면 좋은 지표가 된다.특이 값이 얼마나 좋지 않은지 보기 위해서는 상위 백분위(P95, P99, P999가 일반적)를 살펴보는 것도 좋다.꼬리 지연 시간(tail latency) 로 알려진 상위 백분위 응답 시간은 서비스의 사용자 경험에 직접 영향을 주기에 중요하다.예를들어서 아마존은 내부 서비스의 응답 시간 요구사항을 P999로 기술함.추가적으로 P9999와 같이 상위로 갈수록 최적화에 비용이 많이들고 이익은 적다고 여겨진다.서버는 병렬로 소수의 작업만 처리할 수 있기에 소수의 느린 처리만으로도 후속 요청 처리가 지체되는데 이를 선두 차단(head-of-line blocking) 이라 한다.서버에서 후속 요청이 빠르게 처리되더라도 이전 요청이 완료되길 기다리는 시간 때문에 클라이언트는 전체적으로 응답 시간이 느리다고 생각할 것이다.이런 문제 때문에 클라이언트 쪽 응답 시간 측정이 중요하다.부하 대응 접근 방식 용량 확장(scaling up) / 수직 확장(vertical scaling) 규묘 확장(scaling out) / 수평 확장(hoizontal scaling)다수 장비에 상태 비저장 서비스를 배포하는 일은 상당히 간단하다.하지만 상태 유지 데이터 시스템을 분산 설치하는 일은 아주 많은 복잡도가 추가적으로 발생한다.이러한 이유로 확장 비용이나 데이터베이스를 분산으로 만들어야 하는 고가용성 요구가 있을 때까지 단일 노드에 데이터베이스를 유지하는 것(용량 확장)이 최근까지의 통념유지보수성유지보수성을 위해 주의 기울여야 할 소프트웨어 시스템 설계 원칙운용성: 운영의 편리함 만들기 런타임 동작과 시스템의 내부에 대한 모니터링 제공 자동화와 통합 지원 개별 장비 의존성 회피 좋은 문서와 이해하기 쉬운 운영 모델 만족할 만한 기본 동작을 제공, 필요에 따라 관리자가 기본값을 정의 가능 적절하게 자기 회복, 필요에 따라 관리자가 시스템 상태를 수동으로 제어 가능 예측 가능하게 동작하고 예기치 않은 상황을 최소화단순성: 복잡도 관리단순성이 구축하려는 시스템의 핵심 목표여야 한다.시스템을 단순하게 만드는 일이 반드시 기능을 줄인다는 의미는 아니다.우발적 복잡도(accidental complexity)를 줄인다는 뜻일 수도 있다.우발적 복잡도를 제거하기 위한 최상의 도구는 추상화 다.발전성: 변화를 쉽게 만들기 애자일(조직 프로세스 측면), TDD, 리팩토링정리 신뢰성 : 결함이 발생해도 시스템이 올바르게 동작하게 만든다는 의미 확장성 : 부하가 증가해도 좋은 성능을 유지하기 위한 전략을 의미 유지보수성본질은 시스템에서 작업하는 엔지니어와 운영 팀의 삶을 개선좋은 추상화는 복잡도를 줄이고 쉽게 시스템을 변경할 수 있게 하며 새로운 사용 사례에 적용하는 데 도움좋은 운용성이란 시스템의 건강 상태를 잘 관찰할 수 있고 시스템을 효율적으로 관리하는 방법을 보유한다는 의미" }, { "title": "Emacs에서 PlantUml을 사용하자", "url": "/posts/use_plantuml/", "categories": "Emacs, org-mode", "tags": "emacs, plantuml, uml", "date": "2022-04-28 00:00:00 +0900", "snippet": "Table of Contents PlantUml 다운로드 graphviz 설치 emacs 설정 사용법emacs의 org-mode에서 uml을 작성하고 생성할 수 있는 plantuml을 emacs에 설정해보겠다.맥에서 세팅중이라 맥을 기준으로 작성하겠다.PlantUml 다운로드PlanUml 사이트 다운로드 : https://plantuml.com/ko/download해당 사이트에서 PlanUml을 적당한 위치에 다운로드 한다.graphviz 설치PlantUml이 Class Diagram을 생성할때 graphviz를 필요로 하므로 미리 설치한다.brew install graphvizemacs 설정;; 위에서 다운받은 plantuml.jar 위치를 지정해준다.(setq org-plantuml-jar-path (expand-file-name &quot;~/.emacs.d/custom/package/plantuml.jar&quot;));; plantuml 문법으로 uml 작성 후, C-c C-c를 누르면 이미지가 생성된다(add-hook &#39;org-babel-after-execute-hook (lambda () (when org-inline-image-overlays (org-redisplay-inline-images))))사용법#+BEGIN_SRC plantuml :file 파일명.pngClassA -&amp;gt; ClassB#+END_SRC이제 위의 코드 블록에서 C-c C-c를 누르면 결과 Uml이 출력이 된다." }, { "title": "Doom mode line 설정", "url": "/posts/install-doom-mode-line/", "categories": "Emacs", "tags": "emacs, theme", "date": "2022-04-28 00:00:00 +0900", "snippet": "Table of Contents Doom mode line 설치 all-the-icons 설치 Doom themes 설치Doom mode line 설치Doom mode line github 주소 : https://github.com/seagle0128/doom-modelinepackage manager를 통해서 doom-modeline 설치init.el에 다음과 같이 설정(require &#39;doom-modeline)(doom-modeline-mode 1) all-the-icons 설치Doom mode line은 all-the-icons에 포함된 폰트를 사용하므로 해당 폰트도 설치해 주자all-the-icons github 주소 : https://github.com/domtronn/all-the-icons.el#installationM-x all-the-icons-install-fontsDoom themes 설치그리고, Doom mode line 개발자가 강력 추천하는 doom-themes도 설치해주자(선택 사항)doom-themes github 주소 : https://github.com/hlissner/emacs-doom-themes해당 테마는 package manager로 doom-themes로 검색해서 설치하면 된다." }, { "title": "org-mode에서 한글로 export 하기", "url": "/posts/export_kor_pdf/", "categories": "Emacs, org-mode", "tags": "emacs, org-mode, ko, export", "date": "2022-04-27 00:00:00 +0900", "snippet": "Table of Contents tex 설치 Ubuntu Mac Emacs 설정기본 org-mode를 사용해서 글을 작성 후, pdf 포멧으로 생성할 경우 에러를 만나게 된다.즉, 기본 설정 org-mode에서는 한글로 작성한 글을 pdf 포멧으로 바로 생성이 안 된다.해당 글에서는 org-mode에서 export를 통해서 한글이 존재하는 글을 pdf 포멧으로 생성하는 방법을 정리하고자 한다.tex 설치Ubuntuapt-get install texlive-xetexapt-get install ko.texMacbrew cask install mactexEmacs 설정init.el 파일 이나 설정 파일에 다음과 같이 추가(require &#39;ox-latex)(setenv &quot;PATH&quot; (concat ;; latex 위치를 못 찾을 경우 해당 경로를 지정 ;; mac의 경우 못 찾아서 설정을 해줬음 ;; 아래의 위치는 나의 mactex 설치 위치 &quot;/Library/TeX/texbin/&quot; &quot;:&quot; (getenv &quot;PATH&quot;)))위와 같이 tex 설치 및 설정이 완료가 됐다면, 이제 org-mode에서 글을 작성 후, export pdf를 수행하면 된다.단, 각 글의 해더 부분에 아래와 같이 작성해줘야 한다.#+LATEX_HEADER: \\usepackage{kotex}이제 org-mode에서 pdf 출력 준비가 완료 됐다.한글 문서를 작성하고 Org Export 기능(C-c C-e)을 사용해서 pdf를 출력해보자" }, { "title": "자바 ORM 표준 JPA 프로그래밍 - 트랜잭션과 락, 2차 캐시", "url": "/posts/%EC%9E%90%EB%B0%94_orm_%ED%91%9C%EC%A4%80_jpa_%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D_%ED%8A%B8%EB%9E%9C%EC%9E%AD%EC%85%98%EA%B3%BC_%EB%9D%BD_2%EC%B0%A8_%EC%BA%90%EC%8B%9C/", "categories": "Study, Book", "tags": "JPA, ORM", "date": "2021-05-19 00:00:00 +0900", "snippet": "Table of Contents 트랜잭션과 락 트랜잭션과 격리 수준 낙관적 락과 비관적 락 기초 @Version 버전 정보 비교 방법 JPA 락 사용 JPA 낙관적 락 NONE OPTIMISTIC OPTIMISTICFORCEINCREMENT JPA 비관적 락 PESSIMISTICWRITE PESSIMISTICREAD PESSIMISTICFORCEINCREMENT 비관적 락과 타임아웃 2차 캐시 1차 캐시와 2차 캐시 2차 캐시 JPA 2차 캐시 기능 캐시 모드 설정 캐시 조회, 저장 방식 설정 JPA 캐시 관리 API 하이버네이트와 EHCACHE 적용 @Cache 캐시 영역 쿼리 캐시 쿼리 캐시 영역 쿼리 캐시와 컬렉션 캐시의 주의점 트랜잭션과 락JPA에서 제공하는 낙관적 락과 비관적 락에 대해 알아보자트랜잭션과 격리 수준트랜잭션은 ACID라 하는 원자성, 일관성, 격리성, 지속성을 보장해야 한다. 원자성: 트랜잭션 내에서 실행한 작업들은 마치 하나의 작업인 것처럼 모두 성공하거나 실패해야 한다. 일관성: 모든 트랜잭션은 일관성 있는 데이터베이스 상태를 유지해야 한다. 격리성: 동시에 실행되는 트랜잭션들이 서로에게 영향을 미치지 않도록 격리한다. 지속성: 트랜잭션을 성공적으로 끝내면 그 결과가 항상 기록되어야 한다.트랜잭션 격리 수준 READ UNCOMMITED(커밋되지 않은 읽기) READ COMMITED(커밋된 읽기) REPEATABLE READ(반복 가능한 읽기) SERIALIZABLE(직렬화 가능)트랜잭션 격리 수준과 문제점격리 수준DIRTY READNON-REPEATABLE READPHANTOM READREAD UNCOMMITTEDOOOREAD COMMITTED&amp;#xa0;OOREPEATABLE READ&amp;#xa0;&amp;#xa0;OSERIALIZABLE&amp;#xa0;&amp;#xa0;&amp;#xa0;격리 수준에 따른 발생할 수 있는 문제점은 다음과 같다. DIRTY READ: 커밋되지 않은 수정중인 데이터를 읽을 수 있다. NON-REPEATABLE READ: 트랜잭션 1이 회원 A를 조회 중인데 갑자기 트랜잭션 2가 회원 A를 수정하고 커밋하면 트랜잭션 1이 다시 회원 A를 조회했을 때 수정된 데이터가 조회된다. PHANTOM READ: 트랜잭션1이 10살 이하의 회원을 조회했는데 트랜잭션 2가 5살 회원을 추가하고 커밋하면 트랜잭션1이 다시 10살 이하의 회원을 조회했을 때 회원 하나가 추가된 상태로 조회된다.여기서 SERIALIZABLE은 가장 엄격한 트랜잭션 격리 수준이다. 위의 문제가 모두 발생하지 않지만, 동시성 처리 성능이 급격히 떨어질 수 있다.낙관적 락과 비관적 락 기초JPA의 영속성 컨텍스트를 적절히 활용하면 데이터베이스 트랜젝션이 READ COMMITTED 격리 수준이어도 APP 레벨에서 반복 가능한 읽기가 가능하다.JPA는 데이터베이스 트랜잭션 격리 수준을 READ COMMITTED 정도로 가정한다.만약 일부 로직에 더 높은 격리 수준이 필요하면 낙관적 락과 비관적 락 중 하나를 사용하면 된다. 낙관적 락은 이름 그대로 트랜잭션 대부분은 충돌이 발생하지 않는다고 낙관적으로 가정하는 방법이다.이것은 DB가 제공하는 락 기능을 사용하는 것이 아니라 JPA가 제공하는 버전 관리 기능을 사용한다.트랜잭션을 커밋하기 전까지는 트랜잭션의 충돌을 알 수 없다는 특징이 있다. 비관적 락은 이름 그대로 트랜잭션의 충돌이 발생한다고 가정하고 우선 락을 걸고 보는 방법이다.DB가 제공하는 락 기능을 사용한다.여기에 추가로 DB 트랜잭션 범위를 넘어서는 문제도 있다.예를 들어 두 번의 갱신 분실 문제가 있다. (2번의 수정이 동시에 발생하고 마지막 변경 사항만 남게 된다.)두번의 갱신 분실 문제는 DB 트랜잭션의 범위를 넘어선다.따라서 트랜잭션만으로는 문제를 해결할 수 없다.이때는 3가지 선택 방법이 있다. 마지막 커밋만 인정하기 최초 커밋만 인정하기 충돌하는 갱신 내용 병합하기JPA가 제공하는 버전 관리 기능을 사용하면 손쉽게 최초 커밋만 인정하기를 구현할 수 있다.병합하기는 최초 커밋만 인정하기를 개발자가 직접 사용자를 위해 병합 방법을 제공해야 한다.@VersionJPA가 제공하는 낙관적 락을 사용하려면 @Version 어노테이션을 사용해서 버전 관리 기능을 추가해야 한다.@Version 적용 가능 타입은 다음과 같다. Long (long) Integer (int) Short (short) Timestamp @Entitypublic class Board { @Id private String id; private String title; @Version private Integer version;} 이제부터 엔티티를 수정할 때 마다 버전이 하나씩 자동으로 증가한다.그리고 엔티티를 수정할 때 조회 시점의 버전과 수정 시점의 버전이 다르면 예외가 발생한다.따라서 버전 정보를 사용하면 최초 커밋만 인정 하기가 적용된다.버전 정보 비교 방법엔티티를 수정하고 트랜잭션을 커밋하면 영속성 컨텍스트를 플러시 하면서 UPDATE 쿼리를 실행하면서 버전 정보를 추가한다. UPDATE BOARD SET TITLE = ?, VERSION = ? (버전 +1) WHERE ID = ? AND VERSION = ? (버전 비교)@Version으로 추가한 버전 관리 필드는 JPA가 직접 관리하므로 개발자가 임의로 수정하면 안 된다.만약 버전 값을 강제로 증가하려면 특별한 락 옵션을 선택하면 된다.벌크 연산은 버전을 무시한다. 벌크 연산에서 버전을 증가하려면 버전 필드를 강제로 증가시켜야 한다.JPA 락 사용JPA를 사용할 때 추천하는 전략은 READ COMMITTED 트랜잭션 격리 수준 + 낙관적 버전 관리다.락은 다음 위치에 적용할 수 있다. EntityManager.lock(), EntityManager.find(), EntityManager.refresh() Query.setLockMode() (TypeQuery 포함) @NamedQueryJPA가 제공하는 락 옵션은 javax.persistence.LockModeType에 정의되어 있다.락 모드타입설명낙관적 락OPTIMISTIC낙관적 락을 사용한다.낙관적 락OPTIMISTICFORCEINCREMENT낙관적 락 + 버전정보를 강제로 증가비관적 락PESSIMISTICREAD비관적 락, 읽기 락을 사용비관적 락PESSIMISTICWRITE비관적 락, 쓰기 락을 사용비관적 락PESSIMISTICFORCEINCREMENT비관적 락 + 버전정보를 강제로 증가기타NONE락을 걸지 않는다기타READJPA1.0 호환 기능 OPTIMISTIC과 동일기타WRITEJPA1.0 호환 기능 OPTIMISTICFORCEINCREMENT와 동일JPA 낙관적 락JPA가 제공하는 낙관적 락은 버전(@Version)을 사용한다.낙관적 락은 트랜잭션을 커밋하는 시점에 충돌을 알 수 있다는 특징이 있다.일부 JPA 구현체 중에서 @Version 컬럼 없이 낙관적 락을 허용하기도 하지만 추천하지는 않는다.참고로 락 옵션 없이 @Version만 있어도 낙관적 락이 적용된다.락 옵션을 사용하면 락을 더 세밀하게 제어할 수 있다.NONE락 옵션을 적용하지 않아도 엔티티에 @Version이 적용된 필드만 있으면 낙관적 락이 적용된다. 용도: 조회 시점부터 수정 시점까지를 보장 동작: 엔티티를 수정할 때 버전을 체크하면서 버전을 증가 이점: 두 번의 갱신 분실 문제를 예방OPTIMISTIC@Version만 적용했을 때는 엔티티를 수정해야 버전을 체크하지만이 옵션을 추가하면 엔티티를 조회만 해도 버전을 체크 한다.한번 조회한 엔티티는 트랜잭션을 종료할 때까지 다른 트랜잭션에서 변경하지 않음을 보장 용도: 조회 시점부터 트랜잭션이 끝날 때까지 조회한 엔티티가 변경되지 않음을 보장 동작: 트랜잭션을 커밋할 때 버전 정보를 조회해서 현재 엔티티의 버전과 같은지 검증, 만약 같지 않으면 예외가 발생 이점: OPTIMISTIC 옵션은 DIRTY READ와 NON-REPEATABLE READ를 방지OPTIMISTICFORCEINCREMENT 용도: 논리적인 단위의 엔티티 묶음을 관리할 수 있다. 동작: 엔티티를 수정하지 않아도 트랜잭션을 커밋할 때 UPDATE 쿼리를 사용해서 버전 정보를 강제로 증가시킨다. 추가로 엔티티를 수정하면 수정 시 버전 UPDATE가 발생한다. 따라서 총 2번의 버전 증가가 나타날 수 있다. 이점: 강제로 버전을 증가해서 논리적인 단위의 엔티티 묶음을 버전 관리할 수 있다.JPA 비관적 락데이터베이스 트랜잭션 락 메커니즘에 의존하는 방법주로 SQL 쿼리에 select for update 구문을 사용하면서 시작하고 버전 정보는 사용하지 않는다. 엔티티가 아닌 스칼라 타입을 조회할 때도 사용할 수 있다. 데이터를 수정하는 즉시 트랜잭션 충돌을 감지PESSIMISTICWRITE데이터베이스에 쓰기 락을 걸때 사용 용도: 데이터베이스에 쓰기 락을 건다. 동작: 데이터베이스에 select for update를 사용해서 락을 건다. 이점: NON-REPEATABLE READ를 방지한다. 락이 걸린 로우는 다른 트랜잭션이 수정할 수 없다.PESSIMISTICREAD데이터를 반복 읽기만 하고 수정하지 않는 용도로 락을 걸 때 사용데이터베이스 대부분은 방언에 의해 PESSIMISTICWRITE로 동작 MySQL: lock in share mode PostgreSQL: for sharePESSIMISTICFORCEINCREMENT비관적 락중 유일하게 버전 정보를 사용비관적 락이지만 버전 정보를 강제로 증가시킨다.하이버네이트는 nowait를 지원하는 데이터베이스에 대해서 for update nowait 옵션을 적용한다. oracle: for update nowait PostgreSQL: for update nowait nowait를 지원하지 않으면 for update가 사용된다.비관적 락과 타임아웃비관적 락을 사용하면 락을 획득할 때까지 트랜잭션이 대기한다.대기하다가 타임아웃 시간 대기 후 응답이 없으면 Javax.persistence.LockTimeoutException 예외가 발생한다.타임아웃은 데이터베이스 특성에 따라 동작하지 않을 수 있다.2차 캐시1차 캐시와 2차 캐시영속성 컨텍스트 내부에는 엔티티를 보관하는 저장소가 있는데 이것을 1차 캐시라 한다.대부분의 JPA 구현체들은 애플리케이션 범위의 캐시를 지원하는데 이것을 공유 캐시 또는 2차 캐시라 한다.2차 캐시2차 캐시를 적용하면 엔티티 매니저를 통해서 데이터를 조회할 때 우선 2차 캐시에서 찾고 없으면 데이터베이스에서 찾는다.2차 캐시는 동시성을 극대화하려고 캐시한 객체를 직접 반환하지 않고 복사본을 만들어서 반환한다.만약 캐시한 객체를 그대로 반환하면 여러 곳에서 같은 객체를 동시에 수정하는 문제가 발생할 수 있다.특징은 다음 과 같다. 2차 캐시는 영속성 유닛 범위의 캐시다. 복사본을 만들어서 반환한다. 2차 캐시는 데이터베이스 기본 키를 기준으로 캐시하지만 영속성 컨텍스트가 다르면 객체 동일성(a==b)을 보장하지 않는다.JPA 2차 캐시 기능JPA 캐시 표준은 여러 구현체가 공통으로 사용하는 부분만 표준화해서 세밀한 설정을 하려면 구현체에 의존적인 기능을 사용해야 한다.JPA 캐시 표준 기능은 다음과 같다.캐시 모드 설정2차 캐시를 사용하려면 @Cacheable 어노테이션을 사용하면 된다. @Cacheable @Entity public class Member { @Id @GeneratedValue private Long id; ... }그리고 아래와 같이 persistence.xml에 shared-cache-mode를 설정해서 애플리케이션 전체에 캐시를 어떻게 적용할지 옵션을 설정해야 한다. &amp;lt;persistence-unit name=&quot;test&quot;&amp;gt; &amp;lt;shared-cache-mode&amp;gt;ENABLE_SELECTIVE&amp;lt;/shared-cache-mode&amp;gt; &amp;lt;/persistence-unit&amp;gt;캐시 모드 스프링 프레임워크 XML 설정 &amp;lt;bean id=&quot;entityManagerFactory&quot; class=&quot;org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean&quot;&amp;gt; &amp;lt;property name=&quot;sharedCacheMode&quot; value=&quot;ENABLE_SELECCTIVE&quot;/&amp;gt; ...SharedCacheMode 설정캐시 모드설명ALL모든 엔티티를 캐시한다.NONE캐시를 사용하지 않는다.ENABLESELECTIVECacheable(true)로 설정된 엔티티만 캐시를 적용한다.DISABLESELECTIVE모든 엔티티를 캐시하는데 Cacheable(false)로 명시된 엔티티는 캐시하지 않는다.UNSPECIFIEDJPA 구현체가 정의한 설정을 따른다.캐시 조회, 저장 방식 설정캐시를 무시하고 데이터베이스를 직접 조회하거나 캐시를 갱신하려면 캐시 조회 모드와 캐시 보관 모드를 사용하면 된다.em.setProperty(&quot;javax.persistence.cache.retrieveMode&quot;, CacheRetrieveMode.BYPASS);캐시 조회 모드나 보관 모드에 따라서 사용할 프로퍼티와 옵션이 다르다.프로퍼티 이름은 다음과 같다. javax.persistence.cache.retrieveMode: 캐시 조회 모드 javax.persistence.cache.storeMode: 캐시 보관 모드옵션은 다음과 같다. javax.persistence.CacheRetrieveMode: 캐시 조회 모드 설정 옵션 javax.persistence.CacheStoreMode: 캐시 보관 모드 설정 옵션캐시 조회 모드 public enum CacheRetrieveMode { USE, BYPASS } USE: 캐시에서 조회, 기본 값 BYPASS: 캐시를 무시하고 데이터베이스에서 직접 접근캐시 보관 모드 public enum CacheStoreMode { USE, BYPASS, REFRESH } USE: 조회한 데이터를 캐시에 저장 하지만 이미 캐시에 있으면 캐시 데이터를 최신 상태로 갱신하지 않는다. 기본값 BYPASS: 캐시에 저장하지 않는다. REFRESH: USE 전략에 추가로 데이터베이스에서 조회한 엔티티를 최신 상태로 다시 캐시한다.캐시 모드는 EntityManager.setProperty()로 엔티티 매니저 단위로 설정하거나더 세밀하게 EntityManager.find(), EntityManager.refresh()에 설정할 수 있다.그리고 Query.setHint() (TypeQuery 포함)에 사용할 수 있다.JPA 캐시 관리 APIJPA는 캐시를 관리하기 위한 javax.persistence.Cache 인터페이스를 제공한다.Cache 인터페이스 public interface Cache { // 해당 엔티티가 캐시에 있는지 여부 확인 public boolean contains(Class cls, Object primaryKey); // 해당 엔티티중 특정 실벽자를 가진 엔티티를 캐시에서 제거 public void evict(Class cls, Object primarykey); // 해당 엔티티 전체를 캐시에서 제거 public void evict(Class cls); // 모든 캐시 데이터 제거 public void evictAll(); // JPA Cache 구현체 조회 public &amp;lt;T&amp;gt; T unwrap(Class&amp;lt;T&amp;gt; cls); }하이버네이트와 EHCACHE 적용하이버 네이트가 지원하는 캐시는 크게 3가지가 있다. 엔티티 캐시: 엔티티 단위로 캐시 컬렉션 캐시: 엔티티와 연관된 컬렉션을 캐시컬렉션이 엔티티를 담고 있으면 식별자 값만 캐시(하이버네이트 기능) 쿼리 캐시: 쿼리와 파라미터 정보를 키로 사용해서 캐시한다.결과가 엔티티면 식별자 값만 캐시한다(하이버네이트 기능)@Cache속성설명usageCacheConcurrencyStrategy를 사용해서 캐시 동시성 전략을 설정region캐시 지역 설정include연관 객체를 캐시에 포함할지 선택, 기본 allCacheConcurrencyStrategy 속성속성설명NONE캐시를 설정하지 않는다.READONLY읽기 전용으로 설정한다. 등록, 삭제는 가능하지만 수정은 불가능하다, 그래서 원본 객체를 반환NONSTRICTREADWRITE동시에 같은 엔티티를 수정하면 데이터 일관성이 깨질 수 있다.READWRITEREAD COMMITTED 정도의 격리 수준을 보장한다. EHCACHE는 데이터를 수정하면 캐시 데이터도 같이 수정TRANSACTIONAL컨테이너 관리 환경에서 사용할 수 있다. 설정에 따라 REPEATABLE READ 정도의 격리 수준을 보장캐시 동시성 전략 지원 여부Cacheread-onlynonstrict-read-writeread-writetransactionalConcurrentHashMapooo&amp;#xa0;EHCacheooooInfinispano&amp;#xa0;&amp;#xa0;o캐시 영역엔티티 캐시 영역은 기본값으로 [패키지 명 + 클래시 명]을 사용하고,컬렉션 캐시 영역은 엔티티 캐시 영역 이름에 캐시한 컬렉션의 필드 명이 추가된다.필요하면 @Cache(region = “customRegion”, …) 처럼 region 속성을 사용해서 캐시 영역을 직접 지정할 수 있다.캐시 영역을 위한 접두사를 설정하려면 persistence.xml 설정에 hibernate.cache.regionprefix를 사용하면 된다.core로 설정하면 core.jpabook.jpashop…으로 설정된다.쿼리 캐시쿼리 캐시는 쿼리와 파라미터 정보를 키로 사용해서 쿼리 결과를 캐시하는 방법이다.쿼리 캐시를 적용하려면 영속성 유닛을 설정에 hibernate.cache.usequerycache 옵션을 꼭 true로 설정해야 한다.그리고 쿼리 캐시를 적용하려는 쿼리 마다 org.hibernate.cacheable을 설정하는 힌트를 주면 된다. em.createQuery(&quot;select i from Item i&quot;, Item.class) .setHint(&quot;org.hibernate.cacheable&quot;, true) .getResultList(); @Entity @NamedQuery( hints = @QueryHint(name = &quot;org.hibernate.cacheable&quot;, value = &quot;true&quot;), name = &quot;Member.findByUsername&quot;, query = &quot;select m.address from Member m where m.name = :username&quot; ) public class Member { ... }쿼리 캐시 영역hibernatecache.usequerycache 옵션을 true로 설정해서 쿼리 캐시를 활성화하면 다음 두 캐시 영역이 추가된다. org.hibernate.cache.internal.StandardCache: 쿼리 캐시를 저장하는 영역, 쿼리, 쿼리 결과 집합, 쿼리를 실행한 시점의 타임스탬프를 보관 org.hibernate.cache.spi.UpdateTimestampsCache: 쿼리 캐시가 유효한지 확인하기 위해 쿼리 대상 테이블의 가장 최근 변경 시간을 저장하는 영역, 테이블 명과 해당 테이블의 최근 변경된 타임스탬프를 보관쿼리 캐시를 적용하고 난 후에 쿼리 캐시가 사용하는 테이블에 조금이라도 변경이 있으면 데이터베이스에서 데이터를 읽어와서 쿼리 결과를 다시 캐시한다.이제부터 엔티티에 변경하면 org.hibernate.cache.spi.UpdateTimestampsCache 캐시 영역에 해당 엔티티가 매핑한 테이블 이름으로 타임스탬프를 갱신한다.쿼리를 실행하면 우선 StandardQueryCache 캐시 영역에서 타임스탬프를 조회한다.그리고 쿼리가 사용하는 엔티티의 테이블의 UpdateTimestampsCache 캐시 영역에서 조회해서 테이블들의 타임스탬프를 확인한다.캐시가 유효하지 않다면 데이터베이스에서 데이터를 조회해서 다시 캐시한다.쿼리 캐시를 잘 활용하면 극적인 성능 향상이 있지만 빈번하게 변경이 있는 테이블에 사용하면 오히려 성능이 더 저하된다.쿼리 캐시와 컬렉션 캐시의 주의점쿼리 캐시와 컬렉션 캐시는 결과 집합의 식별자 값만 캐시한다.이 식별자 값을 하나씩 엔티티 캐시에서 조회해서 실제 엔티티를 찾는다.쿼리 캐시나 컬렉션 캐시만 사용하고 대상 엔티티에 엔티티 캐시를 적용하지 않으면 성능상 심각한 문제가 발생할 수 있다.쿼리 캐시나 컬렉션 캐시는 식별자 값만 캐시하니, 엔티티 캐시를 사용하지 않으면 저장된 각 식별자 값으로 한 건씩 데이터베이스에서 조회한다.따라서 쿼리 캐시나 컬렉션 캐시를 사용하면 결과 대상 엔티티에는 꼭 엔티티 캐시를 적용해야 한다." }, { "title": "자바 ORM 표준 JPA 프로그래밍 - 고급 주제와 성능 최적화", "url": "/posts/%EC%9E%90%EB%B0%94_orm_%ED%91%9C%EC%A4%80_jpa_%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D_%EA%B3%A0%EA%B8%89_%EC%A3%BC%EC%A0%9C%EC%99%80_%EC%84%B1%EB%8A%A5_%EC%B5%9C%EC%A0%81%ED%99%94/", "categories": "Study, Book", "tags": "JPA, ORM", "date": "2021-05-18 00:00:00 +0900", "snippet": "Table of Contents 예외 처리 트랜잭션 롤백을 표시하는 예외 트랜잭션 롤백을 표시하지 않는 예외 스프링 프레임워크의 JPA 예외 변환 스프링 프레임워크에 JPA 예외 변환기 적용 트랜잭션 롤백 시 주의사항 엔티티 비교 영속성 컨텍스트가 같을 때 엔티티 비교 영속성 컨텍스트가 다를 때 엔티티 비교 프록시 심화 주제 영속성 컨텍스트와 프록시 프록시 타입 비교 프록시 동등성 비교 상속관계와 프록시 JPQL로 대상 직접 조회 프록시 벗기기 기능을 위한 별도의 인터페이스 제공 비지터 패턴 사용 성능 최적화 N+1 문제 즉시 로딩과 N+1 지연 로딩과 N+1 페치 조인 사용 하이버네이트 @BatchSize 하이버네이트 @Fetch(FetchMode.SUBSELECT) N+1 정리 읽기 전용 쿼리의 성능 최적화 스칼라 타입으로 조회 읽기 전용 쿼리 힌트 사용 읽기 전용 트랜잭션 사용 트랜잭션 밖에서 읽기 정리 배치 처리 JPA 등록 배치 JPA 페이징 배치 처리 하이버네이트 scroll 사용 하이버네이트 무상태 세션 사용 SQL 쿼리 힌트 사용 트랜잭션을 지원하는 쓰기 지연과 성능 최적화 트랜잭션을 지원하는 쓰기 지연과 애플리케이션 확장성 예외 처리JPA 표준 예외는 크게 2가지트랜잭션 롤백을 표시하는 예외심각한 예외이므로 복구해선 안 된다.이 예외가 발생하면 트랜잭션을 강제로 커밋해도 트랜잭션이 커밋되지 않고 대신에 RollbackException 예외가 발생트랜잭션 롤백을 표시하지 않는 예외심각한 예외가 아니다.개발자가 커밋할지 롤백할지 판단하면 된다.스프링 프레임워크의 JPA 예외 변환서비스 계층에서 데이터 접근 계층의 구현 기술에 직접 의존하는 것은 좋은 설계라 할 수 없다.스프링 프레임워크는 이런 문제를 해결하려고 데이터 접근 계층에 대한 에외를 추상화해서 개발자에게 제공한다.스프링 프레임워크에 JPA 예외 변환기 적용JPA 예외를 스프링 프레임워크가 제공하는 추상화된 예외로 변경하려면 PersistenceExceptionTranslationPostProcessor를 스프링 빈으로 등록하면 된다.@Repository 어노테이션을 사용한 곳에 예외 변환 AOP를 적용해서 JPA 예외를 스프링 프레임워크가 추상화한 예외로 변환해준다.만약 예외를 변환하지 않고 그대로 반환하고 싶으면 throws 절에 그대로 반환할 JPA 예외나 JPA 예외의 부모 클래스를 직접 명시하면 된다.트랜잭션 롤백 시 주의사항트랜잭션을 롤백하는 것은 데이터베이스의 반영사항만 롤백하는 것이지 수정한 자바 객체까지 원상태로 복구해주지는 않는다.따라서 트랜잭션이 롤백된 영속성 컨텍스트를 그대로 사용하는 것은 위험하다.스프링 프레임워크는 이런 문제를 예방하기 위해 영속성 컨텍스트의 범위에 따라 다른 방법을 사용한다.기본 전략인 트랜잭션당 영속성 컨텍스트 전략은문제가 발생하면 트랜잭션 AOP 종료 시점에 트랜잭션을 롤백하면서 영속성 컨텍스트도 함께 종료따라서 문제가 발생하지 않는다.OSIV의 경우롤백이 발생해서 영속성 컨텍스트에 이상이 발생해도 다른 트랜잭션에서 해당 영속성 컨텍스트를 그대로 사용하는 문제가 있다.스프링 프레임워크는 영속성 컨텍스트의 범위를 트랜잭션의 범위보다 넓게 설정하면 트랜잭션 롤백시 영속성 컨텍스트를 초기화 해서 잘못된 영속성 컨텍스트를 사용하는 문제를 예방엔티티 비교영속성 컨텍스트가 같을 때 엔티티 비교다음 3가지 조건을 모두 만족 동일성 : == 비교가 같다. 동등성 : equals() 비교가 같다. 데이터베이스 동등성 : @Id인 데이터베이스 식별자가 같다.영속성 컨텍스트가 다를 때 엔티티 비교 동일성 : == 비교가 실패한다. 동등성 : equals() 비교가 같다. 단 equals()를 구현해야 한다. 데이터베이스 동등성 : @Id인 데이터베이스 식별자가 같다.프록시 심화 주제영속성 컨텍스트와 프록시영속성 컨텍스트는 자신이 관리하는 영속 엔티티의 동일성을 보장한다.그럼 프록시로 조회한 엔티티의 동일성도 보장할까?영속성 컨텍스트는 프록시로 조회된 엔티티에 대해서 같은 엔티티를 찾는 요청이 오면 원본 엔티티가 아닌 처음 조회된 프록시를 반환한다.원본 엔티티를 먼저 조회하면 영속성 컨텍스트는 원본 엔티티를 이미 데이터베이스에서 조회했으므로 프록시를 반환할 이유가 없다.프록시 타입 비교프록시는 원본 엔티티를 상속 받아서 만들어지므로 프록시로 조회한 엔티티의 타입을 비교할 때는 == 비교를 하면 안 되고 대신에 instanceof를 사용해야 한다.프록시 동등성 비교엔티티의 동등성을 비교하려면 비즈니스 키를 사용해서 equals() 메소드를 오버라이딩하고 비교하면 된다.하지만 비교 대상이 원본 엔티티면 문제가 없지만 프록시면 문제가 발생할 수 있다.프록시는 실제 데이터를 가지고 있지 않다. 따라서 프록시의 멤버변수에 직접 접근하면 아무값도 조회할 수 없다.프록시의 데이터를 조회할 때는 접근자를 사용해야 한다.결과적으로 프록시 타입 비교는 == 비교 대신에 instanceof를 사용해야 한다. 프록시의 멤버 변수에 직접 접근하면 안 되고 대신에 접근자 메소드를 사용해야 한다.상속관계와 프록시프록시를 부모 타입으로 조회하면 문제가 발생한다.프록시를 부모 타입으로 조회하면 부모 타입을 기반으로 프록시가 생성되는 문제가 있다. instanceof 연산을 사용할 수 없다. 하위 타입으로 다운캐스팅을 할 수 없다.JPQL로 대상 직접 조회처음부터 자식 타입을 직접 조회해서 필요한 연산을 하면 된다.물론 이 방법을 사용하면 다형성을 활용할 수 없다.프록시 벗기기하이버네이트가 제공하는 기능을 사용하면 프록시에서 원본 엔티티를 가져올 수 있다.영속성 컨텍스트는 한 번 프록시로 노출한 엔티티는 계속 프록시로 노출한다.그래야 영속성 컨텍스트가 영속 엔티티의 동일성을 보장할 수 있고, 클라이언트는 조회한 엔티티가 프록시인지 아닌지 구분하지 않고 사용할 수 있다.그런데 이 방법은 프록시에서 원본 엔티티를 직접 꺼내기 때문에 프록시와 원본 엔티티의 동일성 비교가 실패한다는 문제점이 있다.이 방법을 사용할 때는 원본 엔티티가 꼭 필요한 곳에서 잠깐 사용하고 다른 곳에서 사용되지 않도록 하는 것이 중요하다.기능을 위한 별도의 인터페이스 제공인터페이스를 제공하고 각각의 클래스가 자신에게 맞는 기능을 구현하는 것은 다형성을 활용하는 좋은 방법이다.다양한 상품 타입이 추가되어도 Item을 사용하는 OrderItem의 코드는 수정하지 않아도 된다.프록시의 특징 때문에 프록시의 대상이 되는 타입에 인터페이스를 적용해야 한다. public interface TitleVie { String getTitle(); } @Entity @Inheritance(strategy = InheritanceType.SINGLE_TABLE) @DiscriminatorColumn(name = &quot;DTYPE&quot;) public abstract class Item implements TitleView { @Id @GeneratedValue @Column(name =&quot;ITEM_ID&quot;) private Long ig; private String name; private int price; private int stockQuantity; // Getter, Sstter } @Entity @DiscriminatorValue(&quot;B&quot;) public class Book extends Item { private String author; private String isbn; // Getter, Setter @Override public String getTitle() { return &quot;this is book&quot;; } } @Entity @DiscriminatorValue(&quot;M&quot;) public class Movie extends Item { private String director; private String author; // Getter, Setter @Override public String getTitle() { return &quot;this is Movie&quot;; } }비지터 패턴 사용장점 프록시에 대한 걱정 없이 안전하게 원본 엔티티에 접근할 수 있다. instanceof와 타입캐스팅 없이 코드를 구현할 수 있다. 알고리즘과 객체 구조를 분리해서 구조를 수정하지 않고 새로운 동작을 추가할 수 있다.단점 너무 복잡하고 더블 디스패치를 사용하기 때문에 이해하기 힘들다. 객체 구조가 변경되면 모든 Visitor를 수정해야 한다.성능 최적화N+1 문제 @Entity public class Member { @Id @GeneratedValue private Long id; @OneToMany(mappedBy = &quot;member&quot;, fetch = FetchType.EAGER) private List&amp;lt;Order&amp;gt; orders = new ArrayList&amp;lt;Order&amp;gt;(); ... } @Entity @Table(name = &quot;ORDERS&quot;) public class Order { @Id @GeneratedValue private Long id; @ManyToOne private Member member; ... }즉시 로딩과 N+1특정 회원 하나를 em.find() 메소드로 조회하면 즉시 로딩으로 설정한 주문 정보도 함께 조회한다.문제는 JPQL을 사용할 때 발생한다.JPQL을 실행하면 JPA는 이것을 분석해서 SQL을 생성한다.이때는 즉시 로딩과 지연 로딩에 대해서 전혀 신경 쓰지 않고 JPQL만 사용해서 SQL을 생성한다.그런데 회원 엔티티와 연관된 주문 컬렉션이 즉시 로딩으로 설정되어 있으므로 JPA는 주문 컬렉션을 즉시 로딩하려고 추가 SQL을 실행한다.결과적으로 즉시 로딩은 JPQL을 사용할 때 N+1 문제가 발생할 수 있다.지연 로딩과 N+1지연 로딩을 사용하면 JPQL에서 N+1 문제가 발생하지 않는다.문제는 모든 회원에 대해 연관된 주문 컬렉션을 사용할 때 발생한다.주문 컬렉션을 초기화하는 수만큼 추가 SQL이 실행될 수 있다.즉, 이것도 결국 N+1 문제이다.페치 조인 사용N+1 문제를 해결하는 가장 일반적인 방법은 페치 조인을 사용하는 것이다.페치 조인은 SQL 조인을 사용해서 연관된 엔티티를 함께 조회하므로 N+1 문제가 발생하지 않는다.하이버네이트 @BatchSize연관된 엔티티를 조회할 때 지정한 size만큼 SQL의 IN 절을 사용해서 조회한다.만약 조회한 회원이 10명인데 size=5로 지정하면 2번의 SQL만 추가로 실행한다.즉시 로딩으로 설정하면 조회 시점에 10건의 데이터를 모두 조회해야 하므로 다음 SQL이 두 번 실행된다.지연 로딩으로 설정하면 지연 로딩된 엔티티를 최초로 사용하는 시점에 다음 SQL을 실행해서 5건의 데이터를 미리 로딩해둔다.그리고 6번째 데이터를 사용하면 다음 SQL을 추가로 실행한다. SELECT * FROM ORDERS WHERE MEMBER_ID IN ( ?, ?, ?, ?, ? )hibernate.defaultbatchfetchsize 속성을 사용하면 애플리케이션 전체에 기본으로 @BatchSize를 적용할 수 있다.하이버네이트 @Fetch(FetchMode.SUBSELECT)연관된 데이터를 조회할 때 서브 쿼리를 사용해서 N+1 문제를 해결한다.다음 JPQL로 회원 식별자 값이 10을 초과하는 회원을 모두 조회해보자 select m from Member m where m.id &amp;gt; 10즉시 로딩으로 설정하면 조회 시점에, 지연로딩으로 설정하면 지연 로딩된 엔티티를 사용하는 시점에 다음 SQL이 실행된다 SELECT O FROM ORDERS O WHERE O.MEMBER_ID IN ( SELECT M.ID FROM MEMBER M WHERE M.ID &amp;gt; 10 )N+1 정리즉시 로딩은 사용하지 말고 지연 로딩만 사용하는 것이다.즉시 로딩 전략은 그렇듯해 보이지만 N+1 문제는 물론이고 비즈니스 로직에 따라 필요하지 않은 엔티티를 로딩해야 하는 상황이 자주 발생즉시 로딩의 가장 큰 문제는 성능 최적화가 어렵다는 점이다.따라서 모두 지연 로딩으로 설정하고 성능 최적화가 꼭 필요한 곳에는 JPQL 페치 조인을 사용하자읽기 전용 쿼리의 성능 최적화엔티티가 영속성 컨텍스트에 관리되면 1차 캐시부터 변경 감지까지 얻을 수 있는 해택이 많다.하지만 영속성 컨텍스트는 변경 감지를 위해 스냅샷 인스턴스를 보관하므로 더 많은 메모리를 사용한다는 단점이 있다.보관하는 인스턴스를 사용할 일이 없담면, 읽기 전용으로 엔티티를 조회하면 메모리 사용량을 최적화할 수 있다.스칼라 타입으로 조회가장 확실한 방법은 엔티티가 아닌 스칼라 타입으로 모든 필드를 조회하는 것이다.스칼라 타입은 영속성 컨텍스트가 결과를 관리하지 않는다. select o.id, o.name, o.price from Order o읽기 전용 쿼리 힌트 사용하이버네이트 전용 힌트인 org.hibernate.readOnly를 사용하면 엔티티를 읽기 전용으로 조회할 수 있다.읽기 전용이므로 영속성 컨텍스트는 스냅샷을 보관하지 않는다. TypedQuery&amp;lt;Order&amp;gt; query = em.createQuery(&quot;select o from Order o&quot;, Order.class); query.setHint(&quot;org.hibernate.readOnly&quot;, true);읽기 전용 트랜잭션 사용스프링 프레임워크를 사용하면 트랜잭션을 읽기 전용 모드로 설정할 수 있다. @Transactional(readOnly = true)읽기 전용 트랜잭션을 사용하면 스프링 프레임워크가 하이버네이트 세션의 플러시 모드를 MANUAL로 설정한다.이렇게 하면 강제로 플러시를 호출하지 않는 한 플러시가 일어나지 않는다.트랜잭션 밖에서 읽기트랜잭션 없이 엔티티를 조회한다는 뜻이다. 조회가 목적일 때만 사용해야 한다. @Transactional(propagation = Propagation.NOT_SUPPORTED) 이렇게 트랜잭션을 사용하지 않으면 플러시가 일어나지 않으므로 조회 성능이 향상 된다.정리메모리를 최적화하려면 스칼라 타입으로 조회하거나 하이버네이트가 제공하는 읽기 전용 쿼리 힌트를 사용플러시 호출을 막아서 속도를 최적화하려면 읽기 전요 ㅇ트랜잭션을 사용하거나 트랜잭션 밖에서 읽기를 사용하면 된다.즉, 메모리를 최적화하면서 플러스 호출을 막는것이 가장 효과적이다.배치 처리배치와 같이 수백만 건의 데이터를 배치 처리해야 하는 상황이라면 엔티티를 계속 조회하면서 영속성 컨텍스트에 아주 많은 엔티티가 쌓이면서 메모리 부족으로 오류가 발생할 것이다.따라서 이런 배치 처리는 적절한 단위로 영속성 컨텍스트를 초기화해야 한다.2차 캐시를 사용하고 있다면 2차 캐시로 엔티티를 보관하지 않도록 주의해야 한다.JPA 등록 배치영속성 컨텍스트에 엔티티가 계속 쌓이지 않도록 일정 단위마다 영속성 컨텍스트의 엔티티를 데이터베이스에 플러시하고 영속성 컨텍스트를 초기화해야 한다.JPA 페이징 배치 처리페이징 쿼리로 조회하면서 처리코드는 책 참고하이버네이트 scroll 사용하이버네이트는 scroll이라는 이름으로 JDBC 커서를 지원한다.scroll은 하이버네이트 전용 기능이므로 먼저 em.unwrap() 메소드를 사용해서 하이버네이트 세션을 구한다.다음으로 쿼리를 조회하면서 scroll() 메소드로 ScrollableResults 객체를 반환받는다.이 객체의 next() 메소드를 호출하면 엔티티를 하나씩 조회할 수 있다.하이버네이트 무상태 세션 사용하이버네이트는 무상태 세션이라는 특별한 기능을 제공무상태 세션은 영속성 컨텍스트를 만들지 않고 심지어 2차 캐시도 사용하지 않는다.무상태 세션은 영속성 컨텍스트가 없다.그리고 엔티티를 수정하려면 무상태 세션이 제공하는 update() 메소드를 직접 호출해야 한다.SQL 쿼리 힌트 사용JPA는 데이터베이스 SQL 힌트 기능을 제공하지 않는다.SQL 힌트를 사용하려면 하이버네이트를 직접 사용해야 한다.SQL 힌트는 하이버네이트 쿼리가 제공하는 addQueryHint() 메소드를 사용한다. Session session = em.unwrap(Session.class); // 하이버네이트 직접 사용 List&amp;lt;Member&amp;gt; list = session.createQuery(&quot;select m from Member m&quot;) .addQueryHint(&quot;FULL (MEMBER)&quot;) // SQL HINT 사용 .list();실행된 SQL은 다음과 같다. select /*+ FULL (MEMBER) */ m.id, m.name from Member m다른 데이터베이스에서 SQL 힌트를 사용하려면 각 방언에서 org.hibernate.dialect.Dialect에 있는 다음 메소드를 오버라이딩해서 기능을 구현해야 한다.트랜잭션을 지원하는 쓰기 지연과 성능 최적화참고로 SQL 배치 최적화 전략은 구현체마다 조금씩 다르다.하이버네이트에서 SQL 배치를 적용하려면 다음과 같이 설정하면 된다. &amp;lt;property name=&quot;hibernate.jdbc.batch_size&quot; value=&quot;50&quot;/&amp;gt;속성값을 50으로 주면 최대 50건씩 모아서 SQL 배치를 실행한다 하지만 같은 SQL일 때만 유효하다.중간에 다른 SQL이 들어가면 1번에 실행할 것을 3번 실행하게 된다.트랜잭션을 지원하는 쓰기 지연과 애플리케이션 확장성트랜잭션을 지원하는 쓰기 지연과 변경 감지 기능 덕분에 성능과 개발의 편의성이라는 두 마리 토끼를 모두 잡을 수 있었다.하지만 진짜 장점은 데이터베이스 테이블 로우에 락이 걸리는 시간을 최소화한다는 점 이다.JPA는 커밋을 해야 플러시를 호출하고 데이터베이스에 수정 쿼리를 보낸다.쿼리를 보내고 바로 트랜잭션을 커밋하므로 결과적으로 데이터베이스에 락이 걸리는 시간을 최소화한다." }, { "title": "자바 ORM 표준 JPA 프로그래밍 - 컬렉션과 부가 기능", "url": "/posts/%EC%9E%90%EB%B0%94_orm_%ED%91%9C%EC%A4%80_jpa_%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D_%EC%BB%AC%EB%A0%89%EC%85%98%EA%B3%BC_%EB%B6%80%EA%B0%80_%EA%B8%B0%EB%8A%A5/", "categories": "Study, Book", "tags": "JPA, ORM", "date": "2021-05-11 00:00:00 +0900", "snippet": "Table of Contents 컬렉션 JPA와 컬렉션 List + @OrderColumn @OrderColumn의 단점 @OrderBy @Converter 글로벌 설정 리스너 이벤트 종류 이벤트 적용 위치 엔티티에 직접 적용 별도의 리스너 등록 기본 리스너 사용 더 세밀한 설정 엔티티 그래프 Named 엔티티 그래프 em.find()에서 엔티티 그래프 사용 subgraph JPQL에서 엔티티 그래프 사용 동적 엔티티 그래프 엔티티 그래프 정리 ROOT에서 시작 이미 로딩된 엔티티 fetchgraph, loadgraph의 차이 컬렉션JPA는 자바에서 기본으로 제공하는 Collection, List, Set, Map 컬렉션을 지원하고 다음의 경우에 이 컬렉션을 사용할 수 있다. @OneToMany, @ManyToMany를 사용해서 일대다, 다대다 엔티티 관계를 매핑할 때 @ElementCollection을 사용해서 값 타입을 하나 이상 보관할 때자바 컬렉션 인터페이스의 특징은 다음과 같다. Collection: 하이버네이트는 중복을 허용하고 순서를 보장하지 않는다고 가정 Set: 중복을 허용하지 않는 컬렉션이다. 순서를 보장하지 않는다. List: 순서가 있는 컬렉션이다. 순서를 보장하고 중복을 허용한다. Map: Key, Value 구조로 된 특수한 컬렉션JPA 명세에는 자바 컬렉션 인터페이스에 대한 특별한 언급이 없다.따라서 JPA 구현체에 따라서 제공하는 기능이 조금씩 다를 수 있다.여기서는 하이버네이트 구현체를 기준으로 이야기한다.JPA와 컬렉션before persist = class java.util.ArrayListafter persist = class org.hibernate.collection.internal.PersistentBag출력 결과를 보면 원래 ArrayList 타입이었다.영속 상태로 만든 직후 하이버네이트가 제공하는 PersistentBag 타입으로 변경되었다.하이버네이트는 컬렉션을 효율적으로 관리하기 위해 엔티티를 영속 상태로 만들 때 원본 컬렉션을 감싸고 있는 내장 컬렉션을 생성해서 이 내장 컬렉션(래퍼 컬렉션)을 사용하도록 참조를 변경한다하이버네이트는 이런 특징 때문에 컬렉션을 사용할 때 다음처럼 즉시 초기화해서 사용하는 것을 권장한다. Collection&amp;lt;Member&amp;gt; members = new ArrayList&amp;lt;Member&amp;gt;();하이버네이트 내장 컬렉션과 특징컬렉션 인터페이스컬렉션중복 허용순서 보관특징Collection, ListPersistenceBagOX엔티티를 추가해도 지연 로딩된 컬렉션을 초기화 XSetPersistenceSetXX엔티티를 추가할 때 지연 로딩된 컬렉션을 초기화List + @OrderColumnPersistentListOO아래 확인List + @OrderColumn데이터베이스에 순서 값을 저장해서 조회할 때 사용한다. @Entity public class Board { @Id @GeneratedValue private Long id; private String title; private String content; @OneToMany(mappedBy = &quot;board&quot;) @OrderColumn(name = &quot;POSITION&quot;) private List&amp;lt;Comment&amp;gt; comments = new ArrayList&amp;lt;Comment&amp;gt;(); ... } @Entity public class Comment { @Id @GeneratedValue private Long id; private String comment; @ManyToOne @JoinColumn(name = &quot;BOARD_ID&quot;) private Board board; ... }@OrderColumn의 단점다음과 같은 단점들 때문에 실무에서 잘 사용하지 않는다. @OrderColumn을 Board 엔티티에서 매핑하므로 Comment는 POSITION의 값을 알 수 없다.그래서 Comment를 INSERT할 때는 POSITION 값이 저장되지 않는다. 추가의 UPDATE SQL이 발생 List를 변경하면 연관된 많은 위치 값을 변경해야 한다. 2번을 삭제하면, 3, 4 .. 위치를 수정해야 한다. 중간에 POSITION 값이 없으면 조회한 List에 null이 보관된다.@OrderBy데이터베이스의 ORDER BY 절을 사용해서 컬렉션을 정렬.모든 컬렉션에서 사용할 수 있다. @Entity public class Team { @Id @GeneratedValue private Long id; private String name; @OneToMany(mappedBy = &quot;team&quot;) @OrderBy(&quot;username desc, id asc&quot;) private Set&amp;lt;Member&amp;gt; members = new HashSet&amp;lt;Member&amp;gt;(); ... } @Entity public class Member { @Id @GeneratedValue private Long id; @Column(name = &quot;MEMBER_NAME&quot;) private String username; @ManyToOne private Team team; ... }@Converter엔티티의 데이터를 변환해서 데이터베이스에 저장하거나 엔티티로 변환해서 가져올수 있다.속성기능기본값converter사용할 컨버터를 지정한다&amp;#xa0;attributeName컨버터를 적용할 필드를 지정&amp;#xa0;disableConversion글로벌 컨버터나 상속 받은 컨버터를 사용하지 않는다.false글로벌 설정모든 Boolean 타입에 컨버터를 적용하려면 아래와 같이 적용하면 된다. @Converter(autoApply = true) public class BooleanToYNConverter implements AttributeConverter&amp;lt;Boolean, String&amp;gt; {}리스너모든 엔티티를 대상으로 언제 어떤 사용자가 삭제를 요청했는지 모두 로그로 남겨야 하는 요구사항이 있다고 가정하자JPA 리스너 기능을 사용하면 엔티티의 생명주기에 따른 이벤트를 처리할 수 있다.이벤트 종류이벤트 적용 위치엔티티에 직접 적용 @Entity public class Duck { @Id @GeneratedValue public Long id; private String name; @PrePersist public void prePersist() { System.out.println(&quot;Duck.prePersist id=&quot; + id); } public void postPersist() { System.out.println(&quot;Duck.postPersist id=&quot; + id); } @PostLoad public void postLoad() { System.out.println(&quot;Duck.postLoad&quot;); } @PreRemove public void preRemove() { System.out.println(&quot;Duck.preRemove&quot;); } @PostRemove public void postRemove() { System.out.println(&quot;Duck.postRemove&quot;); } ... }별도의 리스너 등록 @Entity @EntityListeners(DuckListener.class) public class Duck {...} public class DuckListener { @PrePersist // 특정 타입이 확실하면 특정 타입을 받을 수 있다. private void prePersist(Object obj) { System.out.println(&quot;DuckListener.prePersist obj = [&quot; + obj + &quot;]&quot;); } @PostPersist // 특정 타입이 확실하면 특정 타입을 받을 수 있다. private void postPersist(Object obj) { System.out.println(&quot;DuckListener.postPersist obj = [&quot; + obj + &quot;]&quot;); } }기본 리스너 사용모든 엔티티의 이벤트를 처리하려면 META-INF/orm.xml에 기본 리스너로 등록여러 리스너를 등록했을 때 이벤트 호출 순서는 다음과 같다. 기본 리스너 부모 클래스 리스너 리스너 엔티티더 세밀한 설정 javax.persistence.ExcludeDefaultListeners: 기본 리스너 무시 javax.persistence.ExcludeSuperclassListeners: 상위 클래스 이벤트 리스너 무시엔티티 그래프JPA 2.1에 추가된 엔티티 그래프 기능을 사용하면 엔티티를 조회하는 시점에 함께 조회할 연관된 엔티티를 선택할 수 있다.엔티티 그래프 기능은 엔티티 조회시점에 연관된 엔티티들을 함께 조회하는 기능이다.Named 엔티티 그래프 @NamedEntityGraph(name = &quot;Order.withMember&quot;, attributeNodes = { @NamedAttributeNode(&quot;member&quot;) }) @Entity @Table(name = &quot;ORDERS&quot;) public class Order { @Id @GeneratedValue @Column(name = &quot;ORDER_ID&quot;) private Long id; @ManyToOne(fetch = FetchType.LAZY, optional = false) @JoinColumn(name = &quot;MEMBER_ID&quot;) private Member member; // 주문 회원 //.. }@NamedEntityGraph로 정의한다. name: 엔티티 그래프의 이름을 정의 attributeNodes: 함께 조회할 속성을 선택위의 예제는 지연로딩으로 설정했지만, 엔티티 그래프에서 함께 조회할 속성으로 설정이되어 Order를 조회할 때 연관된 member도 함께 조회둘 이상 정의하려면 @NamedEntityGraphs를 사용하면 된다.em.find()에서 엔티티 그래프 사용 EntityGraph graph = em.getEntityGraph(&quot;Order.withMember&quot;); Map hints = new HashMap(); hints.put(&quot;javax.persistence.fetchgraph&quot;, graph); Order order = em.find(Order.class, orderId, hints);Named 엔티티 그래프를 사용하려면 정의한 엔티티 그래프를 em.getEntityGraph(“Order.withMember”)를 통해서 찾아오면 된다.자세한 내용은 코드 참고subgraphOrder -&amp;gt; OrderItem -&amp;gt; Item까지 함께 조회해보자 @NamedEntityGraph(name = &quot;Order.withAll&quot;, attributeNodes = { @NamedAttributeNode(&quot;member&quot;), @NamedAttributeNode(value = &quot;orderItems&quot;, subgraph = &quot;orderItems&quot;) }, subgraphs = @NamedSubgraph(name = &quot;orderItems&quot;, attributeNodes = { @NamedAttributeNode(&quot;item&quot;) }) ) @Entity @Table(name = &quot;ORDERS&quot;) public class Order { @Id @GeneratedValue @Column(name = &quot;ORDER_ID&quot;) private Long id; @ManyToOne(fetch = FetchType.LAZY, optional = false) @JoinColumn(name = &quot;MEMBER_ID&quot;) private Member member; // 주문 회원 @OneToMany(mappedBy = &quot;order&quot;, cascade = CascadeType.ALL) private List&amp;lt;OrderItem&amp;gt; orderItems = new ArrayList&amp;lt;OrderItem&amp;gt;(); // ... } @Entity @Table(name = &quot;ORDER_ITEM&quot;) public class OrderItem { @Id @GeneratedValue @Column(name = &quot;ORDER_ITEM_ID&quot;) private Long id; @ManyToOne(fetch = FetchType.LAZY) @JoinColumn(name = &quot;ITEM_ID&quot;) private Item item; // 주문 상품 // .. }OrderItem -&amp;gt; Item은 Order의 객체 그래프가 아니므로 subgraphs 속성으로 정의해야 한다.@NamedSubgraph를 사용해서 서브 그래프를 정의한다.JPQL에서 엔티티 그래프 사용em.find와 동일하게 hints만 추가하면 된다. List&amp;lt;Order&amp;gt; resultList = em.createQuery(&quot;select o from Order o where o.id = :orderId&quot;, Order.class) .setParameter(&quot;orderId&quot;, orderId) .setHint(&quot;javax.persistence.fetchgraph&quot;, em.getEntityGraph(&quot;Order.withAll&quot;)) .getResultList();동적 엔티티 그래프createEntityGraph() 메소드를 사용하면 된다. EntityGraph&amp;lt;Order&amp;gt; graph = em.createEntityGraph(Order.class); graph.addAttributeNodes(&quot;member&quot;); Map hints = new HashMap(); hints.put(&quot;javax.persistence.fetchgraph&quot;, graph); Order order = em.find(Order.class, orderId, hints);subgraph 기능을 동적으로 구성 EntityGraph&amp;lt;Order&amp;gt; graph = em.createEntityGraph(Order.class); graph.addAttributeNodes(&quot;member&quot;); Subgraph&amp;lt;OrderItem&amp;gt; orderItems = graph.addSubgraph(&quot;orderItems&quot;); orderItems.addAttributeNodes(&quot;item&quot;); Map hints = new HashMap(); hints.put(&quot;javax.persistence.fetchgraph&quot;, graph); Order order = em.find(Order.class, orderId, hints);엔티티 그래프 정리ROOT에서 시작엔티티 그래프는 항상 조회하는 엔티티의 ROOT에서 시작해야 한다.이미 로딩된 엔티티영속성 컨텍스트에 해당 엔티티가 이미 로딩되어 있으면 엔티티 그래프가 적용되지 않는다.fetchgraph, loadgraph의 차이fetchgraph는 엔티티 그래프에 선택한 속성만 함께 조회한다.loadgraph 속성은 엔티티 그래프에 선택한 속성뿐만 아니라 글로벌 fetch 모드가 EAGER로 설정된 연관관계도 포함해서 함께 조회" }, { "title": "자바 ORM 표준 JPA 프로그래밍 - 웹 애플리케이션과 영속성 관리", "url": "/posts/%EC%9E%90%EB%B0%94_orm_%ED%91%9C%EC%A4%80_jpa_%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D_%EC%9B%B9_%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98%EA%B3%BC_%EC%98%81%EC%86%8D%EC%84%B1_%EA%B4%80%EB%A6%AC/", "categories": "Study, Book", "tags": "JPA, ORM", "date": "2021-05-11 00:00:00 +0900", "snippet": "Table of Contents 트랜잭션 범위의 영속성 컨텍스트 스프링 컨테이너의 기본 전략 트랜잭션이 같으면 같은 영속성 컨텍스트를 사용한다. 트랜잭션이 다르면 다른 영속성 컨텍스트를 사용한다. 준영속 상태와 지연 로딩 글로벌 페치 전략 수정 단점 JPQL 페치 조인 단점 강제로 초기화 FACADE 계층 FACADE 계층의 역할과 특징 OSIV 과거 OSIV: 요청 당 트랜잭션 문제점 스프링 OSIV: 비즈니스 계층 트랜잭션 스프링 프레임워크가 제공하는 OSIV 라이브러리 스프링 OSIV 분석 트랜잭션 없이 읽기 스프링 OSIV 주의사항 OSIV 정리 스프링 OSIV의 특징 스프링 OSIV의 단점 OSIV vs FACADE vs DTO OSIV를 사용하는 방법이 만능은 아니다 OSIV는 같은 JVM을 벗어난 원격 상황에서는 사용할 수 없다. 트랜잭션 범위의 영속성 컨텍스트순수하게 J2EE 환경에서 JPA를 사용하면 개발자가 직접 엔티티 매니저를 생성하고 트랜잭션도 관리해야 한다.하지만 스프링이나 J2EE 컨테이너 환경에서 JPA를 사용하면 컨테이너가 제공하는 전략을 따라야 한다.스프링 컨테이너의 기본 전략스프링 컨테이너는 트랜잭션 범위의 영속성 컨텍스트 전략을 기본으로 사용한다.이 전략은 이름 그대로 트랜잭션의 범위와 영속성 컨텍스트의 생존 범위가 같다는 뜻이다.PersistenceContext 어노테이션을 사용하면 스프링 컨테이너가 엔티티 매니저를 주입해준다. @PersistenceContext EntityManager em;트랜잭션이 같으면 같은 영속성 컨텍스트를 사용한다.트랜잭션 범위의 영속성 컨텍스트 전략은 다양한 위치에서 엔티티 매니저를 주입받아 사용해도 트랜잭션이 같으면 항상 같은 영속성 컨텍스트를 사용한다.트랜잭션이 다르면 다른 영속성 컨텍스트를 사용한다.같은 엔티티 매니저를 사용해도 트랜잭션에 따라 접근하는 영속성 컨텍스트가 다르다.준영속 상태와 지연 로딩스프링이나 J2EE 컨테이너는 트랜잭션 범위의 영속성 컨텍스트 전략을 기본으로 사용한다.지연 로딩의 경우, 영속성 상태에서 동작한다. 하지만 준영속 상태에서는 변경 감지와 지연로딩이 동작하지 않는다.준영속 상태의 지연 로딩 문제를 해결하는 방법은 크게 2가지다. 뷰가 필요한 엔티티를 미리 로딩해두는 방법 OSIV를 사용해서 엔티티를 항상 영속 상태로 유지하는 방법미리 로딩해두는 방법은 어디서 미리 로딩하느냐에 따라 3가지 방법이 있다. 글로벌 페치 전략 수정 JPQL 페치 조인 강제로 초기화글로벌 페치 전략 수정 @ManyToOne(fetch = FetchType.EAGER) private Member member;단점 사용하지 않는 엔티티를 로딩한다. N+1 문제가 발생한다.JPQL 페치 조인페치 조인은 N+1 문제를 해결하면서 화면에 필요한 엔티티를 미리 로딩하는 현실적인 방법이다. select o from Order o join fetch o.member select o.*, m.* from Order o join Member m on o.MEMBER_ID=m.MEMBER_ID단점무분별하게 사용하면 화면에 맞춘 리포지토리 메소드가 증가할 수 있다. 결국 프리젠테이션 계층이 알게 모르게 데이터 접근 계층을 침범하는 것 이다.메소드를 각각 만들면 최적화는 할 수 있지만 뷰와 리포지토리 간에 논리적인 의존관계가 발생한다.결국 적절한 선에서 타협점을 찾는 것이 합리적강제로 초기화하이버네이트를 사용하면 initialize() 메소드를 사용해서 프록시를 강제로 초기화할 수 있다. org.hibernate.Hibernate.initialize(order.getMember()); // 프록시 초기화JPA 표준에서는 프록시 초기화 메소드가 없다. JPA 표준은 단지 초기화 여부만 확인할 수 있다. PersistenceUnitUtil = persistenceUnitUtil = em.getEntityManagerFactory().getPersistenceUnitUtil(); boolean isLoaded = persistenceUnitUtil.isLoaded(order.getMember());프록시를 초기화하는 역활을 서비스 계층이 담당하면 뷰가 필요한 엔티티에 따라 서비스 계층의 로직을 변경해야 한다.프리젠테이션 계층이 서비스 계층을 침범하는 상황이다.FACADE 계층프록시를 초기화하려면 영속성 컨텍스트가 필요하므로 FACADE에서 트랜잭션을 시작해야 한다.FACADE 계층의 역할과 특징 프리젠테이션 계층과 도메인 모델 계층 간의 논리적 의존성을 분리해준다. 프리젠테이션 계층에서 필요한 프록시 객체를 초기화한다. 서비스 계층을 호출해서 비즈니스 로직을 실행한다. 리포지토리를 직접 호출해서 뷰가 요구하는 엔티티를 찾는다.OSIVOpen Session In View의 약자로 영속성 컨텍스트를 뷰까지 열어둔다는 뜻이다.과거 OSIV: 요청 당 트랜잭션요청이 들어오자마자 서블릿 필터나 스프링 인터셉터에서 영속성 컨텍스트를 만들면서 트랜잭션을 시작하고 요청이 끝날 때 트랜잭션과 영속성 컨텍스트를 함께 종료한다.문제점프리젠테이션 계층에서 데이터를 변경했다고 실제 데이터베이스까지 변경 내용이 반영되면 애플리케이션을 유지보수하기 상당히 힘들어진다.프리젠테이션 계층에서 엔티티를 수정하지 못하게 막는 방법은 다음 3가지가 있다.이러한 방법 모두 코드량이 상당히 증가한다는 단점이 있다. 엔티티를 읽기 전용 인터페이스로 제공 프리젠테이션 계층에 읽기 전용 메소드만 제공하는 인터페이스를 프리젠테이션 계층에 제공하는 방법 엔티티 레핑 엔티티의 읽기 전용 메서드만 가지고 있는 엔티티를 감싼 객체를 만들고 이것을 프리젠테이션 계층에 반환하는 방법 DTO만 반환 프리젠테이션 계층에 엔티티 대신에 단순한 데이터만 전달하는 객체인 DTO를 생성해서 반환하는 방법 스프링 OSIV: 비즈니스 계층 트랜잭션스프링 프레임워크가 제공하는 OSIV 라이브러리 하이버네이트 OSIV 서블릿 필터: org.springframework.orm.hibernate4.support.OpenSessionInViewFilter 하이버네이트 OSIV 스프링 인터셉터: org.springframework.orm.hibernate4.support.OpenSessionInViewInterceptor JPA OEIV 서블릿 필터: org.springframeowrk.orm.jpa.support.OpenEntityManagerInViewFilter JPA OEIV 스프링 인터셉터: org.springframewok.orm.jpa.support.OpenEntityManagerInViewInterceptor스프링 OSIV 분석서블릿 필터나, 스프링 인터셉터에서 영속성 컨텍스트를 생성한다. 하지만 트랜잭션은 시작하지 않는다.서비스 계층에서 @Transactional로 트랜잭션을 시작할때 미리 생성해둔 영속성 컨텍스트를 찾아와서 트랜잭션을 시작한다.서비스 계층이 끝나면 트랜잭션을 커밋하고 영속성 컨텍스트를 플러시 한다.이후 서블릿 필터나 스프링 인터셉터로 요청이 돌아오면 플러시를 호출하지 않고 종료한다.트랜잭션 없이 읽기영속성 컨테스트를 통한 모든 변경은 트랜잭션 안에서 이루어져야 한다. 만약 그렇지 않다면, TransactionRequiredException이 발생스프링이 제공하는 OSIV를 사용하면 프리젠테이션 계층에서는 트랜잭션 없으므로 엔티티를 수정할 수 없다.따라서 프리젠테이션 계층에서 엔티티를 수정할 수 있는 기존 OSIV의 단점을 보완했다.스프링 OSIV 주의사항프리젠테이션 계층에서 엔티티를 수정한 직후에 트랜잭션을 시작하는 서비스 계층을 호출하면 문제가 발생따라서 트랜잭션이 있는 비즈니스 로직을 모두 호출하고 엔티티를 변경하면 된다.OSIV 정리스프링 OSIV의 특징 OSIV는 클라이언트의 요청이 들어올 때 영속성 컨텍스트를 생성해서 요청이 끝날 때까지 같은 영속성 컨텍스트를 유지한다. 엔티티 수정은 트랜잭션이 있는 계층에서만 동작한다. 그 외 계층에서는 조회만 지원스프링 OSIV의 단점 영속성 컨텍스트를 여러 트랜잭션이 공유할 수 있다는 점을 주의해야 한다. 프리젠테이션 계층에서 엔티티를 수정하고나서 비즈니스 로직을 수행하면 엔티티가 수정될 수 있다. 프리젠테이션 계층에서 지연로딩 SQL이 실행, 성능 튜닝시에 확인해야 할 부분이 많다.OSIV vs FACADE vs DTO결국에 준영속 상태가 되기 전에 프록시를 초기화하는 방법이다.OSIV와 비교해서 다른 것들은 코드를 많이 작성해야 한다.OSIV를 사용하는 방법이 만능은 아니다OSIV를 사용하면 화면에 출력할 때 엔티티를 유지하면서 객체 그래프를 마음껏 탐색할 수 있다.하지만 복잡한 화면을 구성할 때는 이 방법이 효과적이지 않은 경우가 많다.이때는 엔티티를 직접 조회하기보다는 JPQL로 필요한 데이터들만 조회해서 DTO로 반환하는 것이 더 나은 해결책이 될수 있다.OSIV는 같은 JVM을 벗어난 원격 상황에서는 사용할 수 없다.외부 API는 엔티티를 직접 노출하기보다는 엔티티를 변경해도 완충 역활을 할 수 있는 DTO로 변환해서 노출하는 것이 안전하다.내부 API는 엔티티를 변경해도 클라이언트와 서버를 동시에 수정할 수 있어서 실용적인 관점에서 엔티티를 직접 노출하는 방법도 괜찮다고 생각한다." }, { "title": "자바 ORM 표준 JPA 프로그래밍 - 스프링 데이터 JPA", "url": "/posts/%EC%9E%90%EB%B0%94_orm_%ED%91%9C%EC%A4%80_jpa_%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D_%EC%8A%A4%ED%94%84%EB%A7%81_%EB%8D%B0%EC%9D%B4%ED%84%B0_JPA/", "categories": "Study, Book", "tags": "JPA, ORM", "date": "2021-05-05 00:00:00 +0900", "snippet": "Table of Contents 스프링 데이터 JPA 설정 공통 인터페이스 기능 쿼리 메소드 기능 메소드 이름으로 쿼리 생성 JPA NamedQuery @Query, 리포지토리 메소드에 쿼리 정의 파라미터 바인딩 벌크성 수정 쿼리 반환 타입 페이징과 정렬 힌트 Lock 명세 사용자 정의 리포지토리 구현 WEB 확장 설정 도메인 클래스 컨버터 기능 페이징과 정렬 기능 접두사 기본값 스프링 데이터 JPA가 사용하는 구현체 스프링 데이터 JPA가 제공하는 공통 인터페이스는 SimpleJpaRepository 클래스가 구현한다. 새로운 엔티티를 판단하는 전략 스프링 데이터 JPA와 QueryDSL 통합 QueryDslPredicateExecutor 사용 QueryDslRepositorySupport 사용 스프링 데이터 JPA 설정 @Configuration @EnableJpaRepositories(basePackages = &quot;검색할 패키지 위치&quot;) public class AppConfig {}공통 인터페이스 기능 public interface MemberRepository extends JpaRepository&amp;lt;Member, Long&amp;gt; {}스프링 데이터 JPA를 사용하는 가장 단순한 방법은 위의 인터페이스를 상속받는 것이다.JpaRepository 인터페이스의 계층 구조쿼리 메소드 기능 메소드 이름으로 쿼리 생성 메소드 이름으로 JPA NamedQuery 호출 @Query 어노테이션을 사용해서 리포지토리 인터페이스에 쿼리 직접 정의메소드 이름으로 쿼리 생성 public interface MemberRepository extends Repository&amp;lt;Member, Long&amp;gt; { List&amp;lt;Member&amp;gt; findByEmailAndName(String email, String name); }인터페이스에 정의한 findByEmailAndName 메소드를 실행하면 스프링 데이터 JPA는 메소드 이름을 분석해서 JPQL을 생성하고 실행한다.JPA NamedQuery스프링 데이터 JPA는 메소드 이름으로 JPA Named 쿼리를 호출하는 기능을 제공한다.JPA Named 쿼리는 이름 그대로 쿼리에 이름을 부여해서 사용하는 방법(어노테이션, XML등에 지정)스프링 데이터 JPA를 사용하면 아래와 같이 메소드 이름만으로 Named 쿼리를 호출할 수 있다. public interface MemberRepository extends JpaRepository&amp;lt;Member, Long&amp;gt; { // 여기 선언한 Member 도메인 클래스 List&amp;lt;Member&amp;gt; findByUsername(@Param(&quot;username&quot;) String username); }스프링 데이터 JPA는 선언한 “도메인 클래스 + . + 메소드 이름”으로 Named 쿼리를 찾아서 실행만약 실행할 Named 쿼리가 없으면 메소드 이름으로 쿼리 생성 전략을 사용한다.@Query, 리포지토리 메소드에 쿼리 정의메소드에 정적 쿼리를 직접 작성하는 방법으로 이름 없는 Named 쿼리라 할 수 있다. public interface MemberRepository extends JpaRepository&amp;lt;Member, Long&amp;gt; { @Query(&quot;select m from Member m where m.username = ?1&quot;) Member findByUsername(String username); }네이티브 SQL을 사용하려면 @Query 어노테이션에 nativeQuery = true를 설정하면 된다.JPQL은 위치 기반 파라미터를 1부터 시작하지만 네이티브 SQL은 0부터 시작한다.파라미터 바인딩위치 기반 파라미터 바인딩과 이름 기반 파라미터 바인딩을 모두 지원 select m from Member m where m.username = ?1 select m from Member m where m.username = :name기본 값은 위치 기반이름 기반 파라미터 바인딩을 사용하려면 org.springframework.data.repository.query.Param 어노테이션을 사용하면 된다.코드 가독성과 유지보수를 위해 이름 기반 파라미터 바인딩을 사용하자벌크성 수정 쿼리 @Modifying @Query(&quot;update Product p set p.price = p.price * 1.1 where p.stockAmount &amp;lt; :stockAmount&quot; int bulkPriceUp(@Param(&quot;stockAmount&quot;) String stockAmount);스프링 데이터 JPA에서 벌크성 수정 삭제 쿼리는 org.springframework.data.repository.Modifying 어노테이션을 사용하면 된다.벌크성 쿼리를 실행하고 나서 영속성 컨텍스트를 초기화하고 싶으면 @Modifying(clearAutomatically = true로 설정하면 된다.기본값은 false이다.반환 타입결과가 한 건 이상이면 컬렉션 인터페이스를 사용단건이면 반환 타입을 지정한다. List&amp;lt;Member&amp;gt; findByName(String name); Member findByEmail(String email);조회 결과가 없으면 컬렉션은 빈 컬렉션을 반환하고 단건은 null을 반환한다.단건을 기대하고 반환 타입을 지정했는데 결과가 2건 이상 조회되면 NonUniqueResultException 예외가 발생한다.페이징과 정렬 org.springframework.data.domain.Sort: 정렬 기능 org.springframework.data.domain.Pageable: 페이징 기능(내부에 Sort 포함)Pageable을 사용하면 반환 타입으로 List나 org.springframework.data.domain.Page를 사용할 수 있다.Page를 사용하면 스프링 데이터 JPA는 페이징 기능을 제공하기 위해 검색된 전체 데이터 건수를 조회하는 count 쿼리를 추가로 호출한다. public interface MemberRepository extends Repository&amp;lt;Member, Long&amp;gt; { Page&amp;lt;Member&amp;gt; findByNameStartingWith(String name, Pageable Pageable); }위의 예제에서 두 번째 파라미터로 받은 Pageable은 인터페이스다.해당 인터페이스를 구현한 PageRequest 객체를 사용한다.힌트JPA 쿼리 힌트를 사용하려면 QueryHints 어노테이션을 사용하면 된다.이것은 SQL 힌트가 아니라 JPA 구현체에게 제공하는 힌트다. @QueryHints(value = { @QueryHint(name = &quot;org.hibernate.readOnly&quot;, value = &quot;true&quot;)}, forCounting = true)forCounting 속성은 반환 타입으로 Page 인터페이스를 적요앟면 추가로 호출하는 count 쿼리에도 쿼리 힌트를 적용할지를 설정하는 옵션이다.Lock @Lock(LockModeType.PESSIMISTIC_WIRTE) List&amp;lt;Member&amp;gt; findByName(String name);명세DDD에서 명세라는 개념을 소개하는데, 스프링 데이터 JPA는 JPA Criteria로 이 개념을 사용할 수 있도록 지원한다.Spectification은 컴포지트 패턴으로 구성되어 있어서 여러 Specification을 조합할 수 있다.명세 기능을 사용하려면 JpaSpecificationExecutor 인터페이스를 상속받으면 된다. public interface OrderRepository extends JpaRepository&amp;lt;Order, Long&amp;gt;, JpaSpecificationExecutor&amp;lt;Order&amp;gt; {}JpaSpecificationexecutor는 Specification을 파라미터로 받아서 검색 조건으로 사용한다. List&amp;lt;Order&amp;gt; result = orderRepository.findAll( where(memberName(name)).and(isOrderStatus()) );Specifications는 명세들을 조립할 수 있도록 도와주는 클래스인데 where, and, or, not 메소드를 제공한다. public class OrderSpec { public static Specification&amp;lt;Order&amp;gt; memberNameLike(final String memberName) { return new Specification&amp;lt;Order&amp;gt;() { public Predicate toPredicate(Root&amp;lt;Order&amp;gt; root, CriteriaQuery&amp;lt;?&amp;gt; query, CriteriaBuilder builder) { if (StringUtils.isEmpty(memberName)) return null; Join&amp;lt;Order, Member&amp;gt; m = root.join(&quot;member&quot;, JoinType.INNER); //회원과 조인 return builder.like(m.&amp;lt;String&amp;gt;get(&quot;name&quot;), &quot;%&quot; + memberName + &quot;%&quot;); } }; } public static Specification&amp;lt;Order&amp;gt; orderStatusEq(final OrderStatus orderStatus) { return new Specification&amp;lt;Order&amp;gt;() { public Predicate toPredicate(Root&amp;lt;Order&amp;gt; root, CriteriaQuery&amp;lt;?&amp;gt; query, CriteriaBuilder builder) { if (orderStatus == null) return null; return builder.equal(root.get(&quot;status&quot;), orderStatus); } }; } }명세를 정의하려면 Specification 인터페이스를 구현하면 된다.사용자 정의 리포지토리 구현일단 사용자 정의 인터페이스를 작성해야 한다. 이름은 자유롭게 지으면 된다. public interface CustomOrderRepository { public List&amp;lt;Order&amp;gt; search(); }이제 사용자 정의 인터페이스를 구현한 클래스를 작성클래스 이름을 짓는 규칙이 있는데 리포지토리 인터페이스 이름 + Impl로 지어야 한다.이렇게 하면 스프링 데이터 JPA가 사용자 정의 구현 클래스로 인식한다. public class OrderRepositoryImpl implements CustomOrderRepository { @Override public List&amp;lt;Order&amp;gt; search() { } }마지막으로 리포지토리 인터페이스에서 사용자 정의 인터페이스를 상속받으면 된다. public interface OrderRepository extends JpaRepository&amp;lt;Order, Long&amp;gt;, CustomOrderRepository {}WEB 확장스프링 데이터 프로젝트는 스프링 MVC에서 사용할 수 있는 편리한 기능을 제공한다.설정스프링 데이터가 제공하는 Web 확장 기능을 활성화하려면 org.springframework.data.web.config.SpringDataWebConfiguration을 스프링 빈으로 등록하면 된다.JavaConfig를 사용하면 EnableSpringDataWebSupport 어노테이션을 사용하면 된다.설정을 완료하면 도메인 클래스 컨버터와 페이징과 정렬을 위한 HandlerMethodArgumentResolver가 스프링 빈으로 등록된다.등록되는 도메인 클래스 컨버터는 DomainClassConverter이다.도메인 클래스 컨버터 기능도메인 클래스 컨버터는 HTTP 파라미터로 넘어온 엔티티의 아이디로 엔티티 객체를 찾아서 바인딩해준다. @RequestMapping(&quot;member/memberUpdateForm&quot;) public String memberUpdateForm(@RequestParam(&quot;id&quot;) Member member, Model model) { model.addAtrribute(&quot;member&quot;, member); return &quot;member/memberSaveForm&quot;; }Http 요청으로 회원 아이디를 받지만 도메인 클래스 컨버터가 중간에 동작해서 아이디를 회원 인티티 객체로 변환해서 넘겨준다.도메인 클래스 컨버터는 해당 엔티티와 관련된 리포지토리를 사용해서 엔티티를 찾는다.페이징과 정렬 기능스프링 데이터가 제공하는 페이징과 정렬 기능을 스프링 MVC에서 편리하게 사용할 수 있도록 HandlerMethodArgumentResolver를 제공한다. 페이징 기능: PageableHandlerMethodArgumentResolver 정렬 기능: SortHandlerMethodArgumentResolver @RequestMapping(value = “/members”, method = RequestMethod.GET)public String list(Pageable pageable, Model model) {} Pageable은 다음 요청 파라미터 정보로 만들어진다. page: 현재 페이지, 0부터 시작 size: 한 페이지에 노출할 데이터 건수 sort: 정렬 조건을 정의접두사사용해야 할 페이징 정보가 둘 이상이면 접두사를 사용해서 구분할 수 있다. public String list( @Qualifier(&quot;member&quot;) Pageable memberPageable, @Qualifier(&quot;order&quot;) Pageable orderPageable, ...)예 /members?memberpage=0&amp;amp;orderpage=1기본값Pageable의 기본값은 page=0, size=20이다.변경하고 싶으면 @PageableDefault 어노테이션을 사용하면 된다. @RequestMapping(..) public String list(@PageableDefault(size = 12, sort = &quot;name&quot;, direction = Sort.Direction.DESC) Pageable pageable)스프링 데이터 JPA가 사용하는 구현체스프링 데이터 JPA가 제공하는 공통 인터페이스는 SimpleJpaRepository 클래스가 구현한다. @Repository 적용: JPA 예외를 스프링이 추상화한 예외로 변환 @Transactional 트랜잭션 적용: 데이터를 변경하는 메소드에 적용되어 있다. @Transactional(readOnly = true): 데이터를 조회하는 메소드에 적용되어 있다. save() 메소드: 새로운 엔티티면 저장하고 이미 있는 엔티티면 병합한다.새로운 엔티티를 판단하는 전략기본 전략은 엔티티의 식별자로 판단, 식별자가 객체일 때 null, 자바 기본 타입일 때 숫자 0 값이면 새로운 엔티티로 판단한다.필요하면 Persistable 인터페이스를 구현해서 판단 로직을 변경할 수 있다.스프링 데이터 JPA와 QueryDSL 통합스프링 데이터 JPA는 2가지 방법으로 QueryDSL을 지원한다. QueryDslPredicateExecutor QueryDslRepositorySupportQueryDslPredicateExecutor 사용 public interface ItemRepository extends JpaRepository&amp;lt;Item, Long&amp;gt;, QueryDslPredicateExecutor&amp;lt;Item&amp;gt; {}QueryDslPredicateExecutor는 스프링 데이터 JPA에서 편리하게 QueryDSL을 사용할 수 있지만 기능에 한계가 있다.예를 들어 join, fetch를 사용할 수 없다.QueryDslRepositorySupport 사용QueryDSL의 모든 기능을 사용하려면 JPAQuery 객체를 직접 생성해서 사용하면 된다.이때 스프링 데이터 JPA가 제공하는 QueryDslRepositorySupport를 상속 받아 사용하면 조금 더 편리하게 QueryDSL을 사용할 수 있다. public interface CustomOrderRepository { public List&amp;lt;Order&amp;gt; search(OrderSearch orderSearch); } public class OrderRepositoryImpl extends QueryDslRepositorySupport implements CustomOrderRepository { public OrderRepositoryImpl() { super(Order.class); } @Override public List&amp;lt;Order&amp;gt; search(OrderSearch orderSearch) { QOrder order = QOrder.order; QMember member = QMember.member; JPQLQuery query = from(order); if (StringUtils.hasText(orderSearch.getMemberName())) { query.leftJoin(order.member, member) .where(member.name.contains(orderSearch.getMemberName())); } if (orderSearch.getOrderStatus() != null) { query.where(order.status.eq(orderSearch.getOrderStatus())); } return query.list(order); } }" }, { "title": "자바 ORM 표준 JPA 프로그래밍 - 값 타입", "url": "/posts/%EC%9E%90%EB%B0%94_orm_%ED%91%9C%EC%A4%80_jpa_%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D_%EA%B0%92_%ED%83%80%EC%9E%85/", "categories": "Study, Book", "tags": "JPA, ORM", "date": "2021-05-04 00:00:00 +0900", "snippet": "Table of Contents 임베디드 타입(복합 값 타입) 임베디드 타입과 연관관계 @AttributeOverride: 속성 재정의 임베디드 타입과 null 값 타입과 불변 객체 값 타입 공유 참조 불변 객체 값 타입의 비교 값 타입 컬렉션 값 타입 컬렉션 사용 값 타입 컬렉션의 제약사항 임베디드 타입(복합 값 타입)새로운 값 타입을 직접 정의해서 사용할 수 있는데, JPA에서는 이것을 임베디드 타입이라 한다.중요한 것은 직접 정의한 임베디드 타입도 int, String 처럼 값 타입이라는 것이다. @Entity public class Member { @Id @GeneratedValue @Column(name = &quot;MEMBER_ID&quot;) private Long id; private String name; @Embedded private Period workPeriod; // 근무 기간 @Embedded private Address homeAddress; // 집 주소 ... } @Embeddable public class Period { @Temporal(TemporalType.DATE) Date startDate; @Temporal(TemporalType.DATE) Date endDate; ... } @Embeddable public class Address { @Column(name=&quot;city&quot;) private String city; private String street; private String zipcode; ... }임베디드 타입을 사용하려면 다음 2가지 어노테이션이 필요하다. 참고로 둘 중 하나는 생략해도 된다. @Embeddable: 값 타입을 정의하는 곳에 표시 @Embedded: 값 타입을 사용하는 곳에 표시임베디드 타입은 엔티티의 값일 뿐이다. 따라서 값이 속한 엔티티의 테이블에 매핑한다.임베디드 타입과 연관관계임베디드 타입은 값 타입을 포함하거나 엔티티를 참조할 수 있다.예제는 생략@AttributeOverride: 속성 재정의 @Entity public class Member { @Id @GeneratedValue private Long id; private String name; @Embedded Address homeAddress; @Embedded @AttributeOverrides({ @AttributeOverride(name=&quot;city&quot;, column=@Column(name = &quot;COMPANY_CITY&quot;)), @AttributeOverride(name=&quot;street&quot;, column=@Column(name = &quot;COMPANY_STREET&quot;)), @Attributeoverride(name=&quot;zipcode&quot;, column=@Column(name = &quot;COMPANY_ZIPCODE&quot;)) }) Address companyAddress; } CREATE TABLE MEMBER ( COMPANY_CITY varchar(255), COMPANY_STREET varchar(255), COMPANY_ZIPCODE varchar(255), city varchar(255), street varchar(255), zipcode varchar(255), ... )@AttributeOverrides는 엔티티에 설정해야 한다. 임베디드 타입이 임베디드 타입을 가지고 있어도 엔티티에 설정해야 한다.임베디드 타입과 null임베디드 타입이 null이면 매핑한 컬럼 값은 모두 null이 된다.값 타입과 불변 객체값 타입은 복잡한 객체 세상을 조금이라도 단순화하려고 만든 개념이다. 따라서 값 타입은 단순하고 안전하게 다룰 수 있어야 한다.값 타입 공유 참조임베디드 타입 같은 값 타입을 여러 엔티티에서 공유하면 위험하다.공유 참조의 변경은 공유해서 참조하는 모든 객체에 영향을 주고, 그 영향은 실제 DB에도 영향을 준다.이러한 부작용을 막을려면 값을 복수해서 사용하면 된다.문제는 복사하지 않고 원본의 참조 값을 직접 넘기는 것을 막을 방법이 없다는 것이다.객체의 공유 참조는 피할 수 없다.따라서 근본적인 해결책이 필요한데 가장 단순한 방법은 객체의 값을 수정하지 못하게 막으면 된다.불변 객체객체를 불변하게 만들면 값을 수정할 수 없으므로 부작용을 원천 차단할 수 있다.따라서 값 타입은 될 수 있으면 불변 객체로 설계해야 한다.값 타입의 비교자바가 제공하는 개체 비교는 2가지다. 동일성 비교 : 인스턴스의 참조 값을 비교, == 사용 동등성 비교 : 인스턴스의 값을 비교, equals() 사용값 타입을 비교할 때는 동등성 비교를 해야 한다.값 타입 컬렉션값 타입을 하나 이상 저장하려면 컬렉션에 보관하고 @ElementCollection, @CollectionTable 어노테이션을 사용하면 된다. @Entity public class Member { @Id @GeneratedValue private Long id; @Embedded private Address homeAddress; @ElementCollection @CollectionTable(name = &quot;FAVORITE_FOODS&quot;, joinColumns = @JoinColumn(name = &quot;MEMBER_ID&quot;)) @Column(name=&quot;FOOD_NAME&quot;) private Set&amp;lt;String&amp;gt; favoriteFoods = new HashSet&amp;lt;String&amp;gt;(); @ElementCollection @CollectionTable(name = &quot;ADDRESS&quot;, joinColumns = @JoinColumn(name = &quot;MEMBER_ID&quot;)) private List&amp;lt;Address&amp;gt; addressHistory = new ArrayList&amp;lt;Address&amp;gt;(); ... } @Embeddable public class Address { @Column private String city; private String streed; private String zipcode; ... }값 타입 컬렉션 사용값 타입 컬렉션은 영속성 전이(Cascade) + 고아 객체 제거(ORPHAN REMOVE) 기능을 필수로 가진다.값 타입 컬렉션도 조회할 때 페치 전략을 선택할 수 있는데 LAZY가 기본이다.값 타입 컬렉션의 제약사항값 타입은 식별자라는 개념이 없고 단순한 값들의 모음이므로 값을 변경해버리면 데이터베이스에 저장된 원본 데이터를 찾기는 어렵다.특정 엔티티 하나에 소속된 값 타입은 값이 변경되어도 자신이 소속된 엔티티를 데이터베이스에서 찾고 값을 변경하면 된다.문제는 값 타입 컬렉션이다.값 타입 컬렉션에 보관된 값 타입들은 별도의 테이블에 보관된다.따라서 여기에 보관된 값 타입의 값이 변경되면 데이터베이스에 있는 원본 데이터를 찾기 어렵다는 문제가 있다.이러한 문제로 인해 JPA 구현체들은 값 타입 컬렉션에 변경 사항이 발생하면, 값 타입 컬렉션이 매핑된 테이블의 연관된 모든 데이터를 삭제하고, 현재 값 타입 컬렉션 객체에 있는 모든 값을 데이터베이스에 다시 저장한다.따라서 실무에서는 값 타입 컬렉션이 매핑된 테이블에 데이터가 많다면 값 타입 컬렉션 대신에 일대다 관계를 고려해야 한다.추가로 값 타입 컬렉션을 매핑하는 테이블은 모든 컬럼을 묶어서 기본 키를 구성해야 한다.따라서 데이터베이스 기본 키 제약 조건으로 인해 컬럼에 null을 입력할 수 없고, 같은 값을 중복해서 저장할 수 없는 제약도 있다.지금까지 설명한 문제를 해결하러면 값 타입 컬렉션을 사용하는 대신 새로운 엔티티를 만들어서 일대다 관계로 설정하면 된다.영속성 전이(Cascade) + 고아 객체 제거(ORPHAN REMOVE) 기능을 적용하면 값 타입 컬렉션처럼 사용할 수 있다." }, { "title": "자바 ORM 표준 JPA 프로그래밍 - 프록시와 연관관계 관리", "url": "/posts/%EC%9E%90%EB%B0%94_orm_%ED%91%9C%EC%A4%80_jpa_%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D_%ED%94%84%EB%A1%9D%EC%8B%9C%EC%99%80_%EC%97%B0%EA%B4%80%EA%B4%80%EA%B3%84_%EA%B4%80%EB%A6%AC/", "categories": "Study, Book", "tags": "JPA, ORM", "date": "2021-04-28 00:00:00 +0900", "snippet": "Table of Contents 프록시 프록시 기초 프록시의 특징 프록시와 식별자 프록시 확인 즉시 로딩과 지연 로딩 즉시 로딩 지연 로딩 JPA 기본 폐치 전략 컬렉션에 즉시 로딩 사용 시 주의점 영속성 전이: CASCADE CASCADE의 종류 고아 객체프록시 지연로딩 : 엔티티가 실제로 사용될 때까지 데이터베이스 조회를 지연하는 방법을 제공 프록시 : 지연 로딩 기능을 사용하려면 실제 엔티티 객체 대신에 데이터베이스 조회를 지연할 수 있는 가짜 객체가 필요한데 이것을 프록시 객체프록시 기초 Member member = em.getReference(Member.class, &quot;member1&quot;);위와 같은 코드는 데이터베이스에서 바로 조회하지 않고 실제 엔티티 객체도 생성하지 않는다.대신 데이터베이스 접근을 위임한 프록시 객체를 반환한다.프록시의 특징 처음 사용할 때 한 번만 초기화된다. 프록시 객체가 초기화되면 프록시 객체를 통해서 실제 엔티티에 접근할 수 있다. 프록시 객체는 원본 엔티티를 상속받은 객체이므로 타입 체크 시에 주의해서 사용해야 한다. 영속성 컨텍스트에 찾는 엔티티가 이미 있으면 데이터베이스를 조회할 필요가 없으므로 em.getReference()를 호출해도 프록시가 아닌 실제 엔티티를 반환 초기화는 영속성 컨텍스트의 도움을 받아야 가능하다. 따라서 영속성 컨텍스트의 도움을 받을 수 없는 준영속 상태의 프록시를 초기화하면 문제가 발생한다.프록시와 식별자엔티티를 프록시로 조회할 때 식별자 값을 파라미터로 전달하는데 프록시 객체는 이 식별자 값을 보관한다.식별자 값을 조회하는 team.getId()를 호출해도 프록시를 초기화하지 않는다.단 엔티티 접근 방식을 프로퍼티(@Access(AccessType.PROPERTY)로 설정한 경우에만 초기화하지 않는다.엔티티 접근 방식을 필드(@Access(AccessType.FIELD)로 설정하면 JPA는 getId() 메소드가 Id만 조회하는 메소드인지 다른 필드까지 활용해서 어떤 일을 하는 메소드인지 알지 못하므로 프록시 객체를 초기화한다.프록시는 다음 코드처럼 연관관계를 설정할 때 유용하게 사용할 수 있다. Member member = em.find(Member.class, &quot;member1&quot;); Team team = em.getReference(Team.class, &quot;team1&quot;); member.setTeam(team);참고로 연관관계를 설정할 때는 엔티티 접근 방식을 필드로 설정해도 프록시를 초기화하지 않는다.프록시 확인PersistenceUnitUtil.isLoaded(Object entity) 메소드를 사용하면 프록시 인스턴스의 초기화 여부를 확인할 수 있다. 초기화가 안 되었다면 false 초기화가 됐거나 프록시 인스턴스가 아니면 true조회한 엔티티가 진짜 엔티티인지 프록시로 조회한 것인지 확인할려면 클래스명을 직접 출력해보면 된다.클래스 명 뒤에 ..javaassit..라 되어 있다면 프록시이다. 하지만, 프록시를 생성하는 라이브러리에 따라 출력 결과는 달라질 수 있다.즉시 로딩과 지연 로딩즉시 로딩즉시 로딩을 사용하면 엔티티를 조회할 때 연관된 엔티티도 함께 조회한다.FetchType.EAGER로 지정한다.지연 로딩연관된 엔티티를 실제 사용할 때 조회한다.FetchType.LAZY로 지정한다.JPA 기본 폐치 전략 @ManyToOne, @OneToOne: 즉시 로딩 @OneToMany, @ManyToMany: 지연 로딩연관된 엔티티가 하나면 즉시 로딩, 컬렉션이면 지연 로딩추천하는 방법은 모든 연관관계에 지연 로딩을 사용하는 것이다. 그리고 애플리케이션 개발이 어느 정도 완료단계에 왔을 때 실제 사용하는 상황을 보고 꼭 필요한 곳에만 즉시 로딩을 사용하도록 최적화하면 된다.컬렉션에 즉시 로딩 사용 시 주의점 컬렉션을 하나 이상 즉시 로딩하는 것은 권장하지 않는다. 컬렉션 즉시 로딩은 항상 외부 조인을 사용한다. @ManyToOne, @OneToOne (optional = false): 내부 조인 (optional = true): 외부 조인 @OneToMany, @ManyToMany (optional = false): 외부 조인 (optional = true): 외부 조인 영속성 전이: CASCADE특정 엔티티를 영속 상태로 만들 때 연관된 엔티티도 함께 영속 상태로 만들고 싶으면 영속성 전이 기능을 사용하면 된다.JPA는 CASCADE 옵션으로 영속성 전이를 제공한다.아래는 예제 코드 @Entity public class Parent { ... @OneToMany(mappedBy = &quot;parent&quot;, cascade = CascadeType.PERSIST) private List&amp;lt;Child&amp;gt; children = new ArrayList&amp;lt;Child&amp;gt;(); ... }CASCADE의 종류 public enum CascadeType { ALL, // 모두 적용 PERSIST, // 영속 MERGE, // 병합 REMOVE, // 삭제 REFRESH, // REFRESH DETACH // DETACH }참고로 CascadeType.PERSIST, CascadeType.REMOVE는 em.persist(), em.remove()를 실행할 때 바로 전이가 발생하지 않고 플러시를 호출할 때 전이가 발생한다.고아 객체JPA는 부모 엔티티와 연관관계가 끊어진 자식 엔티티를 자동으로 삭제하는 기능을 제공하는데 이것을 고아 객체 제거 라 한다. @Entity public class Parent { @Id @GeneratedValue private Long id; @OneToMany(mappedBy = &quot;parent&quot;, orphanRemoval = true) private List&amp;lt;Child&amp;gt; children = new ArrayList&amp;lt;Child(); ... } Parent parent1 = em.find(Parent.class, id); parent1.getChildren().remove(0);위와 같이 고아 객체 제거 옵션을 키고 제거한 경우 데이터베이스에서도 고아 객체는 삭제된다.참조가 제거된 엔티티는 다른 곳에서 참조하지 않는 고아 객체로 보고 삭제하는 기능 이다.따라서 이 기능은 참조하는 곳이 하나일 때만 사용해야 한다.삭제한 엔티티를 다른 곳에서도 참조한다면 문제가 발생할 수 있다.이러한 이유로 @OneToOne, @OneToMany에서만 사용할 수 있다.또한 부모를 제거할 경우, 자식은 고아가 된다.그래서 자식도 같이 제거하게 된다." }, { "title": "자바 ORM 표준 JPA 프로그래밍 - 고급 매핑", "url": "/posts/%EC%9E%90%EB%B0%94_orm_%ED%91%9C%EC%A4%80_jpa_%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D_%EA%B3%A0%EA%B8%89_%EB%A7%A4%ED%95%91/", "categories": "Study, Book", "tags": "JPA, ORM", "date": "2021-04-27 00:00:00 +0900", "snippet": "Table of Contents 상속 관계 매핑 조인 전략 장점 단점 특징 단일 테이블 전략 장점 단점 특징 구현 클래스마다 테이블 전략 장점 단점 특징 @MappedSuperclass 복합 키와 식별 관계 매핑 식별 관계 vs 비식별 관계 식별 관계 비식별 관계 복합 키: 비식별 관계 매핑 @IdClass @EmbeddedId @IdClass vs @EmbeddabledId 복합 키: 식별 관계 매핑 @IdClass와 식별관계 @EmbeddabledId와 식별 관계 비식별 관계로 구현 일대일 식별 관계 식별, 비식별 관계의 장단점 조인 테이블 일대일 조인 테이블 일대다 조인 테이블 다대일 조인 테이블 다대다 조인 테이블 엔티티 하나에 여러 테이블 매핑상속 관계 매핑관계형 데이터베이스에는 객체지향 언어에서 다루는 상속이라는 개념이 없다. 대신 슈퍼타입 서브타입 관계라는 모델링 기법이 객체의 상속 개념과 가장 유사하다.ORM에서 이야기하는 상속 관계 매핑은 객체의 상속 구조와 데이터베이스의 슈퍼타입 서브타입 관계를 매핑하는 것.슈퍼타입 서브타입 논리 모델을 실제 물리 모델인 테이블로 구현할 때는 3가지 방법을 선택 각각의 테이블로 변환 : 모두 테이블로 만들고 조회할 때 조인을 사용. JPA에서는 조인 전략 이라 한다. 통합 테이블로 변환 : 테이블을 하나만 사용해서 통합한다. JPA에서는 단일 테이블 전략 이라 한다. 서브타입 테이블로 변환 : 서브 타입마다 하나의 테이블을 만든다. JPA에서는 구현 클래스마다 테이블 전략 이라 한다.조인 전략엔티티 각각을 모두 테이블로 만들고 자식 테이블이 부모 테이블의 기본 키를 받아서 기본 키 + 외래 키로 사용하는 전략객체는 타입으로 구분할 수 있지만 테이블은 타입의 개념이 없다. 따라서 타입을 구분하는 컬럼을 추가 해야 한다. @Entity @Inheritance(strategy = InheritanceType.JOINED) @DiscriminatorColumn(name = &quot;DTYPE&quot;) // 구분 컬럼 지정 public abstract class Item { @Id @GeneratedValue @Column(name = &quot;ITEM_ID&quot;) private Long id; private String name; //이름 private int price; //가격 ... } @Entity @DiscriminatorValue(&quot;B&quot;) // 구분 컬럼에 입력할 값을 지정 @PrimaryKeyJoinColumn(name = &quot;BOOK_ID&quot;) // ID 재정의 public class Book extends Item { private String author; private String isbn; ... }장점 테이블이 정규화 외래 키 참조 무결성 제약조건을 활용 저장공간을 효율적 사용단점 조인을 많이 사용, 성능 저하 쿼리가 복잡 데이터 등록 시, INSERT SQL을 두 번 실행특징 몇몇 구현체는 구분 컬럼 없이도 동작한다.단일 테이블 전략테이블을 하나만 사용구분 컬럼(DTYPE)으로 어떤 자식 데이터가 저장되었는지 구분조회할 때 조인을 사용하지 않으므로 일반적으로 가장 빠르다. @Entity @Inheritance(strategy = InheritanceType.SINGLE_TABLE) @DiscriminatorColumn(name = &quot;DTYPE&quot;) public abstract class Item { @Id @GeneratedValue @Column(name = &quot;ITEM_ID&quot;) private Long id; private String name; //이름 private int price; //가격 ... } @Entity @DiscriminatorValue(&quot;A&quot;) public class Album extends Item { ... } @Entity @DiscriminatorValue(&quot;B&quot;) public class Book extends Item { ... } @Entity @DiscriminatorValue(&quot;M&quot;) public class Movie extends Item { ... }장점 조회 성능이 빠르다 쿼리가 단순단점 자식 엔티티가 매핑한 컬럼은 모두 null을 허용 테이블이 커질 수 있어서 상황에 따라서는 조회 성능이 오히려 느려질 수 있다.특징 구분 컬럼을 꼭 사용 @DiscriminatorColumn을 꼭 설정 @DiscriminatorValue을 지정하지 않으면 기본으로 엔티티 이름을 사용구현 클래스마다 테이블 전략자식 엔티티마다 테이블을 만든다. 그리고 자식 테이블 각각에 필요한 컬럼이 모두 있다.데이터베이스 설계자와 ORM 전문가 둘 다 추천하지 않는 전략 @Entity @Inheritance(strategy = InheritanceType.TABLE_PER_CLASS) public abstract class Item { @Id @GeneratedValue @Column(name = &quot;ITEM_ID&quot;) private Long id; private String name; //이름 private int price; //가격 ... } @Entity public class Album extends Item { ... } @Entity public class Movie extends Item { ... } @Entity public class Book extends Item { ... }장점 서브 타입을 구분해서 처리할 때 효과적 not null 제약조건을 사용할 수 있다.단점 여러 자식 테이블을 함께 조회할 때 성능이 느리다. 자식 테이블을 통합해서 쿼리하기 어렵다.특징 구분 컬럼을 사용하지 않는다.@MappedSuperclass지금까지 상속 관계 매핑은 부모 클래스와 자식 클래스 모두 데이터베이스 테이블과 매핑부모 클래스는 테이블과 매핑하지 않고부모 클래스를 상속 받는 자식 클래스에게 매핑 정보만 제공하고 싶으면 @MappedSuperclass를 사용하면 된다.실제 테이블과는 매핑되지 않지만, 매핑 정보를 상속할 목적으로만 사용즉, 테이블과는 관계가 없고 단순히 엔티티가 공통으로 사용하는 매핑 정보를 모아주는 역활을 할 뿐이다.부모로부터 물려받은 매핑 정보를 재정의 하려면 @AttributeOverrides나 @AttributeOverride를 사용연관관계를 재정의 하려면 @AssociationOverrides나 @AssociationOverride를 사용 @MappedSuperclass public abstract class BaseEntity { @Id @GeneratedValue private Long id; private String name; ... } @Entity public class Member extends BaseEntity { //ID 상속 //NAME 상속 private String email; ... } @Entity public class Seller extends BaseEntity { //ID 상속 //NAME 상속 private String shopName; ... } 매핑 정보를 상속하기 위해 사용 @MappedSuperclass로 지정한 클래스는 엔티티가 아니므로 em.find()나 JPQL에서 사용할 수 없다. BaseEntity는 직접 생성해서 사용할 일이 거의 없으므로 추상 클래스로 만드는 것을 권장복합 키와 식별 관계 매핑식별 관계 vs 비식별 관계데이터베이스 테이블 사이에 관계는 외래 키가 기본 키에 포함되는지 여부에 따라 식별 관계와 비식별 관계로 구분식별 관계부모 테이블의 기본 키를 내려받아서 자식 테이블의 기본 키 + 외래 키로 사용 하는 관계비식별 관계부모 테이블의 기본 키를 받아서 자식 테이블의 외래 키로만 사용하는 관계필수적 비식별 관계선택적 비실별 관계 필수적 비식별 관계 : 외래 키에 NULL을 허용하지 않는다. 선택적 비식별 관계 : 외래 키에 NULL을 허용한다.최근에는 비식별 관계를 주로 사용하고 꼭 필요한 곳에만 식별 관계를 사용하는 추세복합 키: 비식별 관계 매핑식벽자 필드가 2개 이상이면 별도의 식별자 클래스를 만들고 그곳에 equals와 hashCode를 구현해야 한다.JPA는 복합 키를 지원하기 위해 @IdClass와 @EmbeddedId 2가지 방법을 제공@IdClass는 관계형 데이터베이스에 가까운 방법@EmbeddedId는 좀 더 객체지향에 가까운 방법@IdClass데이터베이스에 가까운 방법 @Entity @IdClass (ParentId.class) public class Parent { @Id @Column(name = &quot;PARENT_ID1&quot;) private String id1; // ParentId.id1과 연결 @Id @Column(name = &quot;PARENT_ID2&quot;) private String id2; // ParentId.id2와 연결 private String name; ... } public class ParentId implements Serializable { private String id1; // Parent.id1 매핑 private String id2; // Parent.id2 매핑 ... }@IdClass를 사용할 때 식별자 클래스는 다음 조건을 만족해야 한다. 식별자 클래스의 속성명과 엔티티에서 사용하는 식별자의 속성명이 같아야 한다. Serializable 인터페이스를 구현 equals, hashCode를 구현 식별자 클래스는 public이어야 한다. Parent parent = new Parent();parent.setId1(“myId1”);parent.setId2(“myId2”);parent.setName(“parentName”);em.persist(parent); 위의 코드를 보면 식별자 클래스 ParentId가 보이지 않는다.em.persist를 호출하면 영속성 컨텍스트에 엔티티를 등록하기 직전에 내부에서 Parent.id1, Parent.id2 값을 사용해서 식별자 클래스인 ParentId를 생성하고 영속성 컨텍스트의 키로 사용 ParentId parentId = new ParentId(&quot;myId1&quot;, &quot;myId2&quot;); Parent parent = em.find(Parent.class, parentId);조회 코드를 보면 식별자 클래스인 ParentId를 사용해서 엔티티를 조회한다. @Entity public class Child { @Id private String id; @ManyToOne @JoinColumns({ @JoinColumn(name = &quot;PARENT_ID1&quot;, referenceColumnName = &quot;PARENT_ID1&quot;), @JoinColumn(name = &quot;PARENT_ID2&quot;, referenceColumnName = &quot;PARENT_ID2&quot;) }) private Parent parent; }@EmbeddedId좀 더 객체지향적인 방법 @Entity public class Parent { @EmbeddedId private ParentId id; private String name; ... } @Embeddable public class ParentId implements Serializable { @Column(name = &quot;PARENT_ID1&quot;) private String id1; @Column(name = &quot;PARENT_ID2&quot;) private String id2; // equals and hashCode 구현 ... }식별자 클래스를 기본키로 직접 매핑한다.@EmbebbedId를 적용한 식별자 클래스는 다음 조건을 만족해야 한다. @Embeddable 붙여주어야 한다. Serializable 인터페이스를 구현 equals, hashCode를 구현 식별자 클래스는 public이어야 한다. // 저장 Parent parent = new Parent(); ParentId parentId = new ParentId(&quot;myId1&quot;, &quot;myId2&quot;); parent.setId(parentId); parent.setName(&quot;parentName&quot;); em.persist(parent); // 조회 ParentId parentId = new ParentId(&quot;myId1&quot;, &quot;myId2&quot;); Parent parent = em.find(Parent.class, parentId);@IdClass vs @EmbeddabledId각각 장단점이 있으므로 본인의 취향에 맞는 것을 일관성 있게 사용하면 된다.@EmbeddabledId가 더 객체지향적이고 중복도 없어서 좋아보이긴 하지만 특정 상황에 JPQL이 조금 더 길어질 수 있다.복합 키: 식별 관계 매핑@IdClass와 식별관계 // 부모 @Entity public class Parent { @Id @Column(name = &quot;PARENT_ID&quot;) private String id; private String name; ... } // 자식 @Entity @IdClass(ChildId.class) public class Child { @Id @ManyToOne @JoinColumn(name = &quot;PARENT_ID&quot;) public Parent parent; @Id @Column(name = &quot;CHILD_ID&quot;) private String childId; private String name; ... } // 자식 ID public class ChildId implements Serializable { private String parent; // Child.parent 매핑 private String childId; // Child.childId 매핑 // equals, hashCode ... } // 손자 @Entity @IdClass(GrandChildId.class) public class GrandChild { @Id @ManyToOne @JoinColumns({ @JoinColumn(name = &quot;PARENT_ID&quot;), @JoinColumn(name = &quot;CHILD_ID&quot;) }) private Child child; @Id @Column(name = &quot;GRANDCHILD_ID&quot;) private String id; private String name; ... } // 손자 ID public class GrandChild implements Serializable { private ChildId child; // GrandChild.child 매핑 private String id; // GrandChild.id 매핑 // equals, hashCode ... }@EmbeddabledId와 식별 관계식별 관계를 구성할 때는 @MapsId를 사용해야 한다. // 부모 @Entity public class Parent { @Id @Column(name = &quot;PARENT_ID&quot;) private String id; private String name; ... } @Entity public class Child { @EmbeddedId public ChildId id; @MapsId(&quot;parentId&quot;) // ChildId.parentId 매핑 @ManyToOne @JoinColumn(name = &quot;PARENT_ID&quot;) public Parent parent; private String name; ... } // 자식 ID @Embeddable public class ChildId implements Serializable { private String parentId; // @MapsId(&quot;parentId&quot;)로 매핑 @Column(name = &quot;CHILD_ID&quot;) private String id; // equals, hashCode ... } // 손자 @Entity public class GrandChild { @EmbeddedId private GrandChildId id; @MapsId(&quot;childId&quot;) // GrandChildId.childId 매핑 @ManyToOne @JoinColumns({ @JoinColumn(name = &quot;PARENT_ID&quot;), @JoinColumn(name = &quot;CHILD_ID&quot;) }) private Child child; private String name; ... } // 손자 ID @Embeddable public class GrandChild implements Serializable { private ChildId childId; // @MapsId(&quot;childId&quot;)로 매핑 @Column(name = &quot;GRANDCHILD_ID&quot;) private String id; // equals, hashCode ... }@MapsId는 외래키와 매핑한 연관관계를 기본 키에도 매핑하겠다는 뜻이다.비식별 관계로 구현 // 부모 @Entity public class Parent { @Id @GeneratedValue @Column(name = &quot;PARENT_ID&quot;) private Long id; private String name; ... } // 자식 @Entity public class Child { @Id @GeneratedValue @Column(name = &quot;CHILD_ID&quot;) private Long id; private String name; @ManyToOne @JoinColumn(name = &quot;PARENT_ID&quot;) private Parent parent; } // 손자 @Entity public class GrandChild { @Id @GeneratedValue @Column(name = &quot;GRANDCHILD_ID&quot;) private Long id; private String name; @ManyToOne @JoinColumn(name = &quot;CHILD_ID&quot;) private Child child; ... }일대일 식별 관계 // 부모 @Entity public class Board { @Id @GeneratedValue @Column(name = &quot;BOARD_ID&quot;) private Long id; private String title; @OneToOne(mappedBy = &quot;board&quot;) private BoardDetail boardDetail; ... } @Entity public class BoardDetail { @Id private Long boardId; @MapsId //BoardDetail.boardId 매핑 @OneToOne @JoinColumn(name = &quot;BOARD_ID&quot;) private Board board; private String content; ... }식별, 비식별 관계의 장단점 식별 관계는 부모 테이블의 기본 키를 자식 테이블로 전파하면서 자식 테이블의 기본 키 컬럼이 점점 늘어난다. 식별 관계는 2개 이상의 컬럼을 합해서 복합 기본 키를 만들어야 하는 경우가 많다. 식별 관계를 사용할 때 기본 키로 비즈니스 의미가 있는 자연 키 컬럼을 조합하는 경우가 많다.비식별 관계는 키본 키를 비즈니스와 전혀 관계없는 대리 키를 주로 사용식별 관계의 자연 키 컬럼들이 자식에 손자까지 전파되면 변경하기 힘들다. 식별 관계는 비식별 관계보다 테이블 구조가 유연하지 못 하다.이와 같은 이유로 객체 관계 매핑 관점에서 비식별 관계를 선호 일대일 관계를 제외하고 식별 관계는 2개 이상의 컬럼을 묶은 복합 기본키를 사용한다. 비식별 관계는 주로 대리키를 사용하여 @GeneratedValue처럼 대리 키를 생성하기 위한 편리한 방법을 제공 식별 관계의 장점으로 기본 키 인덱스를 활용하기 좋고, 특정 상황에 조인 없이 하위 테이블만으로 검색을 완료할 수 있다.비식별관계를 사용하고 기본 키는 Long 타입의 대리 키를 사용하는 것을 추천추가적으로 선택적 비식별 관계보다는 필수적 비식별 관계를 사용하는 것이 좋다.조인 테이블테이블 연관관계를 설계하는 방법은 크게 2가지다. 조인 컬럼 사용 조인 테이블 사용조인 컬럼을 사용하고 필요하다고 판단되면 조인 테이블을 사용하자일대일 조인 테이블 // 부모 @Entity public class Parent { @Id @GeneratedValue @Column(name = &quot;PARENT_ID&quot;) private Long id; private String name; @OneToOne @JoinTable(name = &quot;PARENT_CHILD&quot;, joinColumns = @JoinColumn(name = &quot;PARENT_ID&quot;), inverseJoinColumns = @JoinColumn(name = &quot;CHILD_ID&quot;)) private Child child; ... } // 자식 @Entity public class Child { @Id @GeneratedValue @Column(name = &quot;CHILD_ID&quot;) private Long id; private String name; @OneToOne(mappedBy=&quot;child&quot;) private Parent parent; ... }일대다 조인 테이블 // 부모 @Entity public class Parent { @Id @GeneratedValue @Column(name = &quot;PARENT_ID&quot;) private Long id; private String name; @OneToMany @JoinTable(name = &quot;PARENT_CHILD&quot;, joinColumns = @JoinColumn(name = &quot;PARENT_ID&quot;), inverseJoinColumns = @JoinColumn(name = &quot;CHILD_ID&quot;)) private List&amp;lt;Child&amp;gt; child = new ArrayList&amp;lt;Child&amp;gt;(); ... } // 자식 @Entity public class Child { @Id @GeneratedValue @Column(name = &quot;CHILD_ID&quot;) private Long id; private String name; ... }다대일 조인 테이블다대일은 일대다에서 방향만 반대 // 부모 @Entity public class Parent { @Id @GeneratedValue @Column(name = &quot;PARENT_ID&quot;) private Long id; private String name; @OneToMany(mappedBy = &quot;parent&quot;) private List&amp;lt;Child&amp;gt; child = new ArrayList&amp;lt;Child&amp;gt;(); ... } // 자식 @Entity public class Child { @Id @GeneratedValue @Column(name = &quot;CHILD_ID&quot;) private Long id; private String name; @ManyToOne(optional = false) @JoinTable(name = &quot;PARENT_CHILD&quot;, joinColumns = @JoinColumn(name = &quot;CHILD_ID&quot;), inverseJoinColumns = @JoinColumn(name = &quot;PARENT_ID&quot;)) private Parent parent; ... }다대다 조인 테이블 // 부모 @Entity public class Parent { @Id @GeneratedValue @Column(name = &quot;PARENT_ID&quot;) private Long id; private String name; @ManyToMany @JoinTable(name = &quot;PARENT_CHILD&quot;) joinColumns = @JoinColumn(name = &quot;PARENT_ID&quot;), inverseJoinColumns = @JoinColumn(name = &quot;CHILD_ID&quot;)) private List&amp;lt;Child&amp;gt; child = new ArrayList&amp;lt;Child&amp;gt;(); ... } // 자식 @Entity public class Child { @Id @GeneratedValue @Column(name = &quot;CHILD_ID&quot;) private Long id; private String name; ... }엔티티 하나에 여러 테이블 매핑 @Entity @Table(name=&quot;BOARD&quot;) @SecondaryTable(name = &quot;BOARD_DETAIL&quot;, pkJoinColumns = @PrimaryKeyJoinColumn(name = &quot;BOARD_DETAIL_ID&quot;)) public class Board { @Id @GeneratedValue @Column(name = &quot;BOARD_ID&quot;) private Long id; private String title; @Column(table = &quot;BOARD_DETAIL&quot;) private String content; ... } @SecondaryTable.name: 매핑할 다른 테이블의 이름 @SecondaryTable.pkJoinColumns: 매핑할 다른 테이블의 기본 키 컬럼 속성 content 필드는 @Column(table = “BOARDDETAIL“)을 사용해 BOARDDETAIL 테이블의 컬럼에 매핑 더 많은 테이블에 매핑하려면 @SecondaryTables를 사용 @SecondaryTables({ @SecondaryTable(name=&quot;BOARD_DETAIL&quot;), @SecondaryTable(name=&quot;BOARD_FILE&quot;) })" }, { "title": "자바 ORM 표준 JPA 프로그래밍 - 다양한 연관관계 매핑", "url": "/posts/%EC%9E%90%EB%B0%94_orm_%ED%91%9C%EC%A4%80_jpa_%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D_%EB%8B%A4%EC%96%91%ED%95%9C-%EC%97%B0%EA%B4%80%EA%B4%80%EA%B3%84-%EB%A7%A4%ED%95%91/", "categories": "Study, Book", "tags": "JPA, ORM", "date": "2021-04-21 00:00:00 +0900", "snippet": "Table of Contents 다대일 다대일 단반향 다대일 양방향 일대다 일대다 단방향 일대다 양방향 일대일 주 테이블에 외래키 단방향 양방향 대상 테이블에 외래키 단방향 양방향 다대다 단방향 양방향 매핑의 한계와 극복, 연결 엔티티 사용 복합 기본키 식별 관계 새로운 기본키 사용 다대다 연관관계 정리 엔티티의 연관관계를 매핑할 때는 다음 3가지를 고려해야 한다. 다중성 단방향, 양방향 연관관계의 주인다대일다대일 단반향 @Entity public class Member { @Id @GeneratedValue @Column(name = &quot;MEMBER_ID&quot;) private Long id; private String username; @ManyToOne @JoinColumn(name = &quot;TEAM_ID&quot;) private Team team; ... } @Entity public class Team { @Id @GeneratedValue @Column(name = &quot;TEAM_ID&quot;) private Long id; private String name; ... }다대일 양방향 @Entity public class Member { @Id @GeneratedValue @Column(name = &quot;MEMBER_ID&quot;) private Long id; private String username; @ManyToOne @JoinColumn(name = &quot;TEAM_ID&quot;) private Team team; public void setTeam(Team team) { this.team = team; if (!team.getMembers().contains(this)) { team.getMembers().add(this); } } } @Entity public class Team { @Id @GeneratedValue @Column(name = &quot;TEAM_ID&quot;) private Long id; private String name; @OneToMany(mappedBy = &quot;team&quot;) private List&amp;lt;Member&amp;gt; members = new ArrayList&amp;lt;Member&amp;gt;(); public void addMember(Member member) { this.members.add(member); if (member.getTeam() != this){ member.setTeam(this); } } } 양방향은 외래 키가 있는 쪽이 연관관계의 주인이다. 양방향 연관관계는 항상 서로를 참조해야 한다.연관관계 편의 메소드가 무한루프에 빠질수 있으므로 주의하도록 해야 한다.일대다일대다 단방향 @Entity public class Member { @Id @GeneratedValue @Column(name = &quot;MEMBER_ID&quot;) private Long id; private String username; ... } @Entity public class Team { @Id @GeneratedValue @Column(name = &quot;TEAM_ID&quot;) private Long id; private String name; @OneToMany(mappedBy = &quot;team&quot;) @JoinColumn(name = &quot;TEAM_ID&quot;) private List&amp;lt;Member&amp;gt; members = new ArrayList&amp;lt;Member&amp;gt;(); ... } 일대다 단반향 매핑의 단점매핑한 객체가 관리하는 외래 키가 다른 테이블에 있어서 연관관계 처리를 위한 UPDATE SQL을 추가로 실행 일대다 단반향 매핑보다는 다대일 양방향 매핑을 사용하자엔티티를 매핑한 테이블이 아닌 다른 테이블의 외래 키를 관리해야 하는 부분은 성능 문제도 있지만 관리도 부담스럽다.좋은 방법은 일대다 단방향 매핑 대신에 다대일 양방향 매핑을 사용하는 것일대다 양방향일대다 양방향 매핑은 존재하지 않는다. 대신 다대일 양방향 매핑을 사용해야 한다.양방향 매핑에서 @OneToMany는 연관관계의 주인이 될 수 없다.그렇다고 일대다 양방향 매핑이 완전히 불가능한 것은 아니다. @Entity public class Member { @Id @GeneratedValue @Column(name = &quot;MEMBER_ID&quot;) private Long id; private String username; @ManyToOne @JoinColumn(name = &quot;TEAM_ID&quot;, insertable = false, updatable = false) private Team team; ... } @Entity public class Team { @Id @GeneratedValue @Column(name = &quot;TEAM_ID&quot;) private Long id; private String name; @OneToMany @JoinColumn(name = &quot;TEAM_ID&quot;) private List&amp;lt;Member&amp;gt; members = new ArrayList&amp;lt;Member&amp;gt;(); // Getter, Setter ... }위와 같은 방법은 다대일 단반향 매핑을 읽기 전용으로 추가해서 일대다 양방향처럼 보이도록 하는 방법따라서 일대다 단반향 매핑이 가지는 단점을 그대로 가진다.될 수 있다면 다대일 양방향 매핑을 사용하자일대일일대일 관계는 주 테이블이나 대상 테이블 중에 누가 외래 키를 가질지 선택해야 한다. 주 테이블에 외래키객체지향 개발자들이 선호장점은 주테이블이 외래 키를 가지고 있으므로 주 테이블만 확인해도 대상 테이블과 연관관계가 있는지 알 수 있다. 대상 테이블에 외래키전통적인 데이터베이스 개발자들은 보통 대상 테이블에 외래 키를 두는 것을 선호장점은 테이블 관계를 일대일에서 일대다로 변경할 때 테이블 구조를 그대로 유지주 테이블에 외래키단방향 @Entity public class Member { @Id @GeneratedValue @Column(name = &quot;MEMBER_ID&quot;) private Long id; private String username; @OneToOne @JoinColumn(name = &quot;LOCKER_ID&quot;) private Locker locker; // Getter, Setter ... } @Entity public class Locker { @Id @GeneratedValue @Column(name = &quot;LOCKER_ID&quot;) private Long id; private String name; // Getter, Setter ... }양방향 @Entity public class Member { @Id @GeneratedValue @Column(name = &quot;MEMBER_ID&quot;) private Long id; private String username; @OneToOne @JoinColumn(name = &quot;LOCKER_ID&quot;) private Locker locker; // Getter, Setter ... } @Entity public class Locker { @Id @GeneratedValue @Column(name = &quot;LOCKER_ID&quot;) private Long id; private String name; @OneToOne(mappedBy = &quot;locker&quot;) private Member member; // Getter, Setter ... }대상 테이블에 외래키단방향일대일 관계 중 대상 테이블에 외래 키가 있는 단방향 관계는 JPA에서 지원하지 않는다.양방향 @Entity public class Member { @Id @GeneratedValue @Column(name = &quot;MEMBER_ID&quot;) private Long id; private String username; @OneToOne(mappedBy = &quot;member&quot;) private Locker locker; // Getter, Setter ... } @Entity public class Locker { @Id @GeneratedValue @Column(name = &quot;LOCKER_ID&quot;) private Long id; private String name; @OneToOne @JoinColumn(name = &quot;MEMBER_ID&quot;) private Member member; // Getter, Setter ... }다대다단방향 @Entity public class Member { @Id @Column(name = &quot;MEMBER_ID&quot;) private Long id; private String username; @ManyToMany @JoinTable(name = &quot;MEMBER_PRODUCT&quot;, joinColumns = @JoinColumn(name = &quot;MEMBER_ID&quot;), inverseJoinColumns = @JoinColumn(name = &quot;PRODUCT_ID&quot;)) private List&amp;lt;Product&amp;gt; products = new ArrayList&amp;lt;Product&amp;gt;(); // Getter, Setter ... } @Entity public class Product { @Id @Column(name = &quot;PRODUCT_ID&quot;) private Long id; private String name; // Getter, Setter ... }@JoinTable의 속성 @JoinTable.name : 연결 테이블 지정 @JoinTable.joinColumns : 현재 방향인 회원과 매핑할 조인 컬럼 정보를 지정 @JoinTable.inverseJoinColumns : 반대 방향인 상품과 매핑할 조인 컬럼 정보 지정양방향 @Entity public class Product { @Id @Column(name = &quot;PRODUCT_ID&quot;) private Long id; private String name; @ManyToMany(mappedBy = &quot;products&quot;) private List&amp;lt;Member&amp;gt; members; // Getter, Setter ... }매핑의 한계와 극복, 연결 엔티티 사용바로 이전에 확인한 방법은 단순하고 여러가지로 편하지만 한계가 있다.보통 연결 테이블에 주문 수량이나 주문 날짜 같은 컬럼이 더 필요하다. @Entity public class Member { @Id @Column(name = &quot;MEMBER_ID&quot;) private Long id; private String username; @OneToMany(mappedBy = &quot;member&quot;) private List&amp;lt;MemberProduct&amp;gt; memberProducts; ... } @Entity public class Product { @Id @Column(name = &quot;PRODUCT_ID&quot;) private Long id; private String name; ... } @Entity @IdClass(MemberProductId.class) public class MemberProduct { @Id @ManyToOne @JoinColumn(name = &quot;MEMBER_ID&quot;) private Member member; @Id @ManyToOne @JoinColumn(name = &quot;PRODUCT_ID&quot;) private Product product; private int orderAmount; ... } public class MemberProductId implements Serializable { private String member; private String product; // hashCode and equals }@Id와 @JoinColumn을 동시에 사용해서 기본 키 + 외래 키를 한번에 매핑@IdClass를 사용해서 복합 기본 키를 매핑복합 기본키복합키를 사용하려면 별도의 식별자 클래스를 만들어야 한다.엔티티에 @IdClass를 사용해서 식별자 클래스를 지정하면 된다. 복합 키는 별도의 식별자 클래스로 만들어야 한다. Serializable을 구현해야 한다. equals와 hashCode 메소드를 구현해야 한다. 기본 생성자가 있어야 한다. 식별자 클래스는 public이여야 한다. @EmbeddedId도 존재식별 관계부모 테이블의 기본키를 받아서 자신의 기본 키 + 외래 키로 사용하는 것 을 식별 관계라고 한다.새로운 기본키 사용 @Entity public class Member { @Id @Column(name = &quot;MEMBER_ID&quot;) private Long id; private String username; @OneToMany(mappedBy = &quot;member&quot;) private List&amp;lt;Order&amp;gt; orders = new ArrayList&amp;lt;Order&amp;gt;; ... } @Entity public class Product { @Id @Column(name = &quot;PRODUCT_ID&quot;) private Long id; private String name; ... } @Entity public class Order { @Id @GeneratedValue @JoinColumn(name = &quot;ORDER_ID&quot;) private Long Id; @ManyToOne @JoinColumn(name = &quot;MEMBER_ID&quot;) private Member member; @ManyToOne @JoinColumn(name = &quot;PRODUCT_ID&quot;) private Product product; private int orderAmount; ... }다대다 연관관계 정리 식별 관계 : 받아온 식별자를 기본 키 + 외래 키로 사용 비식별 관계 : 받아온 식별자는 외래 키로만 사용, 새로운 식별자를 추가비식별 관계는 복합 키를 위한 식별자 클래스를 만들지 않아도 되므로 단순하고 편리하게 ORM을 매핑할 수 있다." }, { "title": "자바 ORM 표준 JPA 프로그래밍 - 연관관계 매핑 기초", "url": "/posts/%EC%9E%90%EB%B0%94_orm_%ED%91%9C%EC%A4%80_jpa_%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D_%EC%97%B0%EA%B4%80%EA%B4%80%EA%B3%84-%EB%A7%A4%ED%95%91-%EA%B8%B0%EC%B4%88/", "categories": "Study, Book", "tags": "JPA, ORM", "date": "2021-04-20 00:00:00 +0900", "snippet": "Table of Contents 단방향 연관관계 @JoinColumn @ManyToOne 연관관계 사용 조회 연관관계 제거 연관된 엔티티 삭제 양방향 연관관계 연관관계의 주인 양방향 매핑의 규칙: 연관관계의 주인 연관관계의 주인은 외래 키가 있는 곳 양방향 연관관계 저장 양방향 연관관계의 주의점 순수한 객체까지 고려한 양방향 연관관계 연관관계 편의 메소드 연관관계 편의 메소드 작성 시 주의사항 단방향 연관관계 객체 연관관계와 테이블 연관관계의 가장 큰 차이객체 참조를 통한 연관관계는 언제나 단방향이다. 객체간에 연관관계를 양방향으로 만들고 싶으면 반대쪽에도 필드를 추가해서 참조를 보관해야 한다.즉, 양방향 관계가 아니라 서로 다른 단방향 관계 2개다. 객체 연관관계 VS 테이블 연관관계 정리 객체는 참조로 연관관계를 맺는다. 테이블은 외래 키로 연관관계를 맺는다. @JoinColumn외래 키를 매핑할 때 사용한다. name : 매핑할 외래 키 이름, 필드명 + _ + 참조하는 테이블의 기본 키 컬럼명 referencedColumnName : 외래 키가 참조하는 대상 테이블의 컬럼명, 참조하는 테이블의 기본키 컬럼명 foreignKey(DDL) : 외래 키 제약조건을 직접 지정할 수 있다. 테이블을 생성할 때만 사용 unique, nullable, insertable, updatable, columnDefinition, table : @Column의 속성과 같다.@ManyToOne다대일 관계에서 사용 optional : false로 설정하면 연관된 엔티티가 항상 있어야 한다. 기본값 true fetch : 글로벌 페치 전략을 설정, @ManyToOne=FetchType.EAGER, @ManyToOne=FetchType.LAZY casacade : 연속성 전이 기능을 사용 targetEntity : 연관된 엔티티의 타입 정보를 설정, 거의 사용하지 않음연관관계 사용JPA에서 엔티티를 저장할 때, 연관된 모든 엔티티는 영속 상태여야 한다.조회연관관계가 있는 엔티티를 조회하는 방법은 크게 2가지 객체 그래프 탐색 객체지향 쿼리 사용JPQL연관관계 제거 member1.setTeam(null);다음과 같이 대상 연관관계 객체를 null로 설정연관된 엔티티 삭제연관된 엔티티를 삭제하려면 기존에 있던 연관관계를 먼저 제거하고 삭제해야 한다. 그렇지 않으면 외래 키 제약조건으로 인해, 데이터베이스에서 오류가 발생양방향 연관관계 @Entity public class Member { @Id @Column(name = &quot;MEMBER_ID&quot;) private String id; private String username; @ManyToOne @JoinColumn(name=&quot;TEAM_ID&quot;) private Team team; ... } @Entity public class Team { @Id @Column(name = &quot;TEAM_ID&quot;) private String id; private String name; @OneToMany(mappedBy = &quot;team&quot;) private List&amp;lt;Member&amp;gt; members = new ArrayList&amp;lt;Member&amp;gt;(); ... }연관관계의 주인엔티티를 양방향 연관관계로 설정하면 객체의 참조는 둘인데 외래 키는 하나다. 따라서 둘 사이에 차이가 발생두 객체 연관관계 중 하나를 정해서 테이블의 외래키를 관리해야 하는데 이것을 연관관계의 주인 이라 한다.양방향 매핑의 규칙: 연관관계의 주인연관관계의 주인만이 데이터베이스 연관관계와 매핑되고 외래 키를 관리할 수 있다.반면 주인이 아닌 쪽은 읽기만 할 수 있다. 주인은 mappedBy 속성을 사용하지 않는다. 주인이 아니면 mappedBy 속성을 사용해서 속성의 값으로 연관관계의 주인을 지정해야 한다.연관관계의 주인을 정한다는 것은 사실 외래 키 관리자를 선택하는 것이다.연관관계의 주인은 외래 키가 있는 곳연관관계의 주인은 테이블에 외래 키가 있는 곳으로 정해야 한다.양방향 연관관계 저장양방향 연관관계의 주인이 외래 키를 관리한다. 따라서 주인이 아닌 곳에 입력된 값은 외래 키에 영향을 주지 않는다.양방향 연관관계의 주의점양방향 연관관계를 설정하고 가장 흔히 하는 실수는 연관관계의 주인에는 값을 입력하지 않고, 주인이 아닌 곳에만 값을 입력하는 것이다.순수한 객체까지 고려한 양방향 연관관계연관관계의 주인에만 값을 저장하고 주인이 아닌 곳에는 값을 저장하지 않아도 될까?객체 관점에서 양쪽 방향에 모두 값을 입력해주는 것이 가장 안전하다.연관관계 편의 메소드 public class Member { private Team team; public void setTeam(Team team) { this.team = team; team.getMembers().add(this); } }이렇게 한 번에 양방향 관계를 설정하는 메소드를 연관관계 편의 메소드라 한다.연관관계 편의 메소드 작성 시 주의사항 member1.setTeam(teamA); member1.setTeam(teamB); Member findMember = teamA.getMember(); // member1이 여전히 조회된다.teamB로 변경할 때 teamA -&amp;gt; member1 관계를 제거하지 않았다. public void setTeam(Team team) { // 기존 팀과 관계를 제거 if (this.team != null) { this.team.getMembers().remove(this); } this.team = team; team.getMembers().add(this); }이 코드는 객체에서 서로 다른 단방향 연관관계 2개를 양방향인 것처럼 보이게 하려고 얼마나 많은 고민과 수고가 필요한지 보여준다.정리하자면 객체에서 양방향 연관관계를 사용하려면 로직을 견고하게 작성해야 한다." }, { "title": "자바 ORM 표준 JPA 프로그래밍 - 엔티티 매핑", "url": "/posts/%EC%9E%90%EB%B0%94_orm_%ED%91%9C%EC%A4%80_jpa_%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D_%EC%97%94%ED%8B%B0%ED%8B%B0-%EB%A7%A4%ED%95%91/", "categories": "Study, Book", "tags": "JPA, ORM", "date": "2021-04-19 00:00:00 +0900", "snippet": "Table of Contents @Entity @Table 데이터베이스 스키마 자동 생성 DDL 생성 기능 기본 키 매핑 기본 키 직접 할당 전략 IDENTITY 전략 SEQUENCE 전략 TABLE 전략 AUTO 전략 필드와 컬럼 매핑 @Access @EntityJPA를 사용해서 테이블과 매핑할 클래스는 @Entity를 필수로 붙여야 한다. 이는 JPA가 관리하는 것으로 엔티티라 부른다. 기본 생성자는 필수 : JPA가 엔티티 객체를 생성할 때 기본 생성자를 사용 final 클래스, enum, interface, inner 클래스에는 사용할 수 없다. 저장할 필드에 final을 사용하면 안 된다.@Table@Table은 엔티티와 매핑할 테이블을 지정한다.생략하면 매핑한 엔티티 이름을 테이블 이름으로 사용데이터베이스 스키마 자동 생성다음 속성을 persistence.xml에 추가하자&amp;lt;property name=&quot;hibernate.hbm2ddl.auto&quot; value=&quot;create&quot; /&amp;gt;해당 속성은 애플리케이션 실행 시점에 데이터베이스 테이블을 자동으로 생성한다스키마 자동 생성 기능을 사용하면 애플리케이션 실행 시점에 데이터베이스 테이블이 자동으로 생성되므로 개발자가 테이블을 직접 생성하는 수고를 덜 수 있다.DDL 생성 기능 @Column(name = &quot;NAME&quot;, nullable = false, length = 10) private String username;@Column 매핑 정보의 nullable 속성 값을 false로 지정하면 자동 생성되는 DDL에 not null 제약조건을 추가할 수 있다.length 속성 값을 사용하면 자동 생성되는 DDL에 문자의 크기를 지정할 수 있다.다음은 uniqueConstraints 속성을 추가한 것이다. @Table(name=&quot;MEMBER&quot;, uniqueConstraints = {@UniqueConstraints(name = &quot;NAME_AGE_UNIQUE&quot;, columnNames = {&quot;NAME&quot;, &quot;AGE&quot;})})이런 기능들은 단지 DDL을 자동 생성할 때만 사용되고 JPA의 실행 로직에는 영향을 주지 않는다.따라서 스키마 자동 생성 기능을 사용하지 않고 직접 DDL을 만든다면 사용할 이유가 없다.기본 키 매핑 직접 할당: 기본 키를 애플리케이션에서 직접 할당 자동 생성: 대리 키 사용 방식 IDENTIT: 기본 키 생성을 데이터베이스에 위임 SEQUENCE: 데이터베이스 시퀸스를 사용해서 기본 키를 할당 TABLE: 키 생성 테이블을 사용 기본 키 직접 할당 전략@Id로 매핑하면 된다.적용 가능한 자바 타입은 다음과 같다. 자바 기본형 자바 래퍼 String java.util.Date java.sql.Date java.math.BigDecimal java.math.BigInteger직접 할당 전략은 em.persist()로 엔티티를 저장하기 전에 애플리케이션에서 기본 키를 직접 할당하는 방법IDENTITY 전략기본 키 생성을 데이터베이스에 위임하는 전략데이터베이스에 값을 저장할 때 ID 컬럼을 비워두면 데이터베이스가 순서대로 값을 채워준다.사용법은 아래와 같다. @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id;엔티티가 영속 상태가 되려면 식별자가 반드시 필요하다. IDENTITY 식별자 생성 전략은 엔티티를 데이터베이스에 저장해야 식별자를 구할 수 있으므로 em.persist()를 호출하는 즉시 INSERT SQL이 데이터베이스에 전달된다.따라서 이 전략은 트랜잭션을 지원하는 쓰기 지연이 동작하지 않는다.SEQUENCE 전략사용법은 아래와 같다. @Entity @SequenceGenerator( name = &quot;BOARD_SEQ_GENERATOR&quot;, sequenceName = &quot;BOARD_SEQ&quot;, initialValue = 1, allocationSize = 1) public class Board { @Id @GeneratedValue(strategy = GenerationType.SEQUENCE, generator = &quot;BOARD_SEQ_GENERATOR&quot;) private Long id; ... }SEQUENCE 전략은 em.persist()를 호출할 때 먼저 데이터베이스 시퀸스를 사용해서 식별자를 조회한다. 그리고 조회한 식별자를 엔티티에 할당한 후에 엔티티를 영속성 컨텍스트에 저장한다.이후 트랜잭션을 커밋해서 플러시가 일어나면 엔티티를 데이터베이스에 저장한다.TABLE 전략키 생성 전용 테이블을 하나 만들고 여기에 이름과 값으로 사용할 컬럼을 만들어 데이터베이스 시퀸스를 흉내내는 전략사용법은 아래와 같다. @Entity @TableGenerator( name = &quot;BOARD_SEQ_GENERATOR&quot;, table = &quot;MY_SEQUENCES&quot;, pkColumnValue = &quot;BOARD_SEQ&quot;, allocationsize = 1) public class Board { @Id @GeneratedValue(strategy = GenerationType.TABLE, generator = &quot;BOARD_SEQ_GENERATOR&quot;) private Long id; ... }TABLE 전략은 시퀸스 대신에 테이블을 사용한다는 것만 제외하면 SEQUENCE 전략과 내부 동작방식이 같다AUTO 전략GenerationType.AUTO는 선택한 데이터베이스 방언에 따라 IDENTITY, SEQUENCE, TABLE 전략 중 하나를 자동으로 선택SEQUENCE나 TABLE 전략이 선택되면 시퀸스나 키 생성용 테이블을 미리 만들어 두어야 한다.만약 스키마 자동 생성 기능을 사용한다면 하이버네이트가 기본값을 사용해서 만들어 줄 것이다.필드와 컬럼 매핑분류매핑 어노테이션설명필드 컬럼 매핑@Column컬럼을 매핑&amp;#xa0;@Enumeratedenum 타입을 매핑&amp;#xa0;@Temporal날짜 타입을 매핑&amp;#xa0;@LobBLOB, CLOB 타입을 매핑&amp;#xa0;@Transient특별 필드를 데이터베이스에 매핑하지 않는다.기타@AccessJPA가 엔티티에 접근하는 방식을 지정@Access 필드 접근: AccessType.FIELD, 필드에 직접 접근, private이라도 접근 가능 프로퍼티 접근: AccessType.PROPERTY, 접근자를 사용한다." }, { "title": "자바 ORM 표준 JPA 프로그래밍 - 영속성 관리", "url": "/posts/%EC%9E%90%EB%B0%94_orm_%ED%91%9C%EC%A4%80_jpa_%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D_%EC%98%81%EC%86%8D%EC%84%B1-%EA%B4%80%EB%A6%AC/", "categories": "Study, Book", "tags": "JPA, ORM", "date": "2021-04-18 00:00:00 +0900", "snippet": "Table of Contents 영속성 관리 엔티티 매니저 팩토리와 엔티티 매니저 영속성 컨텍스트란? 엔티티 생명주기 영속성 컨텍스트의 특징 엔티티 조회 엔티티 등록 엔티티 수정 엔티티 삭제 플러시 플러시 모드 옵션 준영속 준영속 상태의 특징 병합: merge() 영속성 관리엔티티 매니저 팩토리와 엔티티 매니저엔티티 매니저 팩토리는 엔티티 매니저를 만드는 공장이다. 엔티티 매니터 팩토리를 만드는 비용은 상당히 크다. 따라서 한 개만 만들어서 애플리케이션 전체에서 공유하도록 설계되어 있다.반면 엔티티 매니저를 생성하는 비용은 거의 들지 않는다.엔티티 매니저 팩토리는 여러 스레드가 동시에 접근해도 안전하지만, 엔티티 매니저는 여러 스레드가 동시에 접근하면 동시성 문제가 발생하므로 스레드 간에 절대 공유하면 안 된다.엔티니 매니저는 데이터베이스 연결이 꼭 필요한 시점까지 커넥션을 얻지 않는다.영속성 컨텍스트란?엔티티를 영구 저장하는 환경이란 의미이다.엔티티 매니저로 엔티티를 저장하거나 조회하면 엔티티 매니저는 영속성 컨텍스트에 엔티티를 보관하고 관리한다.영속성 컨텍스트는 엔티티 매니저를 생성할 때 하나 생성한다. 엔티티 매니저를 통해서 영속성 컨텍스트에 접근할 수 있고 영속성 컨텍스트를 관리할 수 있다.엔티티 생명주기 비영속(new/transient): 영속성 컨텍스트와 전혀 관계가 없는 상태이며, 영속성 컨텍스트나 데이터베이스와는 전혀 관련이 없다. 영속(managed): 영속성 컨텍스트에 저장된 상태, 영속성 컨텍스트가 관리하는 엔티티 준영속(detached): 영속성 컨텍스트에 저장되었다가 분리된 상태, 영속 상태의 엔티티를 영속성 컨텍스트가 관리하지 않으면 준영속 상태 삭제(removed): 삭제된 상태, 영속성 컨텍스트와 데이터베이스에서 삭제영속성 컨텍스트의 특징 영속성 컨텍스트와 식별자 값엔티티를 식별자 값으로 구분, 영속 상태는 식별자 값이 반드시 있어야 한다. 영속성 컨텍스트와 데이터베이스 저장보통 트랜잭션을 커밋하는 순간 영속성 컨텍스트에 새로 저장된 엔티티를 데이터베이스에 반영, 이것을 플러시라 한다. 장점 1차 캐시 동일성 보장 트랜잭션을 지원하는 쓰기 지연 변경 감지 지연 로딩 엔티티 조회영속성 컨텍스트는 내부에 캐시를 가지고 있는데 이것을 1차 캐시라 한다. 영속 상태의 엔티티는 모두 이곳에 저장된다.em.find()를 호출하면 먼저 1차 캐시에서 엔티티를 찾고 만약 찾는 엔티티가 1차 캐시에 없으면 데이터베이스에서 조회만약 1차 캐시에 없으면 엔티티 매니저는 데이터베이스를 조회해서 엔티티를 생성한다. 그리고 1차 캐시에 저장한 후에 영속 상태의 엔티티를 반환한다.영속성 컨텍스트는 성능상 이점과 엔티티의 동일성을 보장한다.엔티티 등록엔티티 매니저는 트랜잭션을 커밋하기 직전까지 데이터베이스에 엔티티를 저장하지 않고 내부 쿼리 저장소에 INSERT SQL을 모아둔다. 그리고 커밋할 때 모아둔 쿼리를 데이터베이스에 보낸다.이것을 트랜잭션을 지원하는 쓰기 지연이다.트랜잭션을 커밋하면 엔티티 매니저는 우선 영속성 컨텍스트를 플러시한다.엔티티 수정엔티티의 변경사항을 데이터베이스에 자동으로 반영하는 기능을 변경 감지라 한다.엔티티를 영속성 컨텍스트에 보관할 때, 최초 상태를 복사해서 저장해두는데 이것을 스냅샷이라 한다.플러시 시점에 스냅샷과 엔티티를 비교해서 변경된 엔티티를 찾는다.변경 감지는 영속성 컨텍스트가 관리하는 영속 상태의 엔티티에만 적용한다.JPA에서 변경 감지로 생성되는 Update SQL은 기본적으로 모든 필드를 업데이트하는 SQL로 생성한다.필드가 많거나 저장되는 내용이 너무 크면 수정된 데이터만 사용해서 동적으로 UPDATE SQL을 생성하는 전략을 선택하면 된다.이때는 하이버네이트 확장 기능을 사용해야 한다. @org.hiberanate.annotations.DynamicUpdate를 사용하면 되고, @DynamicInsert도 있다.엔티티 삭제엔티티를 삭제하려면 먼저 삭제 대상 엔티티를 조회해야 한다.Member memberA = em.find(Member.class, &quot;memberA&quot;);em.remove(memberA);트랜잭션을 커밋해서 플러시를 호출하면 실제 데이터베이스에 삭제 쿼리를 전달한다.em.remove(memberA)를 호출하는 순간 memberA는 영속성 컨텍스트에서 제거된다. 이렇게 삭제된 엔티티는 재사용하지 말고 자연스럽게 가비지컬렉션의 대상이 되도록 두는 것이 좋다.플러시플러시는 영속성 컨텍스트의 변경 내용을 데이터베이스에 반영한다. 변경 감지가 동작해서 수정된 엔티티는 수정 쿼리를 만들어 쓰기 지연 SQL 저장소에 등록 쓰기 지연 SQL 저장소의 쿼리를 데이터베이스에 전송영속성 컨텍스트를 플러시하는 방법은 3가지다. em.flush()를 호출 트랜잭션 커밋 시 플러시가 자동 호출 JPQL 쿼리 실행 시 플러시가 자동 호출플러시 모드 옵션 FlushModeType.AUTO: 커밋이나 쿼리를 실행할 때 플러시 FlushModeType.COMMIT: 커밋할 때만 플러시플러시는 영속성 컨텍스트의 변경 내용을 데이터베이스에 동기화하는 것이다. 지우는것이 아니다.준영속엔티티가 영속성 컨텍스트에서 분리된 것을 준영속 상태라 한다. 따라서 해당 엔티티는 영속성 컨텍스트가 제공하는 기능을 사용할 수 없다.다음과 같이 엔티티를 준영속 상태로 만들수 있다. em.detach(entity): 특정 엔티티만 준영속 상태로 전환 em.clear(): 영속성 컨텍스트를 완전히 초기화 em.close(): 영속성 컨텍스트를 종료준영속 상태의 특징 거의 비영속 상태에 가깝다.영속성 컨텍스트가 제공하는 어떠한 기능도 동작하지 않음 식별자 값을 가지고 있다. 지연로딩을 할 수 없다.병합: merge()준영속 상태의 엔티티를 다시 영속 상태로 변경하려면 병합을 사용merge() 메소드는 준영속 상태의 엔티티를 받아서 새로운 영속 상태의 엔티티를 반환 비영속 병합 병합은 비영속 엔티티도 영속 상태로 만들 수 있다. 병합은 엔티티의 식별자 값으로 영속성 컨텍스트를 조회한다. 찾는 엔티티가 없다면 데이터베이스에서 조회한다. 데이터베이스에서도 발견 하지 못하면 새로운 엔티티를 생성해서 병합 " }, { "title": "자바 ORM 표준 JPA 프로그래밍 - JPA 시작", "url": "/posts/%EC%9E%90%EB%B0%94_orm_%ED%91%9C%EC%A4%80_jpa_%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D_JPA-%EC%8B%9C%EC%9E%91/", "categories": "Study, Book", "tags": "JPA, ORM", "date": "2021-04-12 00:00:00 +0900", "snippet": "Table of Contents JPA 시작 객체 매핑 시작 persistence.xml 설정 데이터베이스 방언 애플리케이션 개발 엔티티 매니저 생성 트랜잭션 관리 비즈니스 로직 JPA 시작객체 매핑 시작 @Entity이 클래스를 테이블과 매핑한다고 JPA에게 알려준다. 이 클래스를 엔티티 클래스라 한다. @Table엔티티 클래스에 매핑할 테이블 정보를 알려준다.이 어노테이션을 생략하면 클래스 이름을 테이블 이름으로 매핑한다. @Id엔티티 클래스의 필드를 테이블의 기본 키에 매핑이렇게 @Id가 사용된 필드를 식별자 필드라 한다. @Column필드를 컬럼에 매핑한다. 매핑정보가 없는 필드매핑 어노테이션을 생략하면 필드명을 사용해서 컬럼명으로 매핑한다.persistence.xml 설정&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;&amp;lt;persistence xmlns=&quot;http://xmlns.jcp.org/xml/ns/persistence&quot; version=&quot;2.1&quot;&amp;gt; &amp;lt;persistence-unit name=&quot;jpabook&quot;&amp;gt; &amp;lt;!-- 영속성 유닛 설정, 일반적으로 연결할 데이터베이스당 하나의 영속성 유닛을 등록 --&amp;gt; &amp;lt;properties&amp;gt; &amp;lt;!-- 필수 속성 --&amp;gt; &amp;lt;property name=&quot;javax.persistence.jdbc.driver&quot; value=&quot;org.h2.Driver&quot;/&amp;gt; &amp;lt;!-- JDBC 드라이버 --&amp;gt; &amp;lt;property name=&quot;javax.persistence.jdbc.user&quot; value=&quot;sa&quot;/&amp;gt; &amp;lt;!-- 데이터베이스 접속 아이디 --&amp;gt; &amp;lt;property name=&quot;javax.persistence.jdbc.password&quot; value=&quot;&quot;/&amp;gt; &amp;lt;!-- 데이터베이스 접속 비밀번호--&amp;gt; &amp;lt;property name=&quot;javax.persistence.jdbc.url&quot; value=&quot;jdbc:h2:tcp://localhost/~/test&quot;/&amp;gt; &amp;lt;!-- 데이터베이스 접속 URL --&amp;gt; &amp;lt;property name=&quot;hibernate.dialect&quot; value=&quot;org.hibernate.dialect.H2Dialect&quot; /&amp;gt; &amp;lt;!-- 데이터베이스 방언 설정 --&amp;gt; &amp;lt;!-- 옵션 --&amp;gt; &amp;lt;property name=&quot;hibernate.show_sql&quot; value=&quot;true&quot; /&amp;gt; &amp;lt;property name=&quot;hibernate.format_sql&quot; value=&quot;true&quot; /&amp;gt; &amp;lt;property name=&quot;hibernate.use_sql_comments&quot; value=&quot;true&quot; /&amp;gt; &amp;lt;property name=&quot;hibernate.id.new_generator_mappings&quot; value=&quot;true&quot; /&amp;gt; &amp;lt;/properties&amp;gt; &amp;lt;/persistence-unit&amp;gt;&amp;lt;/persistence&amp;gt; 하이버네이트 속성hibernate.dialect: 데이터베이스 방언 설정데이터베이스 방언JPA는 특정 데이터베이스에 종속적이지 않은 기술이다. 따라서 다른 데이터베이스로 손쉽게 교체할 수 있다.하지만 각 데이터베이스가 제공하는 SQL 문법과 함수가 조금씩 다르다는 문제점이 있다. 데이터 타입 다른 함수명 페이징 처리JPA 구현체들은 이런 문제를 해결하려고 다양한 데이터베이스 방언 클래스를 제공 H2: org.hibernate.dialect.H2Dialect 오라클: org.hibernate.dialect.Oracle10gDialect MySQL: org.hibernate.dialect.MySQL5InnoDBDialect애플리케이션 개발public class JpaMain { public static void main(String[] args) { //엔티티 매니저 팩토리 생성 EntityManagerFactory emf = Persistence.createEntityManagerFactory(&quot;jpabook&quot;); EntityManager em = emf.createEntityManager(); //엔티티 매니저 생성 EntityTransaction tx = em.getTransaction(); //트랜잭션 기능 획득 try { tx.begin(); //트랜잭션 시작 logic(em); //비즈니스 로직 tx.commit();//트랜잭션 커밋 } catch (Exception e) { e.printStackTrace(); tx.rollback(); //트랜잭션 롤백 } finally { em.close(); //엔티티 매니저 종료 } emf.close(); //엔티티 매니저 팩토리 종료 } public static void logic(EntityManager em) {..}}엔티티 매니저 생성 엔티티 매니저 팩토리 생성persistence.xml에서 jpabook인 영속성 유닛(persistence-unit)을 찾아서 엔티티 매니저 팩토리를 생성한다. 엔티티 매니저 생성 / 종료엔티티 매니저 생성과 종료는 위의 코드를 통해 확인트랜잭션 관리EntityTransaction tx = em.getTransaction(); // 트랜잭션 APItry { tx.begin(); logic(em); tx.commit();} catch (Exception e) { tx.rollback();}비즈니스 로직public static void logic(EntityManager em) { String id = &quot;id1&quot;; Member member = new Member(); member.setId(id); member.setUsername(&quot;지한&quot;); member.setAge(2); //등록 em.persist(member); //수정 member.setAge(20); //한 건 조회 Member findMember = em.find(Member.class, id); System.out.println(&quot;findMember=&quot; + findMember.getUsername() + &quot;, age=&quot; + findMember.getAge()); //목록 조회 List&amp;lt;Member&amp;gt; members = em.createQuery(&quot;select m from Member m&quot;, Member.class).getResultList(); System.out.println(&quot;members.size=&quot; + members.size()); //삭제 em.remove(member);}" }, { "title": "자바 ORM 표준 JPA 프로그래밍 - JPA 소개", "url": "/posts/%EC%9E%90%EB%B0%94_orm_%ED%91%9C%EC%A4%80_jpa_%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D_JPA-%EC%86%8C%EA%B0%9C/", "categories": "Study, Book", "tags": "JPA, ORM", "date": "2021-04-11 00:00:00 +0900", "snippet": "Table of Contents JPA 소개 SQL을 직접 다룰 때 발생하는 문제점 반복, 반복 그리고 반복 SQL에 의존적인 개발 패러다임의 불일치 JPA란 무엇인가? JAP 소개 왜 JPA를 사용해야 하는가? JPA 소개SQL을 직접 다룰 때 발생하는 문제점반복, 반복 그리고 반복객체를 DB에 CRUD하려면 너무 많은 SQL과 JDBC API를 코드로 작성해야 한다.그리고 테이블마다 이런 비슷한 일을 반복해야 하는데, 개발하려는 애플리케이션에서 사용하는 데이터베이스 테이블이 100개라면 무수히 많은 SQL을 작성해야 하는 이런 비슷한 일을 100번은 더 반복해야 한다.SQL에 의존적인 개발물리적으로 SQL과 JDBC API를 데이터 접근 계층에 숨기는 데 성공했을지는 몰라도 논리적으로 엔티티와 아주 강한 의존관계를 가지고 있다.일너 강한 의존관계 때문에 회원을 조회할 때는 물론이고 회원 객체에 필드를 하나 추가할 때도 DAO의 CRUD 코드와 SQL 대부분을 변경해야 하는 문제가 발생한다. 진정한 의미의 계층 분할이 어렵다. 엔티티를 신뢰할 수 없다. SQL에 의존적인 개발을 피하기 어렵다.패러다임의 불일치애플리케이션은 자바라는 객체지향 언어로 개발하고 데이터는 관계형 데이터베이스에 저장해야 한다면, 패터다임의 불일치 문제를 개발자가 중간에서 해결해야 한다.문제는 이런 객체와 관계형 데이터베이스 사이의 패러다임 불일치 문제를 해결하는 데 너무 많은 시간과 코드를 소비하는 데 있다.객체 모델과 관계형 데이터베이스 모델은 지향하는 패러다임이 서로 다르다.문제는 이 패러다임의 차이를 극복하려고 개발자가 너무 많은 시간과 코드를 소비한다는 점이다.더 어려운 문제는 객체지향 애플리케이션답게 정교한 객체 모델링을 할수록 패러다임의 불일치 문제가 더 커진다는 점이다.이 틈을 메우기 위해 개발자가 소모해야 하는 비용도 점점 더 많아진다.결국, 객체 모델링은 힘을 잃고 점점 데이터 중심의 모델로 변해간다.JPA는 패러다임의 불일치 문제를 해결해주고 정교한 객체 모델링을 유지하게 도와준다.JPA란 무엇인가?JPA(Java Persistence API)는 자바 진영의 ORM 기술 표준이다.ORM이란 무엇일까? ORM(Object Relational Mapping)은 이름 그대로 객체와 관계형 데이터베이스를 매핑한다는 뜻이다.ORM 프레임워크는 개체와 테이블을 매핑해서 패러다임의 불일치 문제를 개발자 대신 해결해준다.저장의 기능을 보면 아래와 같이 ORM 프레임워크가 적절한 INSERT SQL을 생성해서 데이터베이스에 객체를 저장해준다.jpa.persist(member); // 저장ORM 프레임워크는 단순히 SQL을 개발자 대신 생성해서 데이터베이스에 전달해주는 것뿐만 아니라 다양한 패러다임의 불일치 문제들도 해결해준다.따라서 객체 측면에서는 정교한 객체 모델링을 할 수 있고 관계형 데이터베이스는 데이터베이스에 맞도록 모델링하면 된다.그리고 둘을 어떻게 매핑해야 하는지 매핑 방법만 ORM 프레임워크에게 알려주면 된다.JAP 소개EJB 3.0에서 하이버네이트를 기반으로 새로운 자바 ORM 기술 표준이 만들어졌는데 이것이 바로 JPA다.그림을 보면 JPA는 자바 ORM 기술에 대한 API 표준 명세다. 쉽게 이야기해서 인터페이스를 모아둔 것이다. 따라서 JPA를 사용하려면 JPA를 구현한 ORM 프레임워크를 선택해야 한다.JPA라는 표준 덕분에 특정 구현 기술에 대한 의존도를 줄일 수 있고 다른 구현 기술로 손쉽게 이동할 수 있는 장점이 있다.왜 JPA를 사용해야 하는가? 생산성반복적인 코드와 CRUD용 SQL을 개발자가 직접 작성하지 않아도 된다. 유지보수SQL을 직접 다루면 엔티티에 필드를 하나만 추가해도 관련된 CRUD SQL과 결과를 매핑하기 위한 JDBC API 코드를 모두 변경해야 했다. 패러다임의 불일치 해결JPA는 상속, 연관관계, 객체 그래프 탐색, 비교하기와 같은 패러다임 불일치 문제를 해결해준다. 성능JPA는 애플리케이션과 데이터베이스 사이에서 다양한 성능 최적화 기회를 제공한다. 데이터 접근 추상화와 벤더 독립성JPA는 다음 그림처럼 애플리케이션과 데이터베이스 사이에 추상화된 데이터 접근 계층을 제공해서 애플리케이션이 특정 데이터베이스 기술에 종속되지 않도록 한다. 표준JPA는 자바 진영의 ORM 기술 표준이다. 표준을 사용하면 다른 구현 기술로 손쉽게 변경할 수 있다." }, { "title": "클린 아키텍처 - 빠져 있는 장", "url": "/posts/clean_architecture_ch33/", "categories": "Study, Book", "tags": "clean architecture, architecture", "date": "2020-11-22 00:00:00 +0900", "snippet": "Table of Contents 계층 기반 패키지 기능 기반 패키지 포트와 어댑터 컴포넌트 기반 패키지 구현 세부사항엔 항상 문제가 있다 조직화 vs 캡슐화 다른 결합 분리 모드 결론: 빠져있는 조언계층 기반 패키지아마도 가장 단순한 첫 번째 설계 방식은 전통적인 수평 계층형 아키텍처다.기술적인 관점에서 해당 코드가 하는 일에 기반해 그 코드를 분할한다.흔히 우리는 이 방식을 ‘계층 기반 패키지’라고 부른다.이 아키텍처는 웹, ‘업무규칙’, 영속성 코드를 위해 계층이 각각 하나씩 존재한다.다시 말해 코드는 계층이라는 얇은 수평 조각으로 나뉘며, 각 계층은 유사한 종류의 것들을 묶는 도구로 사용된다.‘엄격한 계층형 아키텍처’의 경우 계층은 반드시 바로 아래 계층에만 의존해야 한다.마틴 파울러는 ‘프레젠테이션 도메인 데이터 계층화’에서 처음 시작하기에는 계층형 아키텍처가 적합하다고 애기 했다.이건 다양한 책에서도 이야기한다.이 아키텍처는 엄청난 복잡함을 겪지 않고도 무언가를 작동시켜 주는 아주 빠른 방법이다.문제는 마틴이 지적했듯이 소프트웨어가 커지고 복잡해지기 시작하면, 머지 않아 큰 그릇 세 개만으로는 모든 코드를 담기엔 부족하다는 사실을 깨닫고, 더 잘게 모듈화해야 할지를 고민하게 될 것이다.계층형 아키텍처는 업무 도메인에 대해 아무것도 말해주지 않는다는 문제도 있다.전혀 다른 업무 도메인이라도 코드를 계층형 아키텍처로 만들어서 나란히 놓고 보면, 웹, 서비스, 리포지터리로 구성된 모습이 기분 나쁠 정도로 비슷하게 보일 것이다.기능 기반 패키지서로 연관된 기능, 도메인 개념, 또는 (도메인 주도 설계 용어를 사용한다면) Aggregate Root에 기반하여 수직의 얇은 조각으로 코드를 나누는 방식이다.전형적인 구현에서는 모든 타입이 하나의 자바 패키지에 속하며, 패키지 이름은 그 안에 담긴 개념을 반영해 짓는다.아래 그림에서 보듯이 등장하는 인터페이스와 클래스는 이전과 같지만, 모두가 단 하나의 패키지에 속하게 된다.이제 코드의 상위 수준 구조가 업무 도메인에 대해 무언가를 알려주게 된다.드디어 우리는 이 코드 베이스가 주문과 관련한 무언가를 한다는 걸 볼 수 있다.또 다른 이점으로, ‘주문 조회하기’ 유스케이스가 변경될 경우 변경해야 할 코드를 모두 찾는 작업이 더 쉬워질 수 있다.변경해야 할 코드가 여러 군데 퍼져 있지 않고 모두 한 패키지에 담겨 있기 때문이다.수평적 계층화(계층 기반 패키지)의 문제를 깨닫고, 수직적 계층화(기능 기반 패키지)로 전환하는 걸 자주 목격했다.하지만 두 접근법은 모두 차선책이다.포트와 어댑터엉클 밥에 따르면, ‘포트와 어댑터(Port and Adapters)’ 혹은 ‘육각형 아키텍처(Hexagonal Architecture)’, ‘경계, 컨트롤러, 엔티티(BCE)’ 등의 방식으로 접근하는 이유는 업무/도메인에 초점을 둔 코드가 프레임워크나 DB 같은 기술적인 세부 구현과 독립적이며 분리된 아키텍처를 만들기 위해서다.아래 그림과 같이 코드 베이스는 ‘내부’(도메인)와 ‘외부’(인프라)로 구성됨을 흔히 볼 수 있다.‘내부’ 영역은 도메인 개념을 모두 포함하는 반면, ‘외부’ 영역은 외부 세계(UI, DB, 서드파티 통합)와의 상호작용을 포함한다.여기서 주요 규칙은 바로 ‘외부’가 ‘내부’에 의존하며, 절대로 그 반대로는 안 된다는 점이다.여기에서 com.mycompany.myapp.domain 패키지가 ‘내부’이며, 나머지 패키지는 모두 ‘외부’다.의존성이 ‘내부’를 향해 흐르는 모습을 주목하라.계층 기반 패키지, 기능 기반 패키지에서 OrdersRepository가 Orders라는 간단한 이름으로 바뀌었다.이는 도메인 주도 설계라는 세계관에서 비롯된 명명법으로, 도메인 주도 설계에서는 ‘내부’에 존재하는 모든 것의 이름은 반드시 ‘유비쿼터스 도메인 언어’ 관점에서 기술하라고 조언한다.도메인에 대해 논의할 때 우리는 ‘주문’에 대해 말하는 것이지, ‘주문 리포지터리’에 대해 말하는 것이 아니다.이 그림은 다이어그램을 간소화할 때 어떻게 표현할 수 있는지를 보여준다는 점도 짚고 갈 만하다.이 다이어그램에는 인터랙터가 빠졌고, 의존성 경계를 가로질러 데이터를 마샬링하는 객체 등이 누락되었다.컴포넌트 기반 패키지계층형 아키텍처의 목적은 기능이 같은 코드끼리 서로 분리하는 것이다. 웹 관련 코드는 업무 로직으로부터 분리하고, 업무 로직은 다시 데이터 접근으로부터 분리한다.엄격한 계층형 아키텍처에서 의존성 화살표는 항상 아래를 향해야 하며, 각 계층은 반드시 바로 아래 계층에만 의존 해야 한다.여기에는 큰 문제가 있다. 속임수를 써서 몇몇 의존성을 의도치 않은 방식으로 추가하더라도, 보기에는 여전히 좋은 비순환 의존성 그래프가 생성된다는 사실 이다.아래의 그림을 보면 화살표는 여전히 아래를 향하지만, OrderController가 OrderService를 우회하고 있다.이러한 조직화는 계층이 인접한 계층(들)을 건너뛰는 일이 허용되기 때문에 흔히 완화된 계층형 아키텍처 라고 부른다.업무 로직 계층을 우회하는 일은 바람직하지 못하다.여기에서 우리에게 필요한 것은 지침(아키텍처 원칙) 으로, “웹 컨트롤러는 절대로 리포지터리에 직접 접근해서는 안 된다”와 같은 원칙이 필요하다.물론 문제는 강제성 이다.많은 팀들이 훌륭한 규율, 코드 리뷰를 통해서 이 원칙을 강제한다.또는 빌드 시 정적 분석 도구를 사용해서 아키텍처적인 위반 사항이 없는지를 검사한다.이 방식은 다소 조잡하지만 효과가 있는데, 위반 시 빌드가 실패하기 때문이다.하지만 두 접근법 모두 오류가 있을 수 있으며, 그 결과를 알게 되는 주기가 필요 이상으로 길다는 문제 가 있다.개인적으로는 가능하면 컴파일러를 사용해서 아키텍처를 강제하는 방식을 선호 한다.‘컴포넌트 기반 패키지’를 도입해야 하는 이유는 바로 이 때문 이다.큰 단위의 단일 컴포넌트와 관련된 모든 책임을 하나의 자바 패키지로 묶는 데 주안점을 둔다.이 접근법은 서비스 중심적인 시각으로 소프트웨어 시스템을 바라보며, 마이크로서비스 아키텍처가 가진 시각과도 동일 하다.컴포넌트 기반 패키지에서도 사용자 인터페이스를 큰 단위의 컴포넌트로부터 분리해서 유지한다.이 접근법에서는 ‘업무 로직’과 영속성 관련 코드를 하나로 묶는데, 이 묶음을 나는 ‘컴포넌트’라고 부른다.엉클 밥은 이 책 앞부분에서 ‘컴포넌트’에 대한 정의를 아래와 같이 제시했다.“컴포넌트는 배포 단위다. 컴포넌트는 시스템의 구성 요소로, 배포할 수 있는 가장 작은 단위다. 자바의 경우 jar 파일이 컴포넌트다.”컴포넌트에 대한 저자의 정의는 약간 다르다.“컴포넌트는 멋지고 깔끔한 인터페이스로 감싸진 연관된 기능들의 묶음으로, 애플리케이션과 같은 실행 환경 내부에 존재한다.”이 정의는 나의 ‘C4 소프트웨어 아키텍처 모델’에 따른 것으로 소프트웨어 시스템의 정적 구조를 컨테이너, 컴포넌트, 클래스(또는 코드)의 측면에서 계층적으로 생각하는 간단한 방법이다.이 방법론에서 소프트웨어 시스템은 하나 이상의 컨테이너(웹 애플리케이션, 모바일 앱, 돌립형 애플리케이션, DB, FS 등)로 구성되며, 각 컨테이너는 하나 이상의 컴포넌트를 포함 한다.또한 각 컴포넌트는 하나 이상의 클래스(또는 코드)로 구현된다.이때 각 컴포넌트가 개별 jar 파일로 분리될지 여부는 직교적인 관심사 다.컴포넌트 기반 패키지 접근법의 주된 이점은 주문과 관련된 무언가를 코딩해야 할 때 오직 한 곳, 즉 OrdersComponent만 둘러보면 된다는 점이다.이 컴포넌트 내부에서 관심사의 분리는 여전히 유효하며, 따라서 업무 로직은 데이터 영속성과 분리 되어 있다.하지만 이는 컴포넌트 구현과 관련된 세부사항으로, 사용자는 알 필요가 없다.이는 마이크로서비스나 서비스 지향 아키텍처를 적용했을 때 얻는 이점과도 유사하다.즉, 주문 처리와 관련된 모든 것들을 캡슐화하는 별도의 OrderService가 존재한다.큰 차이는 결합 분리 모드에 있다.모노리틱 애플리케이션에서 컴포넌트를 잘 정의하면 마이크로 서비스 아키텍처로 가기 위한 발판으로 삼을 수 있다.구현 세부사항엔 항상 문제가 있다표면상으로는 이 네 가지 접근법이 코드를 조직화하는 완전히 다른 방식처럼 보이며, 따라서 서로 다른 아키텍처 스타일로 여길 수도 있다.하지만, 세부사항을 잘못 구현하면 이러한 견해도 아주 빠르게 흐트러지기 시작한다.모든 타입에서 public 지시자를 사용한다는 건 사용하는 프로그래밍 언어가 제공하는 캡슐화 관련 이점을 활용하지 않겠다는 뜻 이다.이로 인해 누군가가 구체적인 구현 클래스의 인스턴스를 직접 생성하는 코드를 작성하는 일을 절대 막을 수 없으니, 결국 당신이 지향하는 아키텍처 스타일을 위반하게 될 것이다.조직화 vs 캡슐화만약 자바 애플리케이션에서 모든 타입을 public으로 지정한다면, 패키지는 단순히 조직화를 위한 메커니즘(폴더와 같이 무언가를 묶는 방식)으로 전락하여 캡슐화를 위한 메커니즘이 될 수 없다.public 타입을 코드 베이스 어디에서도 사용할 수 있다면 패키지를 사용하는 데 따른 이점이 거의 없다.따라서 사실상 패키지를 사용하지 않는 것과 같다.패키지를 무시해 버리면 최종적으로 어떤 아키텍처 스타일로 만들려고 하는지는 아무런 의미가 없어진다.public 지시자를 과용하면 앞에서 제시한 네 가지 아키텍처 접근법은 본질적으로 완전히 같아진다.각 타입 사이의 화살표를 유심히 살펴보라.모두 동일한 방향을 가리킨다.개념적으로 이 접근법들은 매우 다르지만, 구문적으로는 완전히 똑같다.이처럼 모든 타입을 public으로 선언한다면, 우리가 실제로 갖게 되는 것은 수평적 계층형 아키텍처를 표현하는 네 가지 방식에 지나지 않는다.자바에서 접근 지시자를 적절하게 사용하면, 타입을 패키지로 배치하는 방식에 따라서 각 타입에 접근할 수 있는 정도가 실제로 크게 달라질 수 있다.만약 다이어그램에서 패키지 구조를 다시 살려서 더 제한적인 접근 지시자를 사용할 수 있는 타입을 표시하면, 다이어그램은 상당히 인상적으로 변한다. 계층 기반 패키지OrdersService와 OrdersRepository 인터페이스는 외부 패키지의 클래스로부터 자신이 속한 패키지 내부로 들어오는 의존성이 존재하므로 public으로 선언되어야 한다.나머지는 더 제한적으로 선언할 수 있다.이들 클래스는 누구도 알 필요가 없는 구현 세부사항이다. 기반 기능 패키지OrdersController가 패키지로 들어올 수 있는 유일한 통로를 제공한다.나머지는 더 제한적으로 선언할 수 있다.이들 클래스는 누구도 알 필요가 없는 구현 세부사항이다. 포트와 어댑터OrdersService와 Orders 인터페이스는 외부로부터 들어오는 의존성을 가지브로 public으로 지정해야 한다.나머지는 더 제한적으로 선언할 수 있다.이들 클래스는 누구도 알 필요가 없는 구현 세부사항이다. 컴포넌트 기반 패키지컨트롤러에서 OrdersComponent 인터페이스로 향하는 의존성을 가진다나머지는 더 제한적으로 선언할 수 있다.이들 클래스는 누구도 알 필요가 없는 구현 세부사항이다.이제 패키지 외부의 코드에서 OrdersRepository 인터페이스나 구현체를 직접 사용할 수 있는 방법이 전혀 없다.따라서 우리는 컴파일러의 도움을 받아서 ‘컴포넌트 기반 패키지’ 아키텍처 접근법을 강제할 수 있다.여기에서 설명한 내용은 모노리틱 애플리케이션에 대한 것으로, 모든 코드가 단 하나의 소스 코드 트리에 존재하는 경우다.아키텍처 원칙을 강제할 때 자기 규율이나 컴파일러 후처리 도구를 이용하지말고, 반드시 컴파일러에 의지할 것을 권장한다.다른 결합 분리 모드프로그래밍 언어가 제공하는 방법 외에도 소스 코드 의존성을 분리하는 방법은 존재할 수 있다.자바에서 OSGi 같은 모듈 프레임워크 나 자바9에서 제공하는 새로운 모듈 시스템 이 있다.모듈 시스템을 제대로 사용하면 public 타입과 외부에 공표할 타입을 분리할 수 있다.예를 들어 Orders 모듈을 생성할 때 모든 타입을 public으로 지정하더라도, 그중 일부 타입만을 외부에서 사용할 수 있도록 공표할 수 있다.다른 선택지로는 소스 코드 수준에서 의존성을 분리하는 방법 도 있다.정확하게는 서로 다른 소스 코드 트리로 분리하는 방법이다.포트와 어댑터를 예로 들면, 업무와 도메인용 소스 코드 : OrdersService, OrdersServiceImpl, Orders 웹용 소스 코드 : OrdersController 데이터 영속성용 소스 코드 : JdbcOrdersRepository마지막 두 소스 코드 트리는 업무와 도메인 코드에 대해 컴파일 시점에 의존성을 가지며, 업무와 도메인 코드 자체는 웹이나 데이터 영속성 코드에 대해서는 아무것도 알지 못한다.이상적으로는 이러한 형태를 반복적으로 적용하여 애플리케이션을 구성하는 모든 컴포넌트 각각을 개별적인 소스 코드 트리로 구성해야 한다.포트와 어댑터 접근법을 적용할 때는 이보다 간단한 방법을 사용하기도 하는데, 단순히 소스 코드 트리를 두 개만 만드는 것이다. 도메인 코드(‘내부’) 인프라 코드(‘외부’)이 접근법은 소스 코드를 조직화할 때 효과가 있겠지만, 잠재적으로 절충해야 할 부분이 있음을 알고 있어야만 한다.나는 이를 ‘포트와 어댑터에 대한 페리페리크 안티 패턴’이라고 부른다.인프라 코드를 단일 소스 코드에 모두 모아둔다는 말은 애플리케이션에서 특정 영역에 있는 인프라 코드가 애플리케이션의 다른영역에 있는 코드를 직접 호출할 수 있다는 뜻이다.도메인을 통하지 않고 말이다.특히 해당 코드에 적절한 접근 지시자를 적용하는 걸 잊어버린 경우라면 이러한 호출을 막기는 더욱 힘들다.결론: 빠져있는 조언최적의 설계를 꾀했더라도, 구현 전략에 얽힌 복잡함을 고려하지 않으면 설계가 순식간에 망가질 수도 있다는 사실을 강조하는 데 그 목적이 있다.설계를 어떻게 해야만 원하는 코드 구조로 매핑할 수 있을지, 그 코드를 어떻게 조직화할지, 런타임과 컴파일타임에 어떤 결합 분리 모드를 적용할지를 고민하라.가능하다면 선택사항을 열어두되, 실용주의적으로 행하라.그리고 일정과 예산이라는 제약과 동시에 고려하라.선택된 아키텍처 스타일을 강제하는 데 컴파일러의 도움을 받을 수 있을지를 고민하며, 데이터 모델과 같은 다른 영역에 결합되지 않도록 주의하라.구현 세부사항에는 항상 문제가 있는 법이다." }, { "title": "클린 아키텍처 - 프레임워크는 세부사항이다.", "url": "/posts/clean_architecture_ch32/", "categories": "Study, Book", "tags": "clean architecture, architecture", "date": "2020-11-21 00:00:00 +0900", "snippet": "Table of Contents 프레임워크 제작자 혼인 관계의 비대칭성 위험 요인 해결책 이제 선언합니다. 결론프레임워크 제작자이들은 당신이 풀어야 할 특별한 관심사를 염두에 두지 않는다. 프레임워크 제작자는 당신을 알지 못하며, 당신이 풀어야 할 문제도 알지 못하기 때문이다.물론 당신의 문제는 프레임워크가 풀려는 문제와 꽤 많이 겹칠 것이다.겹치는 영역이 크면 클수록 프레임워크는 실제로 더 유용해진다.혼인 관계의 비대칭성당신과 프레임워크 제작자 사이의 관계는 놀라울 정도로 비대칭적이다.당신은 프레임워크를 위해 대단히 큰 헌신을 해야 하지만, 프레임워크 제작자는 당신을 위해 아무런 헌신도 하지 않는다.프레임워크 제작자는 당신의 애플리케이션이 가능하면 프레임워크에 공고하게 결합될 것을 강하게 역설한다.프레임워크 제작자 입장에서는 프레임워크와의 이러한 결합이 위험 요소가 되지 않는다. 오히려 프레임워크와 결합되기를 바란다.왜냐하면 제작자는 그 프레임워크에 대해 절대적인 제어권을 쥐고 있기 때문이다.제작자는 당신도 자신의 프레임워크에 결합되기를 바란다.한번 결합하면 그 관계를 깨기가 매우 어렵기 때문이다.사용자가 많아지는 일은 자신의 프레임워크가 효과적임을 검증하는 최고의 방법이다.사실상 프레임워크 제작자는 당신에게 프레임워크와 혼인하기를 요구하는 것이다.하지만 프레임워크 제작자는 어떠한 경우에도 그에 상응하는 헌신을 당신에게 하지는 않을 것이다.모든 위험과 부담은 오롯이 당신이 감수할 뿐, 제작자가 감수하는 건 아무것도 없다.위험 요인 프레임워크의 아키텍처는 그다지 깔끔하지 않은 경우가 많다. 프레임워크는 애플리케이션의 초기 기능을 만드는 데는 도움이 될 것이다. 하지만 제품이 성숙해지면서 프레임워크가 제공하는 기능과 틀을 벗어나게 될 것이다. 프레임워크는 당신에게 도움되지 않는 방향으로 진화할 수도 있다. 새롭고 더 나은 프레임워크가 등장해서 갈아타고 싶을 수도 있다.해결책프레임워크를 사용할 수는 있다.하지만 프레임워크와 결합해서는 안 된다.프레임워크는 아키텍처의 바깥쪽 원에 속하는 세부사항으로 취급하라업무 객체를 만들 때 프레임워크가 자신의 기반 클래스로부터 파생하기를 요구한다면, 거절하라! 대신 프락시를 만들고, 업무 규칙에 플러그인할 수 있는 컴포넌트에 이들 프락시를 위치시켜라프레임워크가 핵심 코드 안으로 들어오지 못하게 하라. 대신 핵심 코드에 플러그인할 수 있는 컴포넌트에 프레임워크를 통합하고, 의존성 규칙을 준수하라.예를 들어 당신은 스프링을 좋아할 것이다. 스프링은 훌륭한 의존성 주입 프레임워크다.하지만, 업무 객체는 절대로 스프링에 대해 알아서는 안 된다.업무 객체보다는 메인 컴포넌트에서 스프링을 사용해서 의존성을 주입하는 편이 낫다.메인은 아키텍처 내에서 가장 지저분한, 최저 수준의 컴포넌트이기 때문에 스프링을 알아도 상관 없다.이제 선언합니다.정말로 결혼해야만 하는 프레임워크도 존재한다. 예를들어서 C++를 사용하고 있다면 STL과 결혼해야 할 가능성이 높다. 자바를 사용한다면 표준 라이브러리와 반드시 결혼해야 한다.이러한 관계는 정상이다. 하지만 선택적이어야 한다.다른 모든 것을 저버릴 때도 프레임워크를 사용해야 할 것이다.결론가급적이면 프레임워크를 가능한 오랫동안 아키텍처 경계 너머에 두자." }, { "title": "클린 아키텍처 - 웹은 세부사항이다.", "url": "/posts/clean_architecture_ch31/", "categories": "Study, Book", "tags": "clean architecture, architecture", "date": "2020-11-20 00:00:00 +0900", "snippet": "Table of Contents 끝없이 반복하는 추 요약 결론1960년도 이래로 우리 업계는 일련의 반복되는 진동을 겪어왔고, 현재 웹은 그저 이러한 진동의 맨 끝에 있을 뿐이다.이 진동은 모든 연산 능력을 중앙 서버에 두는 방식과 모든 연산 능력을 단말에 두는 방식 사이에서 끊임없이 움직여 왔다.끝없이 반복하는 추반복되는 진동이 웹으로부터 시작되었다고 보는 일은 옳지 않다.웹이 있기 전에는 클라이언트-서버 아키텍처가 있었다.그 전에는 다수의 멍청한 단말기가 연결되는 중앙집중식 미니컴퓨터가 있었다.그리고 그 이야기는 계속된다.앞으로도 우리는 연산 능력을 어디에 둘지 알 수 없을 것이다.연산능력을 중앙에 집중하는 방식과 분산하는 방식 사이에서 우리는 끊임없이 움직인다.아키텍트로서 우리는 멀리 내다봐야 한다.이 진동은 그저 핵심 업무 규칙의 중심에서 밀어내고 싶은 단기적인 문제일 뿐이다.다양한 앱과 소프트웨어의 GUI가 변경되기도 하고 다시 원복되기도 한다.이로부터 애플리케이션을 보호하기 위해 무슨 일을 해야 할까?업무 규칙을 UI로부터 분리해야 한다.요약GUI = 세부사항웹 = GUI따라서 웹은 세부사항이다.이러한 세부사항을 핵심 업무 로직에서 분리된 경계 바깥에 두어야 한다.UI와 애플리케이션 사이에는 추상화가 가능한 또 다른 경계가 존재한다.업무 로직은 다수의 유스케이스로 구성되며, 각 유스케이스는 사용자를 대신해서 일부 함수를 수행하는 것으로 볼 수 있다.완전한 입력 데이터와 그에 따른 출력 데이터는 데이터 구조로 만들어서 유스케이스를 실행하는 처리 과정을 입력 값과 출력 값으로 사용할 수 있다.이 방식을 따르면 각 유스케이스가 장치 독립적인 방식으로 UI라는 입출력 장치를 동작시킨다고 생각할 수 있다.결론이러한 종류의 추상화는 만들기 쉽지 않고, 제대로 만들려면 수차례를 반복 과정을 거처야 할 것이다.하지만 가능하다.그리고 GUI를 변경하고 싶어하는 마케터가 많기 때문에 이러한 추상화가 꼭 필요할 때가 많다고 주장하기는 어렵지 않다." }, { "title": "클린 아키텍처 - 데이터베이스는 세부사항이다", "url": "/posts/clean_architecture_ch30/", "categories": "Study, Book", "tags": "clean architecture, architecture", "date": "2020-11-19 00:00:00 +0900", "snippet": "Table of Contents 관계형 데이터베이스 데이터베이스 시스템은 왜 이렇게 널리 사용되는가? 디스크가 없다면 어떻게 될까? 세부사항 하지만 성능은? 결론아키텍처 관점에서 볼 때 데이터베이스는 엔티티가 아니다. 즉, 데이터베이스는 세부사항이라서 아키텍처의 구성요소 수준으로 끌어올릴 수 없다.데이터베이스는 일개 소프트웨어일 뿐이며 데이터에 접근할 방법을 제공하는 유틸리티다.아키텍처 관점에서 보면 이러한 유틸리티는 저수준의 세부사항(메커니즘)일 뿐이라서 아키텍처와는 관련이 없다.그리고 뛰어난 아키텍트라면 저수준의 메커니즘이 시스템 아키텍처를 오염시키는 일을 용납하지 않는다.관계형 데이터베이스관계형 데이터베이스의 기술이 얼마나 뛰어나든, 결국은 그저 기술일 뿐이다. 그리고 이는 관계형 데이터베이스가 세부사항임을 뜻한다.데이터를 테이블에 행 단위로 배치한다는 사실은 아키텍처적으로 볼 때 전혀 중요하지 않다.유스케이스는 이러한 방식을 알아서는 안 되며 관여해서도 안 된다.데이터가 테이블 구조를 가진다는 사실은 오직 아키텍처의 외부 원에 위치한 최하위 수준의 유틸리티 함수만 알아야 한다.데이터베이스 시스템은 왜 이렇게 널리 사용되는가?데이터베이스가 우위를 차지할 수 있던 이유는 무엇일까? 한마디로 답하자면, 바로 ‘디스크’ 때문이다.디스크 기술이 지닌 치명적인 한 가지 특성은 바로 느리다는 특성이다.디스크 때문에 피해갈 수 없는 시간 지연이라는 짐을 완하하기 위해, 색인, 캐시, 쿼리 계획 최적화가 필요하다. 그리고 데이터를 표현하는 일종의 표준적인 방식도 필요했다.간단히 말해서 데이터 접근 및 관리 시스템이 필요했다.시간이 지나면서 이러한 시스템은 뚜렷이 구분되는 두 가지 유형으로 분리되었다.하나는 파일시스템이었고 다른 하나는 관계형 데이터베이스 관리 시스템(RDBMS)이었다.이들 두 시스템은 데이터를 디스크에 체계화해서, 각 시스템에 특화된 방식으로 접근해야 할 때 가능한 효율적으로 데이터를 저장하고 검색할 수 있도록 한다.각 시스템은 데이터를 색인하고 배치하는 고유한 전략을 활용한다.덧붙여 말하자면, 데이터를 빠르게 조작할 수 있도록 결국에는 관련 있는 데이터를 RAM으로 가져온다.디스크가 없다면 어떻게 될까?한때는 디스크가 성행했지만, 이제는 소멸 중인 부품이다.디스크가 모두 사라져서 모든 데이터가 RAM에 저장된다면 데이터를 어떻게 체계화할 것인가?데이터를 테이블 구조로 만들어 SQL을 이용해 접근할 것이가?당연히 아니다. 이 데이터들을 연결 리스트, 트리 등 여타 무수히 많은 데이터 구조로 체계화할 것이며, 데이터에 접근할 때는 포인터나 참조를 사용할 것이다.이것이 프로그래머가 하는 일이기 때문이다.세부사항데이터베이스가 세부사항이라고 말하는 이유는 바로 이러한 현실 때문이다.실제로 데이터베이스는 비트를 담는 거대한 그릇이며, 데이터를 장기적으로 저장하는 공간에 지나지 않는다.따라서 아키텍처 관점에서 본다면 회전식 자기 디스크에 데이터가 있기만 한다면, 데이터가 어떤 형태인지는 절대로 신경 써서는 안 된다.디스크 자체가 존재한다는 사실조차도 인식해서는 안 된다.하지만 성능은?데이터 저장소의 측면에서 성능은 완전히 캡슐화하여 업무 규칙과는 분리할 수 있는 관심사다.데이터 저장소에서 데이터를 빠르게 넣고 뺄수 있어야 하는 것은 맞지만, 이는 저수준의 관심사다.이 관심사는 저수준의 데이터 접근 메커니즘 단에서 다룰 수 있다. 성능은 시스템의 전반적인 아키텍처와는 아무런 관련이 없다.결론쳬계화된 데이터 구조와 데이터 모델은 아키텍처적으로 중요하다. 반면, 그저 데이터를 회전식 자기 디스크 표면에서 이리저리 옮길 뿐인 기술과 시스템은 아키텍처적으로 중요치 않다.데이터를 테이블 구조로 만들고 SQL로만 접근하도록 하는 관계형 데이터베이스 시스템은 전자보다는 후자와 훨씬 관련이 깊다.데이터는 중요하다.하지만 데이터베이스는 세부사항이다." }, { "title": "클린 아키텍처 - 클린 임베디드 아키텍처", "url": "/posts/clean_architecture_ch29/", "categories": "Study, Book", "tags": "clean architecture, architecture", "date": "2020-11-18 00:00:00 +0900", "snippet": "Table of Contents 앱-티튜드 테스트 타깃-하드웨어 병목현상 클린 임베디드 아키텍처는 테스트하기 쉬운 임베디드 아키텍처다 계층 하드웨는 세부사항이다. HAL 사용자에게 하드웨어 세부사항을 드러내지 말라 프로세서는 세부사항이다. 운영체제는 세부사항이다. 인터페이스를 통하고 대체 가능성을 높이는 방향으로 프로그래밍하라 DRY 원칙: 조건부 컴파일 지시자를 반복하지 말라 결론“소프트웨어는 닳지 않지만, 펌웨어와 하드웨어에 대한 의존성을 관리하지 않으면 안으로부터 파괴될 수 있다.”펌웨어는 무엇에 의존하는지, 그리고 하드웨어 발전에 맞춰 수정하기가 얼마나 어려운지에 따라 정의된다.하드웨어는 발전할 수밖에 없고 그러한 현실을 염두에 두고 임베디드 코드를 구조화할 수 있어야 한다.우리가 정말로 원하는 건 펌웨어는 더 적게 만들고, 소프트웨어는 더 많이 만드는 것이다.임베디드 엔지니어가 아닌 당신도 코드에 SQL을 심어 놓거나 개발하는 코드 전반에 플랫폼 의존성을 퍼뜨려 놓는다면, 본질적으로 펌웨어를 작성하는 셈이다.펌웨어를 수없이 양산하는 일을 멈추고, 코드에게 유효 수명을 길게 늘릴 수 있는 기회를 주어라.앱-티튜드 테스트켄트백은 소프트웨어를 구축하는 세 가지 활동을 다음과 같이 기술했다. “먼저 동작하게 만들어라” “그리고 올바르게 만들어라” : 코드를 리펙터링해서 당신을 포함한 나머지 사람들이 이해할 수 있게 만들고, 요구가 변경되거나 요구를 더 잘 이해하게 되었을 때 코드를 개선할 수 있게 만들어라. “그리고 빠르게 만들어라”프레드 브룩스는 “맨먼스 미신”에서 “버리기 위한 계획을 세우라”고 제안했다.켄트와 프레드는 사실상 똑같은 충고를 하고 있다. 동작하는 것을 배워라. 그리고 나서 더 나은 해결책을 만들어라.현장에서 지켜본 수많은 임베디드 시스템 소프트웨어는 “동작하게 하라”는 활동만을 염두에 두고 작성된 것처럼 보인다. 또는 “빠르게 만들어라”라는 목표에도 집착하는 것처럼 보인다.이러한 문제들은 임베디드 소프트웨어만 국한되지 않는다. 임베디드가 아닌 대다수의 앱들도 그저 동작하도록 만들어진다.앱이 동작하도록 만드는 것을 “개발자용 앱-티튜드 테스트(App-titude test)라고 부른다.이 애플리케이션이 동작한다. 엔지니어는 앱-티튜드 테스트를 통과했다.하지만 이 애플리케이션이 클린 임베디드 아키텍처를 가진다고 말하기는 어렵다.타깃-하드웨어 병목현상임베디드 개발자들은 임베디드가 아니었다면 다루지 않아도 될 특수한 관심사를 많이 가지고 있다.임베디드가 지닌 특수한 문제 중 하나는 타깃-하드웨어 병목현상이다.임베디드 코드가 클린 아키텍처 원칙과 실천법을 따르지 않고 작성된다면, 대개의 경우 코드를 테스트할 수 있는 환경이 해당 특정 타깃으로 국한될 것이다.그리고 그 타깃이 테스트가 가능한 유일한 장소라면 타깃-하드웨어 병목현상이 발생하여 진척이 느려질 것이다.클린 임베디드 아키텍처는 테스트하기 쉬운 임베디드 아키텍처다몇 가지 아키텍처 원칙을 임베디드 소프트웨어와 펌웨어에 적용하여 타깃-하드웨어 병목현상을 줄이는 방법을 살펴보자.계층계층에는 여러 가지가 있다. 일단 아래의 그림에서 나타낸 세 개의 계층부터 시작하자.최소한 하드웨어가 정의된 이후라면 하드웨어와 나머지 시스템 사이의 분리는 주어진다.(아래 그림 참고)이 상태에서 앱-티튜드 테스트를 해보면 대체로 문제가 발생한다. 하드웨어 관련 정보가 코드 전체를 오염시키지 못하게 막을 방법이 전혀 없다.소프트웨어와 펌웨어가 서로 섞이는 일은 안티 패턴이다. 이 안티 패턴을 보이는 코드는 변화에 저항하게 된다.변경하기 어려울 뿐 아니라 변경하는 일 자체가 위험을 수반하여, 때로는 의도치 않은 결과를 불러온다.하드웨는 세부사항이다.소프트웨어와 펌웨어 사이의 경계는 코드와 하드웨어 사이의 경계와는 달리 잘 정의하기가 대체로 힘들다.임베디드 소프트웨어 개발자가 해야 할 일 하나는 이 경계를 분명하게 만드는 것이다.소프트웨어와 펌웨어 사이의 경계는 하드웨어 추상화 계청(Hardware Abstraction Layer, HAL)이라고 부른다.HAL은 자신보다 위에 있는 소프트웨어를 위해 존재하므로, HAL의 API는 소프트웨어의 필요에 맞게 만들어져야 한다.소프트웨어는 이름/값 쌍을 저장하기 위해 어떤 장치에 저장되는지를 전혀 개의치 않는다.이러한 서비스는 HAL이 제공하며, 어떻게 저장하는지에 대해서는 소프트웨어에게 드러내지 않는다.어떤 장치로 구현하느냐는 소프트웨어로부터 반드시 숨겨야 하는 세부사항 이다.계층은 또 다른 계층을 포함할 수도 있다. 그래서 계층의 수가 정해진 상태로 구성되기보다는 프랙털(fractal) 패턴에 더 가깝다.HAL 사용자에게 하드웨어 세부사항을 드러내지 말라클린 임베디드 아키텍처로 설계된 소프트웨어는 타깃 하드웨어에 관계없이 테스트가 가능하다.HAL을 제대로 만들었다면, HAL은 타깃에 상관없이 테스트할 수 있는 경계층 또는 일련의 대체 지점을 제공한다.프로세서는 세부사항이다.프로세서 제작 업체가 제공하는 C 컴파일러는 종종 전역 변수처럼 보이는 것들을 제공하여 해당 프로세서에 한정된 함수 등을 제공할수 있다.클린 임베디드 아키텍처라면 이들 장치 접근 레지스터를 직접 사용하는 코드는 소수의, 순전히 펌웨어로만 한정시켜야 한다.펌웨어가 저수준 함수들을 프로세서 추상화 계층(Processor Abstraction Layer, PAL)의 형태로 격리시켜줄 수 있다.PAL 상위에 위치하는 펌웨어는 타깃-하드웨어에 관계없이 테스트할 수 있게 되어 펌웨어 자체도 덜 딱딱해질 수 있다.운영체제는 세부사항이다.작성한 코드의 수명을 늘리려면, 무조건 운영체제를 세부사항으로 취급하고 운영체제에 의존하는 일을 막아야 한다.소프트웨어는 운영체제를 통해 운영 환경이 제공하는 서비스에 접근한다. OS는 소프트웨어를 펌웨어로부터 분리하는 계층이다.클린 임베디드 아키텍처는 운영체제 추상화 계층(OS Abstraction Layer, OSAL)을 통해 소프트웨어를 운영체제로부터 격리시킨다.소프트웨어가 OS에 직접적으로 의존하는 대신 OSAL에 의존한다면, 이식 작업의 대부분은 기존 OSAL과 호환되도록 새로운 OSAL을 작성하는 데 소요될 것이다.이제 코드 비대화(code bloat) 문제가 염려되기 시작할 수도 있다. 실제로 OSAL은 OS를 사용하는 데 따른 수많은 중복이 격리되어 있는 장소다.하지만 이러한 중복이 그다지 큰 비용을 추가로 초래하지는 않는다.OSAL을 정의하는 일은 결국 애플리케이션에서도 공통 구조를 가지도록 힘쓰는 일이기도 하다.OSAL은 테스트 지점을 만드는 데 도움이 되며, 그 덕분에 소프트웨어 계층의 귀중한 애플리케이션 코드를 타깃이나 OS에 관계없이 테스트할 수 있게 된다.클린 임베디드 아키텍처를 따른 소프트웨어는 타깃 운영체제에 관계없이 테스트할 수 있다.제대로 만든 OSAL은 타깃과는 별개로 테스트할 수 있도록 해주는 경계층 또는 일련의 대체 지점을 제공한다.인터페이스를 통하고 대체 가능성을 높이는 방향으로 프로그래밍하라HAL을 추가하거나 때로는 OSAL을 추가해야 할 뿐만 아니라, 모든 주요 계층(소프트웨어, OS 펌웨어, 하드웨어) 내부에는 이 책에서 설명한 원칙들을 적용할 수 있다.이들 원칙은 관심사를 분리시키고, 인터페이스를 활용하며, 대체 가능성을 높이는 방향으로 프로그래밍하도록 유도한다.계층형 아키텍처(layered architecture)는 인터페이스를 통해 프로그래밍하자는 발상을 기반 으로 한다.모듈들이 서로 인터페이스를 통해 상호작용한다면 특정 서비스 제공자를 다른 제공자로 대체할 수 있다.경험법칙에 따르면 인터페이스 정의는 헤더 파일에 해야 한다. 하지만 이 경우 헤더 파일에 무엇을 포함시켜야 할지는 신중하게 정해야 한다.헤더 파일에는 함수 선언과 그 함수에서 사용하는 상수와 구조체 이름만 포함시켜야 한다.오직 구현체에서만 필요한 데이터 구조, 상수, 타입 정의들로 인터페이스 헤더 파일을 어지럽히지 말라. 이는 단순히 어수선해지는 문제로 끝나지 않고, 결국 원치 않는 의존성을 만들어낼 것이다.구현 세부사항의 가시성을 제한하라. 구현 세부사항은 변경될 거라고 가정하라. 세부사항을 알고 있는 부분이 적을수록 추적하고 변경해야 할 코드도 적어진다.클린 임베디드 아키텍처에서는 모듈들이 인터페이스를 통해 상호작용하기 때문에 각각의 계층 내부에서 테스트가 가능하다. 각 인터페이스는 타깃과는 별개로 테스트할 수 있도록 해주는 경계층 또는 대체 지점을 제공한다.DRY 원칙: 조건부 컴파일 지시자를 반복하지 말라임베디드 프로그램에서는 조건부 컴파일을 사용해서 특정 코드 블록을 활성화하거나 비활성화한다.특히 기억에 남는 문제 사례는 통시 ㄴ관련 애플리케이션이었는데, “#ifdef BOARDV2” 구문이 수천 번이나 사용되었다.이처럼 코드를 반복하는 일을 반복하지 말라(Don’t Repeat Yourself, DRY)는 원칙을 위배한다.만약 HAL이 조건부 컴파일 대신 사용할 수 있는 일련의 인터페이스를 제공한다면, 우리는 링커 또는 어떤 형태의 실시간 바인딩을 사용해서 소프트웨어를 하드웨어와 연결할 수 있다.결론모든 코드가 펌웨어가 되도록 내버려두면 제품이 오래 살아남을 수 없게 된다.오직 타깃 하드웨어에서만 테스트할 수 있는 제품도 마찬가지다.클린 임베디드 아키텍처는 제품이 장기간 생명력을 유지하는 데 도움을 준다." }, { "title": "클린 아키텍처 - 테스트 경계", "url": "/posts/clean_architecture_ch28/", "categories": "Study, Book", "tags": "clean architecture, architecture", "date": "2020-11-17 00:00:00 +0900", "snippet": "Table of Contents 시스템 컴포넌트인 테스트 테스트를 고려한 설계 테스트 API 구조적 결합 보안 결론테스트는 시스템의 일부이며, 아키텍처에도 관여한다. 시스템의 나머지 요소가 아키텍처에 관여하는 것과 동등하게 말이다.시스템 컴포넌트인 테스트아키텍처 관점에서는 모든 테스트가 동일하다.테스트는 태생적으로 의존성 규칙을 따른다. 테스트는 세부적이며 구체적인 것으로, 의존성은 항상 테스트 대상이 되는 코드를 향한다. 실제로 테스트는 아키텍처에서 가장 바깥쪽 원으로 생각할 수 있다.시스템 내부의 어떤 것도 테스트에는 의존하지 않으며, 테스트는 시스템의 컴포넌트를 향해, 항상 원의 안쪽으로 의존한다.테스트는 독립적으로 배포가 가능하다.그리고 테스트는 시스템 컴포넌트 중에서 가장 고립되어 있다.사실 많은 면에서 테스트는 다른 모든 시스템 컴포넌트가 반드시 지켜야 하는 모델을 표현해준다.테스트를 고려한 설계테스트가 시스템의 설계와 잘 통합되지 않으면, 테스트는 깨지기 쉬워지고, 시스템은 뻣뻣해져서 변경하기가 어려워진다.물론 문제는 결합이다. 시스템에 강하게 결합된 테스트라면 시스템이 변경될 때 함께 변경되어야만 한다.사소한 변경이라도 이와 결합된 수많은 테스트를 망가뜨릴 수 있다.상황은 더 심각해질 수 있다. 시스템의 공통 컴포넌트가 변경되면 수백, 심지어 수천 개의 테스트가 망가진다.이 문제는 깨지기 쉬운 테스트 문제(Fragile Tests Problem) 로 알려져 있다.깨지기 쉬운 테스트는 시스템을 뻣뻣하게 만든다는 부작용을 낳을 때가 많다.간단한 변경이 대량의 테스트 실패로 이어진다면, 개잘자는 그러한 변경을 하지 않으려 들 것이다.이 문제를 해결하려면 테스트를 고려해서 설계해야 한다.소프트웨어 설계의 첫 번째 규칙은 언제나 같다. 변동성이 있는 것에 의존하지 말라.시스템과 테스트를 설계할 때, GUI를 사용하지 않고 업무 규칙을 테스트할 수 있게 해야 한다.테스트 API이 목표를 달성하려면 테스트가 모든 업무 규칙을 검증하는 데 사용할 수 있도록 특화된 API를 만들면 된다.이러한 API는 보안 제약사항을 무시할 수 있으며, 값비싼 자원은 건너뛰고, 시스템을 테스트 가능한 특정 상태로 강제하는 강력한 힘을 지녀야만 한다.이 API는 사용자 인터페이스가 사용하는 인터렉터와 인터페이스 어댑터들의 상위 집합이 될 것이다.테스트 API는 테스트를 애플리케이션으로부터 분리할 목적으로 사용한다.테스트 구조를 애플리케이션 구조로부터 결합을 분리하는 게 목표다.구조적 결합구조적 결합은 테스트 결합 중에서 가장 강하며, 가장 은밀하게 퍼져 나가는 유형이다.테스트 API의 역활은 애플리케이션의 구조를 테스트로부터 숨기는 데 있다.이렇게 만들면 상용 코드를 리팩터링하거나 진화시키더라도 테스트에는 전혀 영향을 주지 않는다. 또한 테스트를 리팩터링하거나 진화시킬 때도 상용 코드에는 전혀 영향을 주지 않는다.이처럼 따로따로 진화할 수 있다는 점은 필수적인데, 시간이 지날수록 테스트는 계속해서 더 구체적이고 더 특화된 형태로 변할 것이고, 반대로 사용 코드는 더 추상적이고 더 범용적인 형태로 변할 것이기 때문이다.하지만 구조적 결합이 강하면 필수적인 진화 과정을 방해할뿐만 아니라, 상용 코드의 범용성과 유연성이 충분히 좋아지지 못하게 막는다.보안테스트 API가 지닌 강력한 힘을 운영 시스템에 배포하면 위험에 처할 수 있다.위험을 피하고 싶다면, 테스트 API 자체와 테스트 API 중 위험한 부분의 구현부는 독립적으로 배포할 수 있는 컴포넌트로 분리해야 한다.결론테스트는 시스템 외부에 있지 않다. 오히려 시스템의 일부다.따라서 테스트에서 기대하는 안정성과 회귀의 이점을 얻을 수 있으려면 테스트는 잘 설계돼야만 한다.테스트를 시스템의 일부로 설계하지 않으면 테스트는 깨지기 쉽고 유지보수하기 어려워지는 경향이 있다.이러한 테스트는 유지보수하기가 너무 힘들기 때문에 결국 방바닥의 휴지처럼 버려지는 최후를 맡는다." }, { "title": "클린 아키텍처 - &#39;크고 작은 모든&#39; 서비스들", "url": "/posts/clean_architecture_ch25/", "categories": "Study, Book", "tags": "clean architecture, architecture", "date": "2020-11-16 00:00:00 +0900", "snippet": "Table of Contents 서비스 아키텍처? 서비스의 이점? 횡단 관심사 결론서비스 지향 ‘아키텍처’와 마이크로서비스 ‘아키텍처’는 최근에 큰 인기를 끌고 있다. 그 이유는 다음과 같다. 서비스를 사용하면 상호 결합이 철저하게 분리되는 것처럼 보인다. 이는 일부만 맞는 말이다. 서비스를 사용하면 개발과 배포 독립성을 지원하는 것처럼 보인다. 이는 일부만 맞는 말이다.서비스 아키텍처?먼저 서비스를 사용한다는 것이 본질적으로 아키텍처에 해당하는지에 대해 생각해 보자. 이 개념은 명백히 사실이 아니다.시스템의 아키텍처는 의존성 규칙을 준수하며 고수준의 정책을 저수준의 세부사항으로부터 분리하는 경계에 의해 정의된다.단순히 애플리케이션의 행위를 분리할 뿐인 서비스라면 값비싼 함수 호출에 불과하며, 아키텍처 관점에서 꼭 중요하다고 볼 수는 없다.기능을 프로세스나 플랫폼에 독립적이 되게끔 서비스들을 생성하면 의존성 규칙 준수 여부와 상관없이 큰 도움이 될 때가 많다.그러나 서비스 그 자체로는 아키텍처를 정의하지 않는다.모노리틱 시스템이나 컴포넌트 기반 시스템에서 아키텍처를 정의하는 요소는 바로 의존성 규칙을 따르며 아키텍처 경계를 넘나드는 함수 호출들이다.반면 시스템의 나머지 많은 함수들은 행위를 서로 분리할 뿐이며, 아키텍처적으로는 전혀 중요하지 않다.서비스도 마찬가지다. 결국 서비스는 프로세스나 플랫폼 경계를 가로지르는 함수 호출에 지나지 않는다.아키텍처적으로 중요한 서비스도 있지만, 중요하지 않는 서비스도 존재한다.여기에서 우리가 관심을 가지는 서비스는 전자다.서비스의 이점? 결합 분리의 오류시스템을 서비스들로 분리함으로써 얻게 되리라 예상되는 큰 이점 하나는 서비스 사이의 결합이 확실히 분리된다는 점이다.서비스는 다른 서비스의 변수에 직접 접근할 수 없다. 그리고 모든 서비스의 인터페이스는 반드시 잘 정의되어 있어야 한다.물론 서비스는 개별 변수 수준에서는 각각 결합이 분리된다. 하지만 프로세서 내의 또는 네트워크 상의 공유 자원 때문에 결합될 가능성이 여전히 존재한다.더욱이 서로 공유하는 데이터에 의해 이들 서비스는 강력하게 결합되어 버린다.예를 들어 서비스 사이를 오가는 데이터 레코드에 새로운 필드를 추가한다면, 이 필드를 사용해 동작하는 모든 서비스는 반드시 변경되어야 한다.서비스들은 이 데이터 레코드에 강하게 결합되고, 서비스들 사이는 서로 간접적으로 결합되어 버린다.인터페이스가 잘 정의되어 있어야 한다는 이점에 대해서라면 이는 명백히 사실이다. 하지만 함수의 경우에도 전혀 다르지 않다.서비스 인터페이스가 함수 인터페이스보다 더 엄밀하거나, 더 엄격하고, 더 잘 정의되는 것은 아니다. 개발 및 배포 독립성의 오류전담팀이 서비스를 소유하고 운영한다는 점이 또 다른 이점이다. 그래서 데브옵스 전략의 일환으로 전담팀에서 각 서비스를 작성하고, 유지보수하며, 운영하는 책임을 질 수 있다.이러한 개발 및 배포 독립성은 확장 가능한 것으로 간주된다.어느 정도 일리가 있지만, 극히 일부일 뿐이다.첫째로, 대규모 엔터프라이즈 시스템은 서비스 기반 시스템 이외에도, 모노리틱 시스템이나 컴포넌트 기반 시스템으로도 구축할 수 있다는 사실은 역사적으로 증명되어 왔다.따라서 서비스는 확장 가능한 시스템을 구축하는 유일한 선택지가 아니다.둘째, ‘결합 분리의 오류’에 따르면 서비스라고 해서 항상 독립적으로 개발하고, 배포하며, 운영할 수 있는 것은 아니다.데이터나 행위에서 어느 정도 결합되어 있다면 결합된 정도에 맞게 개발, 배포, 운영을 조정해야만 한다.횡단 관심사아키텍처 경계가 서비스 사이에 있지 않다. 오히려 서비스를 관통하며, 서비스를 컴포넌트 단위로 분할한다.서비스 내부는 의존성 규칙도 준수하는 컴포넌트 아키텍처로 설계해야 한다.이 서비스들은 시스템의 아키텍처 경계를 정의하지 않는다. 아키텍처 경계를 정의하는 것은 서비스 내에 위치한 컴포넌트다.결론서비스는 시스템의 확장성과 개발 가능성 측면에서 유용하지만, 그 자체로는 아키텍처적으로 그리 중요한 요소는 아니다.시스템의 아키텍처는 시스템 내부에 그어진 경계와 경계를 넘나드는 의존성에 의해 정의된다.서비스는 단 하나의 아키텍처 경계로 둘러싸인 단일 컴포넌트로 만들 수 있다. 혹은 여러 아키텍처 경계로 분리된 다수의 컴포넌트로 구성할 수도 있다.드물게는 클라이언트와 서비스가 강하게 결합되어 아키텍처적으로 아무런 의미가 없을 때도 있다." }, { "title": "클린 아키텍처 - 부분적 경계", "url": "/posts/clean_architecture_ch24/", "categories": "Study, Book", "tags": "clean architecture, architecture", "date": "2020-11-12 00:00:00 +0900", "snippet": "Table of Contents 마지막 단계를 건너뛰기 일차원 경계 퍼사드 결론아키텍처 경계를 완벽하게 만드는 데는 비용이 많이 든다. 쌍방향의 다형적 Boundary 인터페이스, Input과 Output을 위한 데이터 구조를 만들어야 할 뿐만 아니라, 두 영역을 독립적으로 컴파일하고 배포할 수 있는 컴포넌트로 격리하는 데 필요한 모든 의존성을 관리해야 한다.이렇게 만들려면 엄청난 노력을 기울여야 하고, 유지하는 데도 또 엄청난 노력이 든다.많은 이가 이러한 종류의 선행적인 설계를 탐탁치 않게 여기는데, YAGNI(You Aren’t Going to Need It) 원칙을 위배하기 때문이다.하지만 아키텍트라면 그래도 필요할지도 모른다고 생각이 들 수도 있다.만약 그렇다면 부분적 경계(partial boundary)를 구현해볼 수 있다.마지막 단계를 건너뛰기부분적 경계를 생성하는 방법 하나는 독립적으로 컴파일하고 배포할 수 있는 컴포넌트를 만들기 위한 작업은 모두 수행한 후, 단일 컴포넌트에 그대로 모아만 두는 것이다.이 모두를 단일 컴포넌트로 컴파일해서 배포한다.이처럼 부분적 경계를 만들려면 완벽한 경계를 만들 때 만큼의 코드량과 사전 설계가 필요하다.하지만 다수의 컴포넌트를 관리하는 작업은 하지 않아도 된다. 추적을 위한 버전 번호도 없으며, 배포 관리 부담도 없다. 이 차이는 가볍지 않다.일차원 경계완벽한 형태의 아키텍처 경계는 양방향으로 격리된 상태를 유지해야 하므로 쌍방향 Boundary 인터페이스를 사용한다.양방향으로 격리된 상태를 유지하려면 초기 설정할 때나 지속적으로 유지할 때도 비용이 많이 든다.추후 완벽한 형태의 경계로 확장할 수 있는 공간을 확보하고자 할 때 활용할 수 있는 더 간단한 구조가 아래 다이어그램에 나와 있다.이는 전통적인 전략 패턴을 사용한 전형적인 사례다.이 방식이 미래에 필요할 아키텍처 경계를 위한 무대를 마련한다는 점은 명백하다. Client를 ServiceImpl로부터 격리시키는 데 필요한 의존성 역전이 이미 적용되었기 때문이다.또한 이 다이어그램의 위험천만한 점선 화살표에서 보듯이 이러한 분리는 매우 빠르게 붕괴될 수 있다는 점 역시 분명하다.쌍방향 인터페이스가 없고 개발자와 아키텍트가 근면 성실하고 제대로 훈련되어 있지 않다면, 이 점선과 같은 비밀 통로가 생기는 일을 막을 방법이 없다.퍼사드이보다 훨씬 더 단순한 경계는 퍼사드 패턴으로 아래 다이어그램과 같다.이 경우에는 심지어 의존성 역전까지도 희생한다. 경계는 퍼사드 클래스로만 간단히 정의된다.즉, 클라이언트는 이들 서비스 클래스에 직접 접근할 수 없다.하지만 Client가 이 모든 서비스 클래스에 대해 추이 종속성을 가지게 된 것을 주목하자.이러한 구조라면 비밀 통로 또한 정말 쉽게 만들 수 있다는 사실도 충분히 파악할 수 있을 것이다.결론아키텍처 경계를 부분적으로 구현하는 간단한 방법 세 가지를 봤다. 이 외에도 방법은 많다.이러한 접근법 각각은 나름의 비용과 장점을 지닌다. 각 접근법은 완벽한 형태의 경계를 담기 위한 공간으로써, 적절하게 사용할 수 있는 상황이 서로 다르다.또한 각 접근법은 해당 경계가 실제로 구체화되지 않으면 가치가 떨어질 수 있다.아키텍처 경계가 언제, 어디에 존재해야 할지, 그리고 그 경계를 완벽하게 구현할지 아니면 부분적으로 구현할지를 결정하는 일 또한 아키텍트의 역활이다." }, { "title": "클린 아키텍처 - 프레젠터와 험블 객체", "url": "/posts/clean_architecture_ch23/", "categories": "Study, Book", "tags": "clean architecture, architecture", "date": "2020-11-11 00:00:00 +0900", "snippet": "Table of Contents 험블 객체 패턴 프레젠터와 뷰 테스트와 아키텍처 데이터베이스 게이트웨이 데이터 매퍼 서비스 리스너 결론프레젠터는 험블 객체(Humble Object) 패턴을 따른 형태로, 아키텍처 경계를 식별하고 보호하는 데 도움이 된다.실제로 이전 장 “클린 아키텍처”는 험블 객체 구현체들로 가득 차 있었다.험블 객체 패턴험블 객체 패턴은 디자인 패턴으로, 테스트하기 어려운 행위와 테스트하기 쉬운 행위를 단위테스트 작성자가 분리하기 쉽게 하는 방법으로 고안 되었다.아이디어는 매우 단순하다.행위들을 두 개의 모듈 또는 클래스로 나눈다.이들 모듈 중 하나가 험블이다. 가장 기본적인 본질을 남기고, 테스트하기 어려운 행위를 모두 험블 객체 로 옮긴다.나머지 모듈에는 험블 객체에 속하지 않은 테스트하기 쉬운 행위를 모두 옮긴다.험블 객체 패턴을 사용하면 두 부류의 행위를 분리하여 프레젠터와 뷰라는 서로 다른 클래스로 만들 수 있다.프레젠터와 뷰뷰는 험블 객체 이고 테스트하기 어렵다. 이 객체에 포함된 코드는 가능한 간단하게 유지한다. 뷰는 데이터를 GUI로 이동시키지만, 데이터를 직접 처리하지 않는다.프리젠터는 테스트하기 쉬운 객체 다.프리젠터의 역활은 애플리케이션으로부터 데이터를 받아 화면에 표현할 수 있는 포맷으로 만드는 것이다.이를 통해 뷰는 데이터를 화면으로 전달하는 간단한 일만 처리하도록 만든다.뷰는 뷰 모델의 데이터를 화면으로 로드할 뿐이며, 이 외에 뷰가 맡은 역활은 전혀 없다.따라서 뷰는 보잘것없다(humble)테스트와 아키텍처테스트 용이성은 좋은 아키텍처가 지녀야 할 속성으로 오랫동안 알려져 왔다.험블 객체 패턴이 좋은 예인데, 행위를 테스트하기 쉬운 부분과 테스트하기 어려운 부분으로 분리하면 아키텍처 경계가 정의되기 때문이다.프레젠터와 뷰 사이의 경계는 이러한 경계 중 하나이며, 이 밖에도 수많은 경계가 존재한다.데이터베이스 게이트웨이유스케이스 인터렉터와 데이터베이스 사이에는 데이터베이스 게이트웨이가 위치한다. 이 게이트웨이는 다형적 인터페이스로, 애플리케이션이 데이터베이스에 수행하는 CRUD 작업과 관련된 모든 메서드를 포함한다.다시 한번 말하지만 유스케이스 계층은 SQL을 허용하지 않는다. 따라서 유스케이스 계층은 필요한 메서드를 제공하는 게이트웨이 인터페이스를 호출한다.그리고 인터페이스의 구현체는 DB 계층에 위치한다. 이 구현체는 험블 객체 다.인터랙터는 애플리케이션에 특화된 업무 규칙을 캡슐화하기 때문에 헙블 객체가 아니다.따라서 테스트하기 쉬운데, 게이트웨이는 스텁이나 테스트 더블로 적당히 교체할 수 있기 때문이다.데이터 매퍼객체 관계 매퍼(ORM) 같은 건 사실 존재하지 않는다. 이유는 객체는 데이터 구조가 아니기 때문이다.데이터는 모두 private로 선언되므로 객체의 사용자는 데이터를 볼 수 없다.사용자는 public 메서드만 볼 수 있다. 따라서 사용자 관점에서 볼 때 객체는 단순히 오퍼레이션의 집합 이다.객체와 달리 데이터 구조는 함축된 행위를 가지지 않는 public 데이터 변수 집합이다.ORM보다는 차라리 ‘데이터 매퍼(Data Mapper)’라고 부르는 편이 나아 보이는데, 관계형 데이터베이스 테이블로부터 가져온 데이터를 데이터 구조에 맞게 담아주기 때문이다.ORM은 데이터베이스 계층이다. ORM은 게이트웨이 인터페이스와 데이터베이스 사이에서 일종의 또 다른 험블 객체 경계를 형성한다.서비스 리스너애플리케이션이 다른 서비스와 통신해야 한다면, 또는 일련의 서비스를 제공해야 한다면, 우리는 여기에서 험블 객체 패턴을 발견할 수 있다.애플리케이션은 데이터를 간단한 데이터 구조 형태로 로드한 후, 이 데이터 구조를 경계를 가로질러서 특정 모듈로 전달한다. 그리면 해당 모듈은 데이터를 적절한 포맷으로 만들어서 외부 서비스로 전송한다.결론경계를 넘나드는 통신은 거의 모두 간단한 데이터 구조를 수반할 때가 많고, 대개 그 경계는 테스트하기 어려운 무언가와 테스트하기 쉬운 무언가로 분리될 것이다.그리고 이러한 아키텍처 경계에서 험블 객체 패턴을 사용하면 전체 시스템의 테스트 용이성을 크게 높일 수 있다." }, { "title": "클린 아키텍처 - 클린 아키텍처", "url": "/posts/clean_architecture_ch22/", "categories": "Study, Book", "tags": "clean architecture, architecture", "date": "2020-11-10 00:00:00 +0900", "snippet": "Table of Contents 의존성 규칙 엔티티 유스케이스 인터페이스 어댑터 프레임워크와 드라이버 원은 네 개여야만 하나? 경계 횡단하기 경계를 횡단하는 데이터는 어떤 모습인가 결론지난 수십 년간 우리는 시스템 아키텍처와 관련된 여러 가지 아이디어를 봐왔다. 아래의 내용도 여기에 포함된다. 육각형 아키텍처(Hexagonal Architecture) DCI(Data, Context and Interaction) BCE(Boundary-Control-Entiry)이 아키텍처들의 목표는 모두 같다. 바로 관심사의 분리(seperation of concerns)다. 이들은 모두 소프트웨어를 계층으로 분리함으로써 관심사의 분리라는 목표를 달성할 수 있었다.이들 아키텍처들의 시스템은 다음과 같은 특징을 지니도록 만든다. 프레임워크 독립성 테스트 용이성 UI 독립성 DB 독립성 모든 외부 에이전시에 대한 독립성아래의 다이어그램은 이들 아키텍처 전부를 실행 가능한 하나의 아이디어로 통합하려는 시도다.의존성 규칙위의 다이어그램에서 각각의 동심원은 소프트웨어에서 서로 다른 영역을 표현한다.보통 안으로 들어갈수록 고수준의 소프트웨어가 된다. 바깥쪽 원은 메커니즘이고, 안쪽 원은 정책이다.이러한 아키텍처가 동작하도록 하는 가장 중요한 규칙은 의존성 규칙(Dependency Rule)이다.소스 코드 의존성은 반드시 안쪽으로, 고수준의 정책을 향해야 한다.내부의 원에 속한 요소는 외부의 원에 속한 어떤 것도 알지 못한다. 특히 내부의 원에 속한 코드는 외부의 원에 선언된 어떤 것에 대해서도 그 이름을 언급해서는 절대 안 된다.같은 이유로, 외부의 원에 선언된 데이터 형식도 내부의 원에서 절대로 사용해서는 안 된다.우리는 외부 원에 위치한 어떤 것도 내부의 원에 영향을 주지 않기를 바란다.엔티티엔티티는 전사적인 핵심 업무 규칙을 캡슐화한다. 엔티티는 메서드를 가지는 객체이거나 일련의 데이터 구조와 함수의 집합일 수도 있다.기업의 다양한 애플리케이션에서 엔티티를 재사용할 수만 있다면, 그 형태는 그다지 중요하지 않다.전사적이지 않은 단순한 단일 애플리케이션을 작성하고 있다면 엔티티는 해당 애플리케이션의 업무 객체가 된다.이 경우 엔티티는 가장 일반적이며 고수준인 규칙을 캡슐화한다.운영 관점에서 특정 애플리케이션에 무언가 변경이 필요하더라도 엔티티 계층에는 절대로 영향을 주어서는 안 된다.유스케이스유스케이스 계층의 소프트웨어는 애플리케이션에 특화된 업무 규칙을 포함한다.또한 유스케이스 계층의 소프트웨어는 시스템의 모든 유스케이스를 캡슐화하고 구현한다.유스케이스는 엔티티로 들어오고 나가는 데이터 흐름을 조정하며, 엔티티가 자신의 핵심 업무 규칙을 사용해서 유스케이스의 목적을 달성하도록 이끈다.유스케이스 계층에서 발생한 변경이 엔티티에 영향을 줘서는 안 된다.또한 외부 요소에서 발생한 변경이 이 계층에 영향을 줘서도 안 된다.유스케이스 계층은 이러한 관심사로부터 격리되어 있다.하지만 운영 관점에서 애플리케이션이 변경된다면 유스케이스가 영향을 받으며, 따라서 이 계층의 소프트웨어에도 영향을 줄 것이다.유스케이스의 세부사항이 변하면 이 계층의 코드 일부는 분명 영향을 받을 것이다.인터페이스 어댑터인터페이스 어댑터 계층은 일련의 어댑터들로 구성된다.어댑터는 데이터를 유스케이스와 엔티티에게 가장 편리한 형식에서 DB나 웹 같은 외부 에이전시에게 가장 편리한 형식으로 변환한다.이 계층은, 예를 들어 GUI의 MVC 아키텍처를 모두 포괄 한다. 프레젠터, 뷰, 컨트롤러는 모두 인터페이스 어댑터 계층에 속한다.모델은 그저 데이터 구조 정도에 지나지 않으며, 컨트롤러에서 유스케이스로 전달되고, 다시 유스케이스에서 프레젠터와 뷰로 되돌아 간다.마찬가지로 이 계층은 데이터를 엔티티와 유스케이스에게 가장 편리한 형식에서 영속성용으로 사용 중인 임의의 프레임워크(즉, DB)가 이용하기에 가장 편리한 형식으로 변환한다.이 원 안에 속한 어떤 코드도 DB에 대해 조금도 알아서는 안 된다.예컨데 SQL 기반의 DB를 사용한다면 모든 SQL은 이 계층을 벗어나서는 안 된다. 특히 이 계층에서도 DB를 담당하는 부분으로 제한되어야 한다.또한 이 계층에는 데이터를 외부 서비스와 같은 외부적인 형식에서 유스케이스나 엔티티에서 사용되는 내부적인 형식으로 변환하는 또 다른 어댑터가 필요하다.프레임워크와 드라이버위의 다이어그램에서 가장 바깥쪽 계층은 일반적으로 DB나 웹 프레임워크 같은 프레임워크나 도구들로 구성된다.일반적으로 이 계층에서는 안쪽 원과 통신하기 위한 접합 코드 외에는 특별히 더 작성해야 할 코드가 그다지 많지 않다.프레임워크나 드라이버 계층은 모두 세부사항이 위치하는 곳이다.우리는 이러한 것들을 모두 외부에 위치시켜서 피해를 최소화 한다.원은 네 개여야만 하나?위의 다이어그램에 표시한 원들은 그저 개념을 설명하기 위한 하나의 예시일 뿐이다.네 개보다 더 많은 원이 필요할 수도 있다. 항상 네 개만 사용해야 한다는 규칙은 없다.하지만 어떤 경우에도 의존성 규칙은 적용 된다.소스코드 의존성은 항상 안쪽을 향한다.안쪽으로 이동할수록 추상화와 정책의 수준은 높아진다. 가장 바깥쪽 원은 저수준의 구체적인 세부사항으로 구성된다.그리고 안쪽으로 이동할수록 소프트웨어는 점점 추상화되고 더 높은 수준의 정책들을 캡슐화한다.따라서 가장 안쪽 원은 가장 범용적이며 높은 수준 을 가진다.경계 횡단하기위의 다이어그램은 원의 경계를 횡단하는 방법을 보여주는 예시이다.우선 제어흐름에 주목해 보자. 제어흐름은 컨트롤러에서 시작해서, 유스케이스를 지난 후, 프레젠터가 실행되면서 마무리된다.다음은 소스코드 의존성도 주목해 보자. 각 의존성은 유스케이스를 향해 안쪽을 가리킨다.이처럼 제어흐름과 의존성의 방향이 명백히 반대여야 하는 경우, 대체로 의존성 역전 원칙을 사용하여 해결한다.동적 다형성을 이용하여 소스 코드 의존성을 제어흐름과는 반대로 만들수 있고, 이를 통해 제어흐름이 어느 방향으로 흐르더라도 의존성 규칙을 준수할 수 있다.경계를 횡단하는 데이터는 어떤 모습인가경계를 가로지르는 데이터는 흔히 간단한 데이터 구조로 이루어져 있다.기본적인 구조체나 간단한 데이터 전송 객체(data transfer object) 등 원하는 대로 고를 수 있다. 그게 아니라면 데이터를 해시맵으로 묶거나 객체로 구성할 수도 있다.중요한 점은 격리된 간단한 데이터 구조가 경계를 가로질러 전달 된다는 사실이다.엔티티 객체나 데이터베이스의 행을 전달하는 일은 원치 않는다.데이터 구조가 어떤 의존성을 가져 의존성 규칙을 위배하게 되는 일은 바라지 않는다.따라서 경계를 가로질러 데이터를 전달할 때, 데이터는 항상 내부의 원에서 사용하기에 가장 편리한 형태 를 가져야만 한다.결론소프트웨어를 계층으로 분리하고 의존성 규칙을 준수한다면 본질적으로 테스트하기 쉬운 시스템을 만들게 될 것이며, 그에 따른 이점을 누릴 수 있다.DB나 웹 프레임워크와 같은 시스템의 외부 요소가 구식이 되더라도, 이들 요소를 야단스럽지 않게 교체할 수 있다." }, { "title": "클린 아키텍처 - 소리치는 아키텍처", "url": "/posts/clean_architecture_ch21/", "categories": "Study, Book", "tags": "clean architecture, architecture", "date": "2020-11-09 00:00:00 +0900", "snippet": "Table of Contents 아키텍처의 테마 아키텍처의 목적 하지만 웹은? 프레임워크는 도구일 뿐, 삶의 방식은 아니다 테스트하기 쉬운 아키텍처 결론아키텍처의 테마Object Oriented Software Engineering에서 이바 야콥슨은 소프트웨어 아키텍처는 시스템의 유스케이스를 지원하는 구조라고 지적했다.소프트웨어 애플리케이션의 아키텍처는 애플리케이션의 유스케이스에 대해 소리쳐야 한다.아키텍처는 프레임워크에 대한 것이 아니다. 아키텍처를 프레임워크로부터 제공받아서는 절대 안 된다.프레임워크는 사용하는 도구일 뿐, 아키텍처가 준수해야 할 대상이 아니다.아키텍처를 프레임워크 중심으로 만들어버리면 유스케이스가 중심이 되는 아키텍처는 절대 나올 수 없다.아키텍처의 목적좋은 아키텍처는 유스케이스를 그 중심에 두기 때문에, 프레임워크나 도구 환경에 전혀 구애받지 않고 유스케이스를 지원하는 구조를 아무런 문제 없이 기술할 수 있다.좋은 소프트웨어 아키텍처는 여타 개발 환경 문제나 도구에 대해서는 결정을 미룰 수 있도록 만든다.뿐만 아니라 이러한 결정을 쉽게 번복할 수 있도록한다.좋은 아키텍처는 유스케이스에 중점을 두며, 지엽적인 관심사에 대한 결합은 분리시킨다.하지만 웹은?시스템이 웹을 통해 전달된다는 사실이 시스템의 아키텍처에 영향을 줘서는 안 된다.웹은 전달 메커니즘(입출력 장치)이며, 애플리케이션 아키텍처에서도 그와 같이 다뤄야 한다.웹을 통해 전달 된다는 사실은 세부사항 이며, 시스템 구조를 지배해서는 절대 안 된다.실제 애플리케이션을 웹으로 전달할지 여부는 미루어야 할 결정사항 중 하나다.프레임워크는 도구일 뿐, 삶의 방식은 아니다프레임워크는 매우 강력하고 상당히 유용할 수 있다. 그래서 “프레임워크가 모든 것을 하게 하자”라는 태도를 취할 수 있다.이는 우리가 취하고 싶은 태도가 아니다.어떻게 하면 아키텍처를 유스케이스에 중점을 둔 채 그대로 보존할 수 있을지를 생각하라. 프레임워크가 아키텍처의 중심을 차지하는 일을 막을 수 있는 전략을 개발하라.테스트하기 쉬운 아키텍처프레임워크를 전혀 준비하지 않더라도 필요한 유스케이스 전부에 대해 단위 테스트를 할 수 있어야 한다.엔티티 객체는 반드시 오래된 방식의 간단한 객체(plain old object)여야 하며, 프레임워크나 데이터베이스, 또는 여타 복잡한 것들에 의존해서는 안 된다.유스케이스 객체가 엔티티 객체를 조작해야 한다.최종적으로, 프레임워크로 인한 어려움을 겪지 않고도 반드시 이 모두를 있는 그대로 테스트할 수 있어야 한다.결론아키텍처는 시스템을 이야기해야 하며, 시스템에 적용한 프레임워크에 대해 이야기해서는 안 된다.새로 합류한 프로그래머는 시스템이 어떻게 전달될지 알지 못한 상태에서도 시스템의 모든 유스케이스를 이해할 수 있어야 한다." }, { "title": "클린 아키텍처 - 업무 규칙", "url": "/posts/clean_architecture_ch20/", "categories": "Study, Book", "tags": "clean architecture, architecture", "date": "2020-11-05 00:00:00 +0900", "snippet": "Table of Contents 엔티티 유스케이스 요청 및 응답 모델 결론애플리케이션을 업무 규칙과 플러그인으로 구분하려면 업무 규칙이 실제로 무엇인지를 잘 이해해야만 한다.엄밀하게 말하면 업무 규칙 은 사업적으로 수익을 얻거나 비용을 줄일 수 있는 규칙 또는 절차다.더 엄밀하게 말하면 컴퓨터상으로 구현했는지와 상관없이, 업무 규칙은 사업적으로 수익을 얻거나 비용을 줄일 수 있어야 한다. 심지어 사람이 수동으로 직접 수행하더라도 마찬가지다.이러한 규칙을 핵심 업무 규칙(Critical Business Rule) 이라고 부를 것이다.이들 규칙은 사업 자체에 핵심적이며, 규칙을 자동화하는 시스템이 없더라도 업무 규칙은 그대로 존재하기 때문이다.핵심 업무 규칙은 보통 데이터를 요구한다.우리는 이러한 데이터를 핵심 업무 데이터(Critical Business Data) 라고 부르겠다. 이러한 데이터는 시스템으로 자동화되지 않는 경우에도 존재하는 그런 데이터다.핵심 규칙과 핵심 데이터는 본질적으로 결합되어 있기 때문에 객체로 만들 좋은 후보가 된다.우리는 이러한 유형의 객체를 엔티티라고 하겠다.엔티티엔티티는 컴퓨터 시스템 내부의 객체로서, 핵심 업무 데이터를 기반으로 동작하는 일련의 조그만 핵심 업무 규칙을 구체화한다.엔티티 객체는 핵심 업무 데이터를 직접 포함하거나 핵심 업무 데이터에 매우 쉽게 접근할 수 있다.엔티티의 인터페이스는 핵심 업무 데이터를 기반으로 동작하는 핵심 업무 규칙을 구현한 함수들로 구성된다.우리는 이러한 종류의 클래스를 생성할 때, 업무에서 핵심적인 개념을 구현하는 소프트웨어는 한데 모으고, 구축 중인 자동화 시스템의 나머지 모든 고려사항과 분리시킨다.이 클래스는 DB, UI, 서드파티 프레임워크에 대한 고려사항들로 인해 오염되어서는 절대 안 된다.이 클래스는 어떤 시스템에서도 업무를 수행할 수 있으며, 시스템의 표현 형식이나 데이터 저장 방식, 그리고 해당 시스템에서 컴퓨터가 배치되는 방식과도 무관하다.엔티티는 순전히 업무에 대한것이며, 이외의 것은 없다.엔티티의 유일한 요구조건은 핵심 업무 데이터와 핵심 업무 규칙을 하나로 묶어서 별도의 소프트웨어 모듈로 만들어야 한다는 것이다.유스케이스모든 업무 규칙이 엔티티처럼 순수한 것은 아니다. 자동화된 시스템이 동작하는 방법을 정의하고 제약함으로써 수익을 얻거나 비용을 줄이는 업무 규칙도 존재한다.이러한 규칙은 자동화된 시스템의 요소로 존재해야만 의미가 있으므로 수동 환경에서는 사용될 수 없다.시스템에서 신상정보 화면을 모두 채우고 검증한 후, 신용도가 하한선보다 높은지가 확인된 이후에 대출 견적 화면으로 진행되어야 한다는 식으로 은행에서 업무 요건을 기술했다고 해보자.바로 이것이 유스케이스다. 유스케이스는 자동화된 시스템이 사용되는 방법을 설명한다.유스케이스는 사용자가 제공해야 하는 입력, 사용자에게 보여줄 출력, 그리고 해당 출력을 생성하기 위한 처리 단계를 기술한다.유스케이스는 애플리케이션에 특화된 업무 규칙 을 설명한다.유스케이스는 엔티티 내부의 핵심 업무 규칙을 어떻게, 그리고 언제 호출할지를 명시하는 규칙을 담는다.주목할 또 다른 사실은 인터페이스로 들어오는 데이터와 인터페이스에서 되돌려주는 데이터를 형식 없이 명시한다는 점만 빼면 유스케이스는 사용자 인터페이스를 기술하지 않는다는 점이다.유스케이스는 시스템이 사용자에게 어떻게 보이는지를 설명하지 않는다. 이보다는 애플리케이션에 특화된 규칙을 설명하며, 이를 통해 사용자와 엔티티 사이의 상호작용을 규정한다.시스템에서 데이터가 들어오고 나가는 방식은 유스케이스와 무관하다.유스케이스는 객체다. 애플리케이션에 특화된 규칙을 구현하는 하나 이상의 함수를 제공한다.또한 유스케이스는 입력 데이터, 출력 데이터, 유스케이스가 상호작용하는 엔티티에 대한 참조 데이터 등의 데이터 요소를 포함한다.엔티티는 자신을 제어하는 유스케이스에 대해 아무것도 알지 못한다. 반대로 저수준인 유스케이스는 고수준인 엔티티에 대해 알고 있다.왜 엔티티는 고수준이며, 유스케이스는 저수준일까? 왜냐하면 유스케이스는 단일 애플리케이션에 특화되어 있으며, 따라서 해당 시스템의 입력과 출력에 보다 가깝게 위치하기 때문이다.엔티티는 수많은 다양한 애플리케이션에서 사용될 수 있도록 일반화된 것이므로, 각 시스템의 입력이나 출력에서 더 멀리 떨어져 있다.유스케이스는 엔티티에 의존한다. 반면 엔티티는 유스케이스에 의존하지 않는다.요청 및 응답 모델유스케이스는 입력 데이터를 받아서 출력 데이터를 생성한다. 그런데 제대로 구성된 유스케이스 객체라면 데이터를 사용자나 또 다른 컴포넌트와 주고 받는 방식에 대해서는 전혀 눈치챌 수 없어야 한다.우리는 유스케이스 클래스의 코드가 HTML이나 SQL에 대해 알게 되는 일은 절대로 원치 않는다.요청 및 응답 모델는 사용자나 다른 컴포넌트와 주고 받는 방식에 대한 의존성을 제거하는 일은 매우 중요하다.요청 및 응답 모델이 독립적이지 않다면, 그 모델에 의존하는 유스케이스도 결국 해당 모델이 수반하는 의존성에 간접적으로 결합되어 버린다.엔티티 객체를 가리키는 참조를 요청 및 응답 데이터 구조에 포함하려는 유혹을 받을 수도 있다.엔티티와 요청/응답 모델은 상당히 많은 데이터를 공유하므로 이러한 방식이 적합해 보일 수도 있다.하지만 이 유혹을 떨쳐내라! 이들 두 객체의 목적은 완전히 다르다.시간이 지나면 두 객체는 완전히 다른 이유로 변경될 것이고, 따라서 두 객체를 어떤 식으로든 함께 묶는 행위는 공통 폐쇄 원칙과 단일 책임 원칙을 위배하게 된다.결론업무 규칙은 소프트웨어 시스템이 존재하는 이유다. 업무 규칙은 핵심적인 기능이다. 업무 규칙은 수익을 내고 비용을 줄이는 코드를 수반한다.업무 규칙은 UI나 DB와 같은 저수준의 관심사로 인해 오염되어서는 안 되며, 원래 그대로의 모습으로 남아 있어야 한다.업무 규칙을 표현하는 코드는 반드시 시스템의 심장부에 위치해야 하며, 덜 중요한 코드는 이 심장부에 플러그인 되어야 한다.업무 규칙은 시스템에서 가장 독립적이며 가장 많이 재사용할 수 있는 코드여야 한다." }, { "title": "클린 아키텍처 - 정책과 수준", "url": "/posts/clean_architecture_ch19/", "categories": "Study, Book", "tags": "clean architecture, architecture", "date": "2020-11-04 00:00:00 +0900", "snippet": "Table of Contents 수준 결론소프트웨어 시스템이란 정책을 기술한 것이다. 실제로 컴퓨터 프로그램의 핵심부는 이게 전부다.대다수의 주요 시스템에서 하나의 정책은 이 정책을 서술하는 여러 개의 조그만 정책들로 쪼갤 수 있다.소프트웨어 아키텍처를 개발하는 기술에는 이러한 정책을 신중하게 분리하고, 정책이 변경되는 양상에 따라 정책을 재편성하는 일도 포함된다.동일한 이유로 동일한 시점에 변경되는 정책은 동일한 수준에 위치하며, 동일한 컴포넌트에 속해야 한다.서로 다른 이유로, 혹은 다른 시점에 변경되는 정책은 다른 수준에 위치하며, 반드시 다른 컴포넌트로 분리해야 한다.흔히 아키텍처 개발은 재편성된 컴포넌트들을 비순환 방향 그래프로 구성하는 기술을 포함한다.그래프에서 정점은 동일한 수준의 정책을 포함하는 컴포넌트에 해당한다.방향이 있는 간선은 컴포넌트 사이의 의존성을 나타낸다.간선은 다른 수준에 위치한 컴포넌트를 서로 연결한다.이러한 의존성은 소스코드, 컴파일타임의 의존성이다.좋은 아키텍처라면 각 컴포넌트를 연결할 때 의존성의 방향이 컴포넌트의 수준을 기반으로 연결되도록 만들어야 한다. 즉, 저수준 컴포넌트가 고수준 컴포넌트에 의존하도록 설계되어야 한다.수준‘수준(level)’을 엄밀하게 정의하자면 ‘입력과 출력까지의 거리’다. 시스템의 입력과 출력 모두로부터 멀리 위치할수록 정책의 수준은 높아진다. 입력과 출력을 다루는 정책이라면 시스템에서 최하위 수준에 위치한다.번역 컴포넌트는 이 시스템에서 최고 수준의 컴포넌트이다. 입력과 출력에서 가장 멀리 떨어져 있기 때문이다.주목할 점은 데이터 흐름과 소스코드 의존성이 항상 같은 방향을 가리키지 않는다는 사실이다.아래와 같이 암호화 프로그램을 작성하면 잘못된 아키텍처이다. function encrypt() { while(true) writeChar(translate(readChar())); }고수준인 encrypt 함수가 저수준인 readChar와 writeChar 함수에 의존하기 때문이다.아래의 클래스 다이어그램은 이 시스템의 아키텍처를 개선해본 모습이다.주목할 점은 Encrypt 클래스, CharWriter와 CharReader 인터페이스를 둘러 싸고 있는 점선으로 된 경계다. 이 경계를 횡단하는 의존성은 모두 경계 안쪽으로 향한다. 이 경계로 묶인 영역이 이 시스템에서 최고 수준의 구성요소다.이 구조에서 고수준의 암호화 정책을 저수준의 입력/출력 정책으로부터 분리시킨 방식에 주목하자. 입력과 출력에 변화가 생기더라도 암호화 정책은 거의 영향을 받지 않기 때문이다.정책을 컴포넌트로 묶는 기준은 정책이 변경되는 방식에 달려있다는 사실을 상기하자. 단일 책임 원칙과 공통 폐쇄 원칙에 따르면 동일한 이유로 동일한 시점에 변경되는 정책은 함께 묶인다.이처럼 모든 소스코드 의존성의 방향이 고수준 정책을 향할 수 있도록 정책을 분리했다면 변경의 영향도를 줄일 수 있다.이 논의는 저수준 컴포넌트가 고수준 컴포넌트에 플러그인되어야 한다는 관점으로 바라볼 수도 있다.결론여기에서 설명한 정책에 대한 논의는 단일 책임 원칙, 개방 폐쇄 원칙, 공통 폐쇄 원칙, 의존성 역전 원칙, 안정된 의존성 원칙, 안정된 추상화 원칙을 모두 포함한다." }, { "title": "클린 아키텍처 - 경계 해부학", "url": "/posts/clean_architecture_ch18/", "categories": "Study, Book", "tags": "clean architecture, architecture, boundary", "date": "2020-11-03 00:00:00 +0900", "snippet": "Table of Contents 경계 횡단하기 두려운 단일체 배포형 컴포넌트 스레드 로컬 프로세스 서비스 결론시스템 아키텍처는 일련의 소프트웨어 컴포넌트와 그 컴포넌트들을 분리하는 경계에 의해 정의된다. 이러한 경계는 다양한 형태로 나타난다. 여기에서는 이러한 형ㅌ태 중에서 가장 흔한 몇 가지를 살펴보려고 한다.경계 횡단하기‘런타임에 경계를 횡단한다’ 함은 그저 경계 한쪽에 있는 기능에서 반대편 기능을 호출하여 데이터를 전달하는 일에 불과하다. 적절한 위치에서 경계를 횡단하는 비결은 소스코드 의존성 관리에 있다.왜 소스 코드일까? 왜냐하면 소스 코드 모듈 하나가 변경되면, 이에 의존하는 다른 소스코드 모듈도 변경하거나 다시 컴파일해야 할지도 모르기 때문이다.경계는 이러한 변경이 전파되는 것을 막는 방화벽을 구축하고 관리하는 수단으로써 존재한다.두려운 단일체아키텍처 경계 중에서 가장 단순하며 가장 흔한 형태는 물리적으로 엄격하게 구분되지 않는 형태다. 함수와 데이터가 단일 프로세서에서 같은 주소 공간을 공유하며 그저 나름의 규칙에 따라 분리되어 있을 뿐이다.이를 소스 수준 분리 모드라고 불렀다.배포 관점에서 보면 이는 소위 단일체 라고 불리는 단일 실행 파일에 지나지 않는다.그렇다고 해서 단일체에는 경계가 실제로 존재하지 않거나, 경계 자체가 무의미하다는 뜻은 아니다.가장 단순한 형태의 경계 횡단은 저수준 클라이언트에서 고수준 서비스로 향하는 함수 호출이다.이 경우 런타임 의존성과 컴파일타임 의존성은 모두 같은 방향, 즉 저수준 컴포넌트에서 고수준 컴포넌트로 향한다.고수준 클라이언트가 저수준 서비스를 호출해야 한다면 동적 다형성을 사용하여 제어흐름과는 반대 방향으로 의존성을 역전시킬 수 있다.이렇게 하면 런타임 의존성은 컴파일타임 의존성과는 반대가 된다.또한 데이터 구조의 정의가 호출하는 쪽에 위치한다는 점도 주목하자.정적 링크된 모노리틱 구조의 실행 파일이라도 이처럼 규칙적인 방식으로 구조를 분리하면 프로젝트를 개발, 테스트, 배포하는 작업에 큰 도움이 된다.고수준 컴포넌트는 저수준 세부사항으로부터 독립적으로 유지된다.배포형 컴포넌트아키텍처의 경계가 물리적으로 드러날 수도 있는데 그중 가장 단순한 형태는 동적 링크 라이브러리다.이는 배포 수준 결합 분리 모드에 해당한다. 배포 작업은 단순히 이들 배포 가능한 단위를 좀 더 편리한 형태로 묶는 일에 지나지 않는다.배포 과정만 차이가 날 뿐, 배포 수준의 컴포넌트는 단일체와 동일하다.스레드단일체와 배포형 컴포넌트는 모두 스레드를 활용할 수 있다. 스레드는 아키텍처 경계도 아니며 배포 단위도 아니다.이보다 스레드는 실행 계획과 순서를 체계화하는 방법에 가깝다. 모든 스레드가 단 하나의 컴포넌트에 포함될 수도 있고, 많은 컴포넌트에 걸쳐 분산될 수도 있다.로컬 프로세스로컬 프로세스를 일종의 최상위 컴포넌트라고 생각하자. 즉, 로컬 프로세스는 컴포넌트 간 의존성을 동적 다형성을 통해 관리하는 저수준 컴포넌트로 구성된다.로컬 프로세스 간 분리 전략은 단일체나 바이너리 컴포넌트의 경우와 동일하다.소스 코드 의존성의 화살표는 단일체나 바이너리 컴포넌트와 동일한 방향으로 경계를 횡단한다. 즉, 항상 고수준 컴포넌트를 향한다.저수준 프로세스가 고수준 프로세스의 플러그인이 되도록 만드는 것이 아키텍처 관점의 목표라는 사실을 기억하자.로컬 프로세스 경계를 지나는 통신에는 운영체제 호출, 데이터 마샬링 및 언마샬링, 프로세스 간 문맥 교환 등이 있으며, 이들은 제법 비싼 작업에 속한다.따라서 통신이 너무 빈번하게 이뤄지지 않도록 신중하게 제한해야 한다.서비스물리적인 형태를 띠는 가장 강력한 경계는 바로 서비스다. 서비스들은 모든 통신이 네트워크를 통해 이뤄진다고 가정한다.서비스 경계를 지나는 통신은 함수 호출에 비해 매우 느리다. 이 수준의 통신에서는 지연에 따른 문제를 고수준에서 처리할 수 있어야 한다.이를 제외하고는 로컬 프로세스에 적용한 규칙이 서비스에도 그대로 적용된다. 저수준 서비스는 반드시 고수준 서비스에 ‘플러그인’되어야 한다.고수준 서비스의 소스코드에는 저수준 서비스를 특정 짓는 어떤 물리적인 정보도 절대 포함해서는 안 된다.결론단일체를 제외한 대다수의 시스템은 한 가지 이상의 경계 전략을 사용한다.실제로 서비스는 상호작용하는 일련의 로컬 프로세스 퍼사드에 불과할 때가 많다.즉, 대체로 한 시스템 안에서도 통신이 빈번한 로컬 경계와 지연을 중요하게 고려해야 하는 경계가 혼합되어 있음을 의미한다." }, { "title": "클린 아키텍처 - 경계 선 긋기", "url": "/posts/clean_architecture_ch17/", "categories": "Study, Book", "tags": "clean architecture, architecture, boundary", "date": "2020-11-02 00:00:00 +0900", "snippet": "Table of Contents 어떻게 선을 그을까? 그리고 언제 그을까? 입력과 출력은? 플러그인 아키텍처 플러그인에 대한 논의 결론소프트웨어 아키텍처는 선을 긋는 기술이며, 이 선을 경계(boundary)라고 부른다.경계는 소프트웨어 요소를 서로 분리하고, 경계 한편에 있는 요소가 반대편에 있는 요소를 알지 못하도록 막는다.초기에 그어지는 선들은 가능한 오랫동안 결정을 연기시키기 위해, 그래서 이들 결정이 핵심적인 업무 로직을 오염시키지 못하게 만들려는 목적으로 쓰인다.아키텍트의 목표는 필요한 시스템을 만들고 유지하는 데 드는 인적 자원을 최소화하는 것이라는 사실을 상기하자.그렇다면 인적 자원의 효율을 떨어뜨리는 요인은 무엇일까?바로 결합(coupling)이다. 특히 너무 일찍 내려진 결정에 따른 결합이다.어떤 종류의 결정이 이른 결정일까?바로 시스템의 업무 요구사항, 즉 유스케이스와 아무런 관련이 없는 결정이다.좋은 아키텍처는 이러한 결정을 가능한 최후의 순간에 내릴 수 있게 해주며, 결정에 따른 영향이 크지 않게 만든다.어떻게 선을 그을까? 그리고 언제 그을까?관련이 있는 것과 없는 것 사이에 선을 긋는다.GUI는 업무 규칙과는 관련 없기 때문에 이 둘 사이에 선이 있어야 한다.데이터베이스와 GUI와는 관련 없으므로 선이 있어야 한다.데이터베이스와 업무 규칙과 관련이 없으므로 선이 있어야 한다.하지만, 데이터베이스는 업무 규칙과 서로 떼어놓을 수 없는 관계라고 배운 사람이 많다.하지만 잘못된 생각이다.데이터베이스는 업무 규칙이 간접적으로 사용할 수 있는 도구다.업무 규칙은 스키마, 쿼리 언어, 또는 데이터베이스와 관련된 나머지 세부사항에 대해 어떤 것도 알아서는 안 된다.업무 규칙이 알아야 할 것은 데이터를 가져오고 저장할 때 사용할 수 있는 함수 집합이 있다는 사실이 전부다.이러한 함수 집합을 통해서 우리는 데이터베이스를 인터페이스 뒤로 숨길 수 있다.입력과 출력은?입력과 출력은 중요하지 않다.인터페이스 뒤에는 인터페이스를 조작하는 모델이 존재한다.더 중요한 사실은 모델은 인터페이스를 전혀 필요로 하지 않는다는 점이다.중요한 것은 업무 규칙 이다.플러그인 아키텍처데이터베이스와 GUI에 대해 내린 두 가지 결정을 하나로 합쳐서 보면 컴포넌트 추가와 관련된 일종의 패턴이 만들어진다.이 패턴은 시스템에서 서드 파티 플러그인을 사용할 수 있게 한 바로 그 패턴과 동일하다.사실 소프트웨어 개발 기술의 역사는 플러그인을 손쉽게 생성하여, 확장 가능하며 유지보수가 쉬운 시스템 아키텍처를 확립할 수 있게 만드는 방법에 대한 이야기다.플러그인에 대한 논의시스템을 플러그인 아키텍처로 배치함으로써 변경이 전파될 수 없는 방화벽을 생성할 수 있다.GUI가 업무 규칙에 플러그인 형태로 연결되면 GUI에서 발생한 변경은 절대로 업무 규칙에 영향을 미칠 수 없다.경계는 변경의 축이 있는 지점에 그어진다.경계의 한쪽에 위치한 컴포넌트는 경계 반대편의 컴포넌트와는 다른 속도로 그리고 다른 이유로 변경된다.이 역시도 순전히 단일 책임 원칙에 해당한다.단일 책임 원칙은 어디에 경계를 그어야 할지를 알려준다.결론소프트웨어 아키텍처에서 경계선을 그리려면 먼저 시스템을 컴포넌트 단위로 분할해야 한다.컴포넌트 사이의 화살표가 특정 방향, 즉 핵심 업무를 향하도록 이들 컴포넌트의 소스를 배치한다.의존성 화살표는 저수준 세부사항에서 고수준의 추상화를 향하도록 배치한다." }, { "title": "Boost.Preprocessor Library", "url": "/posts/boost-preprocessor-library/", "categories": "", "tags": "boost, library, macro, preprocessor", "date": "2016-08-02 04:21:32 +0900", "snippet": "코드를 읽다가 Boost에서 제공하는 Preprocessor 라이브러리가 있다는 사실을 알게 되었다. Preprocessor 라이브러리를 사용하여 함수의 원형을 작성 하고 여러개의 함수 인자를 받을 수 있도록 전처리기가 함수를 생성하여 오버로딩을 하는 코드였다. 일단, Preprocessor 라이브러리의 메크로로 생성한 코드는 컴파일 전처리 단계에서 코드가 생성이 된다. 이로 인해서 컴파일 시간이 늘어날 수 있겠지만, 실행 단계에서의 부하는 일반 함수를 호출하는 것과 동일한 부하가 생긴다는 것을 알 수 있다. 일단 내가 보고 있는 코드에서 사용하는 메크로들에 대해서 정리해보고자 한다.BOOST_PP_CAT사용법은 BOOST_PP_CAT(a, b)와 같이 사용한다. 해당 메크로는 이름에서 느껴지듯 인자들을 연결 시킨다. 즉, 메크로가 모두 풀리면, ab와 같은 형태가 된다.실제 예제를 보자. (컴파일 시, -save-temps 옵션을 주면 전처리가 수행된 결과 코드를 확인할 수 있다.)// 예제코드(BOOST_PP_CAT)#include &amp;lt;boost/preprocessor.hpp&amp;gt;#define check BOOST_PP_CAT(x, BOOST_PP_CAT(y, z))int main(int argc, char* argv[]){ int check; return 0;}// 전처리 후, 코드int main(int argc, char* argv[]){ int xyz; // check 상수가 xyz로 변경 됨. return 0;}BOOST_PP_INC사용법은 BOOST_PP_INC(a)와 같이 사용한다. 해당 메크로는 인자의 값을 1 증가 시킨다.실제 예제를 보자.#include &amp;lt;iostream&amp;gt;#include &amp;lt;boost/preprocessor.hpp&amp;gt;using namespace std;int main(int argc, char* argv[]){ cout &amp;lt;&amp;lt; BOOST_PP_INC(1) &amp;lt;&amp;lt; endl &amp;lt;&amp;lt; BOOST_PP_INC(BOOST_PP_INC(5)) &amp;lt;&amp;lt; endl; return 0;}// 전처리 후, 코드int main(int argc, char* argv[]){ cout &amp;lt;&amp;lt; 2 &amp;lt;&amp;lt; endl &amp;lt;&amp;lt; 7 &amp;lt;&amp;lt; endl; return 0;}BOOST_PP_ENUM_PARAMS사용법은 BOOST_PP_ENUM_PARAMS(count, param)와 같이 사용한다. 해당 메크로는 쉼표로 구분되는 파라미터들을 생성해준다. param##0, param##1, param##2, … 과 같은 형태로 count – 1까지 생성이 된다. #include &amp;lt;boost/preprocessor.hpp&amp;gt;void myFunc(BOOST_PP_ENUM_PARAMS(3, int i)) { return;}int main(int argc, char* argv[]){ myFunc(1, 2, 3); return 0;}void myFunc( int i0 , int i1 , int i2) { // myFunc의 인자 값이 메크로가 펼쳐진 결과이다. return;}int main(int argc, char* argv[]){ myFunc(1, 2, 3); return 0;}BOOST_PP_ENUM_BINARY_PARAMS사용법은 BOOST_PP_ENUM_BINARY_PARAMS(count, p1, p2)와 같이 사용한다. 해당 메크로는 쉼표로 구분되는 두개의 파라미터 리스트를 생성한다. p1##0 p2##0, p1##1 p2##1, … 과 같은 형태로 count – 1까지 생성된다. #include &amp;lt;boost/preprocessor.hpp&amp;gt;template&amp;lt;BOOST_PP_ENUM_PARAMS(3, typename T)&amp;gt;void myFunc(BOOST_PP_ENUM_BINARY_PARAMS(3, T, t)) { return;}int main(int argc, char* argv[]){ myFunc(1, 2, 3); return 0;}template&amp;lt; typename T0 , typename T1 , typename T2&amp;gt;void myFunc( T0 t0 , T1 t1 , T2 t2) { // myFunc의 인자 값이 BOOST_PP_ENUM_BINARY_PARAMS 메크로의 결과 return;}int main(int argc, char* argv[]){ myFunc(1, 2, 3); return 0;}BOOST_PP_REPEAT_FROM_TO사용법은 BOOST_PP_REPEAT_FROM_TO(first, last, macro, data)와 같이 사용한다. 해당 메크로는 대상이 되는 메크로를 수평으로 반복하여 생성하는 메크로이다. 여기서 각 인자 값에 대해서 알아보자.first : 메크로의 반복의 시작 값last : (last – 1)안 반복의 긑 값macro : macro(z, n, data) 형태의 메크로의 이름을 나타내고, BOOST_PP_REPEAT_FROM_TO 메크로로 반복하여 생성될 메크로이다. n이 현재 반복 값, data는 다음에 나올 BOOST_PP_REPEAT_FROM_TO의 data 인자 값data : 생성될 메크로로 전달되는 보조 데이터#include &amp;lt;boost/preprocessor.hpp&amp;gt;using namespace std;#define DECL(z, n, text) BOOST_PP_CAT(text, n) = n;BOOST_PP_REPEAT_FROM_TO(5, 10, DECL, int x)#define TEMPLATE(Z, N, DATA) \\ template &amp;lt;BOOST_PP_ENUM_PARAMS(N, typename A)&amp;gt; \\ void myFunc( \\ BOOST_PP_ENUM_BINARY_PARAMS(N, A, a)) \\ { \\ cout &amp;lt;&amp;lt; a0 &amp;lt;&amp;lt; endl; \\ return; \\ }BOOST_PP_REPEAT_FROM_TO(1, 11, TEMPLATE, _)#undef TEMPLATEint main(int argc, char* argv[]){ myFunc(1, 2, 3); return 0;}using namespace std;// BOOST_PP_REPEAT_FROM_TO(5, 10, DECL, int x) 의 결과int x5 = 5; int x6 = 6; int x7 = 7; int x8 = 8; int x9 = 9;# 18 &quot;test_macro.cpp&quot;// BOOST_PP_REPEAT_FROM_TO(1, 11, TEMPLATE, _) 의 결과template &amp;lt; typename A0&amp;gt; void myFunc( A0 a0) { cout &amp;lt;&amp;lt; a0 &amp;lt;&amp;lt; endl; return; } template &amp;lt; typename A0 , typename A1&amp;gt; void myFunc( A0 a0 , A1 a1) { cout &amp;lt;&amp;lt; a0 &amp;lt;&amp;lt; endl; return; } template &amp;lt; typename A0 , typename A1 , typename A2&amp;gt; void myFunc( A0 a0 , A1 a1 , A2 a2) { cout &amp;lt;&amp;lt; a0 &amp;lt;&amp;lt; endl; return; } template &amp;lt; typename A0 , typename A1 , typename A2 , typename A3&amp;gt; void myFunc( A0 a0 , A1 a1 , A2 a2 , A3 a3) { cout &amp;lt;&amp;lt; a0 &amp;lt;&amp;lt; endl; return; } template &amp;lt; typename A0 , typename A1 , typename A2 , typename A3 , typename A4&amp;gt; void myFunc( A0 a0 , A1 a1 , A2 a2 , A3 a3 , A4 a4) { cout &amp;lt;&amp;lt; a0 &amp;lt;&amp;lt; endl; return; } template &amp;lt; typename A0 , typename A1 , typename A2 , typename A3 , typename A4 , typename A5&amp;gt; void myFunc( A0 a0 , A1 a1 , A2 a2 , A3 a3 , A4 a4 , A5 a5) { cout &amp;lt;&amp;lt; a0 &amp;lt;&amp;lt; endl; return; } template &amp;lt; typename A0 , typename A1 , typename A2 , typename A3 , typename A4 , typename A5 , typename A6&amp;gt; void myFunc( A0 a0 , A1 a1 , A2 a2 , A3 a3 , A4 a4 , A5 a5 , A6 a6) { cout &amp;lt;&amp;lt; a0 &amp;lt;&amp;lt; endl; return; } template &amp;lt; typename A0 , typename A1 , typename A2 , typename A3 , typename A4 , typename A5 , typename A6 , typename A7&amp;gt; void myFunc( A0 a0 , A1 a1 , A2 a2 , A3 a3 , A4 a4 , A5 a5 , A6 a6 , A7 a7) { cout &amp;lt;&amp;lt; a0 &amp;lt;&amp;lt; endl; return; } template &amp;lt; typename A0 , typename A1 , typename A2 , typename A3 , typename A4 , typename A5 , typename A6 , typename A7 , typename A8&amp;gt; void myFunc( A0 a0 , A1 a1 , A2 a2 , A3 a3 , A4 a4 , A5 a5 , A6 a6 , A7 a7 , A8 a8) { cout &amp;lt;&amp;lt; a0 &amp;lt;&amp;lt; endl; return; } template &amp;lt; typename A0 , typename A1 , typename A2 , typename A3 , typename A4 , typename A5 , typename A6 , typename A7 , typename A8 , typename A9&amp;gt; void myFunc( A0 a0 , A1 a1 , A2 a2 , A3 a3 , A4 a4 , A5 a5 , A6 a6 , A7 a7 , A8 a8 , A9 a9) { cout &amp;lt;&amp;lt; a0 &amp;lt;&amp;lt; endl; return; }int main(int argc, char* argv[]){ myFunc(1, 2, 3); return 0;}지금까지 Boost의 Preprocessor 라이브러리의 메크로 몇 가지를 확인해봤다. 직접 전처리기가 생성하는 코드도 확인해보면서 매크로의 결과를 직접 확인했다.위와 같이 인자 값만 다르고 다른 부분이 모두 동일한 경우에 위와 같은 메크로들을 사용하여 중복 없이 여러 함수들을 전처리기를 통해서 생성할 수 있다. 매우 편리한 기능이다.만약 인자 값만 다양하게 생성하고 싶다면, 위에서 살펴본 메크로 보다는 variadic template을 사용하는 방법이 더 직관적이면서 코드량도 줄어든다.하지만, 내가 본 코드의 경우 Boost Preprocessor 라이브러리를 통하여 구현을 하였는데, 이유가 일단 C++ 11 이후에서 지원한다는 점이다. 추가적으로 variadic template과 lambda를 함께 사용할 수 없었던 버그 때문이였다. 현재는 해당 버그는 해결이 된 상황이다.여튼 boost에서 전처리기를 위한 라이브러리를 따로 제공하고 있다는 점이 흥미로웠다." }, { "title": "Overloading Typecasts", "url": "/posts/overloading-typecasts/", "categories": "", "tags": "c++, operator overloading, type casting, 형 변환", "date": "2016-07-31 10:04:45 +0900", "snippet": "C++은 기본 타입에 대한 형 변환을 어떻게 수행할지 알고 있다. 하지만 사용자 정의 클래스는 어떻게 형 변환을 수행할지 알지 못 한다. 아래의 클래스를 살펴보자.class Cent {private: int m_cents;public: Cent(int cents = 0) : m_cents(cents) {} int get_cents() { return m_cents; } void set_cents(int cents) { m_cents = cents; }};Cent 클래스는 m_cents라는 int 형을 가지고 있고, 접근 연산자를 가지고 있다. 또한 int 형을 어떻게 Cent 클래스로 변환할지 알 수 있는 생성자를 가지고 있다.즉, int 형에서 Cent 형으로 변환이 가능하다. 그렇다면, Cent 형에서 int 형으로 변환할 수 있을까? 어떤 경우에는 안 되지만, 아래와 같이 변환이 가능하다.void print_ints(int value) { std::cout &amp;lt;&amp;lt; &quot;print_ints : &quot; &amp;lt;&amp;lt; value &amp;lt;&amp;lt; std::endl;}int main(){ Cent cents(7); print_int(cents.getCents()); // print 7 return 0;}다음과 같이 접근 연산자를 통해서 가능하다. 하지만, 더 간단하게 암시적 타입 변환 혹은 기본 연산자와 같이 형 변환을 수행할 수 없을까?class Cent {private: int m_cents;public: Cent(int cents = 0) : m_cents(cents) {} // Overloaded int cast operator int() { return m_cents; } int get_cents() { return m_cents; } void set_cents(int cents) { m_cents = cents; }};위와 같이 우리는 operator int() 함수를 통해서 Cent 클래스를 int 형으로 형 변환이 가능하다.Overloading Typecast int 형 변환을 위해서 operator int() 함수를 오버로딩 한다. 여기에서 operator 다음 공백을 주고 변환할 형을 지정한다. 형 변환 연산자는 반환값을 지정하지 않는다. 대신 C++ 컴파일러는 사용자가 정확한 형을 반환한다고 가정한다.int main(){ Cent cents(7); print_ints(cents); return 0;}컴파일러는 print_ints 함수가 int 형을 받는 것을 알고 있다. 하지만, cents 변수는 int 형이 아닌 Cent 클래스이다. 결국 컴파일러는 Cent 클래스가 int 형으로 변환할 방법을 제공하는지 확인하는데, 해당 방법이 operator int() 함수이다. 컴파일러는 operator int() 함수를 통해 print_ints 함수에 cents 변수를 int 형으로 변환하여 전달하게 된다.이번에는 명시적 형 변환을 확인해보자. 이미 형 변환 방법은 제공했고, 기본 타입의 형 변환과 동일하게 수행할 수 있다.아래 코드를 보자.Cent cents(7);int iCent = static_cast&amp;lt;int&amp;gt;(cents);이와 같은 방법으로 사용자 정의 클래스를 기본 타입과 같이 형 변환을 할 수 있다. 위는 클래스에서 기본 타입에 대한 형 변환을 확인해 봤다. 또한 기본 타입이 아닌 사용자 정의 클래스 간의 형 변환에서도 사용할 수 있다." }, { "title": "EFFICIENT C++_단일 쓰레드 메모리 풀링", "url": "/posts/efficient-ceb8ba8ec9dbc-ec93b0eba088eb93/", "categories": "", "tags": "c++, Efficient C++, Memory, Performance, Pool, Single Thread", "date": "2016-07-18 09:49:54 +0900", "snippet": "메모리를 자주 할당하고 해지하는 것은 응용프로그램 성능을 저하시키는 주요한 요소이다. 성능 저하는 기본 메모리 관리자가 일반적인 목적을 가지고 있기 때문에 발생한다. 특화된 메모리 관리자를 개발하여 이러한 사항을 극복할 수 있다. 이러한 메모리 관리자를 개발하고자 할때, 메모리의 크기와 동시성이라는 문제를 생각해야 한다.메모리 크기는 다음 2가지를 생각할 수 있다. 고정 크기 – 고정 크기의 메모리 블록을 할당 가변 크기 – 다양한 크기의 메모리 블록을 할당동시성에서도 2가지를 생각할 수 있다. 단일 쓰레드 – 하나의 쓰레드가 메모리 관리자를 사용 멀티 쓰레드 – 여러 쓰레드가 메모리 관리자를 사용이렇게 메모리 관리자는 4버전으로 만들 수 있다. 이번에는 단일 쓰레드 차원에서 메모리 관리자간의 성능을 확인해 보자.버전 0: 전역 new()와 delete()기본 메모리 관리자는 일반적인 역활을 수행한다. 기본 메모리 관리자는 전역 new()와 delete()를 호출할 때 사용이 된다. 기본 메모리 관리자는 멀티쓰레드 환경에서 작동할 수 있다. 더불어 메모리 크기는 요청이 발생할 때마다 변할 수 있다. 이러한 유연성은 속도와 절충된다.클라이언트 코드가 전역 new()와 delete()의 전 기능이 필요하지 않는 경우가 있다. 이런 경우, 해당 함수의 전 기능을 사용하는것은 CPU 주기 낭비이다.아래는 전역 new와 delete를 사용한 코드이다. class Rational { public: Rational(int a = 0, int b = 0) : n(a), d(b) { } private: int n; // 분자 int d; // 분모 };Rational 클래스를 사용하여 전역 new(), delete()의 성능을 측정해보자. TEST(Chapter6, Normal_NEW_DELETE) { Rational *array[1000]; for (int j = 0; j &amp;lt; 5000; j++) { for (int i = 0; i &amp;lt; 1000; i++) { array[i] = new Rational(i); } for (int i = 0; i &amp;lt; 1000; i++) { delete array[i]; } }}성능은 gtest에서 해당 테스트의 걸린 시간으로 측정했다. 약 2600 millisecond로 측정이 됐다.버전 1: Rational에 특화된 메모리 관리자기본 메모리 관리자를 너무 자주 호출하는 것을 방지하기 위해서 Rational 클래스는 미리 할당된 Rational 객체들의 정적 연결 리스트로 유지한다.  새로운 Rational 객체가 필요하면, 해당 리스트에서 하나를 가져온다. 사용이 끝나면 이후에 사용할 수 있도록 이것을 리스트로 반환한다.  class NextOnFreeList { public: NextOnFreeList *next; }; class RationalVer1 { private: static void expandTheFreeList(); public: RationalVer1(int a = 0, int b = 0) : n(a), d(b) { } inline void *operator new(size_t size); inline void operator delete(void *doomed, size_t size); static void newMemPool() { expandTheFreeList(); } static void deleteMemPool(); private: static NextOnFreeList *freeList; enum { EXPASION_SIZE = 32 }; int n; // 분자 int d; // 분모 }; inline void* RationalVer1::operator new(size_t size) { if (0 == freeList) { expandTheFreeList(); } NextOnFreeList *head = freeList; freeList = head-&amp;gt;next; return head; } inline void RationalVer1::operator delete(void *doomed, size_t size) { NextOnFreeList *head = static_cast&amp;lt;NextOnFreeList*&amp;gt;(doomed); head-&amp;gt;next = freeList; freeList = head; } NextOnFreeList *RationalVer1::freeList = NULL; void RationalVer1::expandTheFreeList() { size_t size = (sizeof(RationalVer1) &amp;gt; sizeof(NextOnFreeList *)) ? sizeof(RationalVer1) : sizeof(NextOnFreeList *); NextOnFreeList *runner = (NextOnFreeList *)new char[size]; freeList = runner; for (int i = 0; i &amp;lt; EXPASION_SIZE; i++) { runner-&amp;gt;next = (NextOnFreeList *)new char[size]; runner = runner-&amp;gt;next; } runner-&amp;gt;next = 0; } void RationalVer1::deleteMemPool() { NextOnFreeList *nextPtr; for (nextPtr = freeList; nextPtr != NULL; nextPtr = freeList) { freeList = freeList-&amp;gt;next; delete [] nextPtr; } }한번에 한 블록씩 할당 받지만 미리 받은 메모리 블록은 재활용한다는 점에서 버전 0과는 다른 점이다.TEST(Chapter6, VER1_NEW_DELETE) { RationalVer1*array[1000]; Rational::newMemPool(); for (int j = 0; j &amp;lt; 5000; j++) { for (int i = 0; i &amp;lt; 1000; i++) { array[i] = new RationalVer1(i); } for (int i = 0; i &amp;lt; 1000; i++) { delete array[i]; } } Rational::deleteMemPool();}이번 버전1의 경우 약 100 millisecond가 걸렸다. 기본 메모리 관리자에 비해서 약 26배 정도 속도 차이가 나는 것을 확인할 수 있다.버전 2: 고정 크기 객체 메모리 풀이번에는 템플릿을 이용하여 관리하고자 하는 다양한 클래스를 관리할 수 있도록 작성할 것이다. template&amp;lt;class T&amp;gt; class MemoryPool { public: MemoryPool(size_t size = EXPANSION_SIZE); ~MemoryPool(); inline void *alloc(size_t size); inline void free(void *someElement); private: MemoryPool&amp;lt;T&amp;gt; *next; enum { EXPANSION_SIZE = 32 }; void expandTheFreeList(int howMany = EXPANSION_SIZE); }; template &amp;lt;class T&amp;gt; inline void* MemoryPool&amp;lt;T&amp;gt;::alloc(size_t) { if (!next) { expandTheFreeList(); } MemoryPool&amp;lt;T&amp;gt; *head = next; next = head-&amp;gt;next; return head; } template &amp;lt;class T&amp;gt; inline void MemoryPool&amp;lt;T&amp;gt;::free(void *doomed) { MemoryPool&amp;lt;T&amp;gt; *head = static_cast&amp;lt;MemoryPool&amp;lt;T&amp;gt; *&amp;gt;(doomed); head-&amp;gt;next = next; next = head; } template &amp;lt;class T&amp;gt; void MemoryPool&amp;lt;T&amp;gt;::expandTheFreeList(int howMany) { size_t size = (sizeof(T) &amp;gt; sizeof(MemoryPool&amp;lt;T&amp;gt; *)) ? sizeof(T) : sizeof(MemoryPool&amp;lt;T&amp;gt; *); MemoryPool&amp;lt;T&amp;gt; *runner = (MemoryPool&amp;lt;T&amp;gt; *)new char[size]; next = runner; for (int i = 0; i &amp;lt; howMany; i++) { runner-&amp;gt;next = (MemoryPool&amp;lt;T&amp;gt; *)new char[size]; runner = runner-&amp;gt;next; } runner-&amp;gt;next = 0; } template &amp;lt;class T &amp;gt; MemoryPool&amp;lt;T&amp;gt;::MemoryPool(size_t size) { expandTheFreeList(size); } template &amp;lt;class T&amp;gt; MemoryPool&amp;lt;T&amp;gt;::~MemoryPool() { MemoryPool&amp;lt;T&amp;gt; *nextPtr = next; for (; nextPtr != NULL; nextPtr = next) { next = next-&amp;gt;next; delete [] nextPtr; } } class NextOnFreeList { public: NextOnFreeList *next; }; class RationalVer1 { private: static void expendTheFreeList(); public: RationalVer1(int a = 0, int b = 0) : n(a), d(b) { } inline void *operator new(size_t size); inline void operator delete(void *doomed, size_t size); static void newMemPool() { expendTheFreeList(); } static void deleteMemPool(); private: static NextOnFreeList *freeList; enum { EXPASION_SIZE = 32 }; int n; // 분자 int d; // 분모 }; inline void* RationalVer1::operator new(size_t size) { if (0 == freeList) { expendTheFreeList(); } NextOnFreeList *head = freeList; freeList = head-&amp;gt;next; return head; } inline void RationalVer1::operator delete(void *doomed, size_t size) { NextOnFreeList *head = static_cast&amp;lt;NextOnFreeList*&amp;gt;(doomed); head-&amp;gt;next = freeList; freeList = head; } NextOnFreeList *RationalVer1::freeList = NULL; void RationalVer1::expendTheFreeList() { size_t size = (sizeof(RationalVer1) &amp;gt; sizeof(NextOnFreeList *)) ? sizeof(RationalVer1) : sizeof(NextOnFreeList *); NextOnFreeList *runner = (NextOnFreeList *)new char[size]; freeList = runner; for (int i = 0; i &amp;lt; EXPASION_SIZE; i++) { runner-&amp;gt;next = (NextOnFreeList *)new char[size]; runner = runner-&amp;gt;next; } runner-&amp;gt;next = 0; } void RationalVer1::deleteMemPool() { NextOnFreeList *nextPtr; for (nextPtr = freeList; nextPtr != NULL; nextPtr = freeList) { freeList = freeList-&amp;gt;next; delete [] nextPtr; } }테스트 코드는 이전과 유사하다.TEST(Chapter6, VER2_NEW_DELETE) { RationalVer2* array[1000]; Rational::newMemPool(); for (int j = 0; j &amp;lt; 5000; j++) { for (int i = 0; i &amp;lt; 1000; i++) { array[i] = new RationalVer2(i); } for (int i = 0; i &amp;lt; 1000; i++) { delete array[i]; } } Rational::deleteMemPool();}이번에 만든 메모리 풀 템플릿 버전의 수행시간은 139 millisecond가 걸렸다. 약간이지만 버전 1에 비해서 느린것을 알 수 있다.버전 3: 단일 쓰레드 가변 크기 메모리 관리자가변 크기의 메모리를 필요로하는 응용프로그램들이 있는데, 그 중에 하나가 웹 서버이다. 웹 서버는 문자열 처리를 굉장히 많이 한다. 이로 인해서 가변 크기의 메모리 관리자가 필요로 하는데, 이번에 살펴보도록 하자. class MemoryChunk { public: MemoryChunk(MemoryChunk *nextChunk = NULL, size_t chunkSize = DEFAULT_CHUNK_SIZE); ~MemoryChunk() { delete mem; } inline void *alloc(size_t size); inline void free(void* someElement); MemoryChunk *nextMemChunk() { return next; } size_t spaceAvailable() { return chunkSize - bytesAlreadyAllocated; } enum { DEFAULT_CHUNK_SIZE = 4096 }; private: MemoryChunk *next; void *mem; // 단일 메모리 청크 크기 size_t chunkSize; // 현재 메모리 청크에 할당된 바이트 수 size_t bytesAlreadyAllocated; }; inline void* MemoryChunk::alloc(size_t requestSize) { void *addr = (void*)((size_t)(mem) + bytesAlreadyAllocated); bytesAlreadyAllocated += requestSize; return addr; } inline void MemoryChunk::free(void *someElement) { // 할당한 메모리를 재활용하지 않기 때문 } MemoryChunk::MemoryChunk(MemoryChunk *nextChunk, size_t reqSize) { chunkSize = (reqSize &amp;gt; DEFAULT_CHUNK_SIZE) ? reqSize : DEFAULT_CHUNK_SIZE; next = nextChunk; bytesAlreadyAllocated = 0; mem = new char[chunkSize]; } class ByteMemoryPool { public: ByteMemoryPool(size_t initSize = MemoryChunk::DEFAULT_CHUNK_SIZE); ~ByteMemoryPool(); inline void *alloc(size_t requestSize); inline void free(void* someElement); private: MemoryChunk *listOfMemoryChunks; void expandStorage(size_t reqSize); }; inline void* ByteMemoryPool::alloc(size_t requestSize) { size_t space = listOfMemoryChunks-&amp;gt;spaceAvailable(); if (space &amp;lt; requestSize) { expandStorage(requestSize); } return listOfMemoryChunks-&amp;gt;alloc(requestSize); } inline void ByteMemoryPool::free(void *doomed) { listOfMemoryChunks-&amp;gt;free(doomed); } ByteMemoryPool::ByteMemoryPool(size_t initSize) { expandStorage(initSize); } ByteMemoryPool::~ByteMemoryPool() { MemoryChunk *memChunk = listOfMemoryChunks; while(memChunk != NULL) { listOfMemoryChunks = memChunk-&amp;gt;nextMemChunk(); delete memChunk; memChunk = listOfMemoryChunks; } } void ByteMemoryPool::expandStorage(size_t reqSize) { listOfMemoryChunks = new MemoryChunk(listOfMemoryChunks, reqSize); } class RationalVer3 { public: RationalVer3(int a = 0, int b = 1) : n(a), d(b) { } ~RationalVer3() { } void *operator new(size_t size) { return memPool-&amp;gt;alloc(size); } void operator delete(void *doomed, size_t size) { memPool-&amp;gt;free(doomed); } static void newMemPool() { memPool = new ByteMemoryPool; } static void deleteMemPool() { delete memPool; } private: int n; int d; static ByteMemoryPool *memPool; }; ByteMemoryPool *RationalVer3::memPool = NULL;이번 버전의 경우 176 millisecond가 걸렸다. 키 포인트 메모리 관리의 강력함과 유연성은 성능에 영향을 준다. 전역 메모리 관리자는 일반적 목적을 가지고 구현, 성능에는 안 좋다. 고정된 크기의 메모리 블록을 주로 할당하면, 특화된 고정 크기 메모리 관리자가 성능에 좋다. 단일 쓰레드와 한정된 메모리 블록을 주로 할당하면 위와 같이 성능 개선이 가능." }, { "title": "EFFICIENT C++_임시 객체", "url": "/posts/efficient-cec9e84ec8b9c-eab09decb2b4/", "categories": "", "tags": "c++, Efficient C++, Performance, temporary, Temporary object", "date": "2016-07-16 08:52:44 +0900", "snippet": "임시 객체 생성은 성능적으로 작은 영향을 주는 부분은 아니다. 즉, 임시 객체의 기원, 그것의 비용 그리고 임시 객체를 제거할 수 있는 방법을 알지 않고서는 효율적인 코드를 작성하기 힘들다.임시 객체는 소스 코드에 존재하지 않고 컴파일러가 조용히 객체를 만들어 낸다. 컴파일러가 어떤 코드에서 임시 객체를 만들어 내는지 찾아내려면 숙련된 관찰력이 필요하다.이번에는 컴파일러가 어떤 경우에 임시 객체를 생성하는지 확인해보자.객체 정의class Rational { friend Rational operator+(const Rational&amp;amp;, const Rational&amp;amp;);public: Rational(int a = 0, int b = 1) : m(a), n(b) { printf(&quot;Rational&quot;); }private: int m; int n;}; Rational r1(100); // 1 Rational r2 = 100; // 2 Rational r3 = Rational(100); // 3컴파일러 구현과 무관하게 Rational r(100) 구문만이 임시 객체를 생성하지 않는다고 보장할 수 있다.만약 2, 3의 형태를 사용한다면 컴파일러 구현에 따라 임시 객체를 생성할지도 모른다. 3의 형태를 사용한다고 하면  컴파일러가 이 형태를 만나면 Rational::Rational(int, int) 생성자를 사용하여 정수 100을 가지고 Rational 형식의 임시 객체를 생성한다. 그런 다음 복사 생성자를 사용해 임시 객체로부터 r3을 초기화한다.의사 코드로 작성하면 아래와 같다.{ Rational r3; Rational _temp; _temp.Rational::Rational(100,1); // Construct the temporary r3.Rational::Rational(_temp); // Copy-construct r3 _temp.Rational::~Rational(); // Destroy the temporary ...}실제로는 대부분의 컴파일러는 최적화를 통해서 임시 객체를 없애기 때문에, 3가지 형태 모두 임시 객체가 생성되지 않았다.형식 불일치형식 불일치의 일반적인 경우에는 형식 X의 객체가 필요할 때마다 어떤 다른 형식이 제공되는 것이다. 컴파일러는 이때 제공된 형식을 형식 X의 객체로 변환한다. 이 과정에서 임시객체는 생겨난다.{ Rational r; r = 100; ... }위의 Rational 클래스는 정수 매개 변수를 받는 대입 연산자를 선언하지 않았다. 기본적으로 생성되는 대입 연산자로 Rational은 우변에 Rational 객체를 기대한다. 위에서 정의한 생정자가 정수 매개 변수를 처리하는 방법을 알고 있다. 결과적으로 처리되는 순서를 의사 코드로 표현하면 아래와 같다.Rational _temp; // Place holder for temporary_temp.Rational::Rational(100,1); // Construct temporaryr.Rational::operator=(_temp); // Assign temporary to rtemp.Rational::~Rational(); // Destroy the temporary위와 같이 컴파일러가 중간에 임시 객체를 생성을 하고 r객체에 해당 값을 할당한다. 이러한 부분은 프로그래밍에는 편리하지만 불필요한 객체가 생성되고 소멸되는 과정이 임의적으로 생성된 것이다. 성능 관점에서는 좋지 않다.이런 임의의 변환을 컴파일러가 수행하지 못 하도록 제한할 수 있다. 생성자에 explicit 키워드를 사용하면 된다. 이는 개발자가 명시적으로 생성자를 사용하지 않는다면 컴파일러가 임의로 사용할 수 없도록 제한하는 것이다.또 다른 방법으로는 operator=() 함수를 오버로드하여 이 형식의 임시 객체를 제거할 수 있다.class Rational {public: ... // as before Rational&amp;amp; operator=(int a) {m=a; n=1; return *this; } };그리고, 해당 책에서 형식 불일치 임시 객체 생성을 해결할 수 있는 방법을 제시하고 있다. 다음 예제를 보자. Complex a, b; for (int i = 0; i &amp;lt; 100; i++) { a = b + 1.0; }a = b + 1.0 구문이 반복문으로 실행될 때 마다 계속해서 임시 객체가 생성된다. 즉 100회의 추가적인 임시객체가 생성된다. 이 경우 생성되는 임시객체를 제거해 보자. Complex a, b, one(1.0); for (int i = 0; i &amp;lt; 3; i++) { a = b + one; }처음의 1.0 상수 값을 Complex를 one이라는 객체로 변경했고, 그로인해서 1.0이 Complex 임시 객체가 생성되는 것을 방지했다.값으로 전달객체를 값으로 전달할 때,  다음과 같이 형식 매개변수를 실제 매개변수로 초기화 한다.T formalArg = actualArg;void g(T formalArg) { ...}T t;g(t);다음과 같이 g 함수가 존재하고 g를 위와 같이 호출을 했다. 이런 경우 컴파일러는 형식 T의 임시 객체를 생성한 다음 t를 입력 인자로 사용한다. 의사 코드로 표현하면 다음과 같다.T _temp;_temp.T::T(t); // copy construct _temp from tg(_temp); // pass _temp by reference_temp.T::~T(); // Destroy _temp임시 객체를 생성하고 소멸하는 과정은 부담이 간다. 가능하면 객체는 포인터나 참조로 전달하여 임시 객체 생성을 방지하는 것이 좋다.값으로 반환임시 객체가 생성될 수 있는 또 하나의 경우는 함수가 값을 반환할 때이다.다음 예제를 통해서 확인해보자.string f() { string s; ... // Compute &quot;s&quot; return s;}String p;...p = f();f()의 반환 값은 string 형식의 객체이다. 결과적으로 반환 값을 저장하기 위해서 임시 객체가 생성된다. 위의 예제를 보면 f()의 반환 값은 임시 객체로 전달 되고 좌변 객체로 대입된다. 좀 더 자세한 예제로 string operator+를 가지고 확인해보자. 아래는 string operator+ 연산자의 직관적 해석으로 구현한 것이다.string operator+(const string&amp;amp; lhs, const string&amp;amp; rhs){ char *buffer = new char[lhs.length() + rhs.length() + 1]; strcpy(buffer, lhs.c_str()); strcat(buffer, rhs.c_str()); string result(buffer); delete buffer; return result;}다음 코드는 string operator+를 사용하는 예제이다. string s1 = &quot;Hello&quot;; string s2 = &quot;World&quot;; string s3; s3 = s1 + s2;위에서 s3 = s1 + s2 구문은 아래와 같은 연산을 포함하고 있다. operator+(const string&amp;amp;, const string&amp;amp;);  string 생성자가 opertor+ 연산자내에서 string result(buffer)를 실행 operator+()의 반환 값을 저장하기 위해 임시 객체가 필요, 복사 생성자를 이용해서 operator+의 결과 string을 복사하여 임시 객체 생성 operator+() 함수가 종료하기 전에 지역 범위 객체인 result 객체가 소멸 대입 연산자를 사용하여 operator+가 생성한 임시 객체를 좌변 s3에 대입한다. 반환 값을 저장하기 위해서 사용한 임시 객체가 소멸이렇게 s3 = s1 + s2 하나의 구문을 수행하기 위해서 6개의 연산이 수행된다. 앞에서 이야기 했던 RVO가 적용되면 result 객체를 제거하여 생성자 소멸자를 수행하지 않을 수 있다.그렇다면 임시 객체도 제거할 수 있을까? 임시 객체를 제거하면 두 가지의 함수 호출을 더 제거할 수 있다.s3 = s1 + s2 구문에서 왜 임시 객체를 생성할까? 이유는 우리에게 string s3의 이전 내용을 지우고 s1 + s2의 내용으로 덮어쓸 수 있는 자유가 없기 때문이다. 대입 연산자는 string s3의 이전 내용을 새 내용으로 덮어쓰는 역활을 한다. 컴파일러는 operator=을 수행하지 않을 권한이 없기 때문에 임시 객체는 필수이다.그렇다면 s3이 이전 내용을 가지지 않은 완전 새로운 객체라면 어떠할까? 이 경우 결과가 직접 복사 생성 되므로 임시 객체가 필요 없게 된다.{ string s1 = &quot;Hello&quot;; string s2 = &quot;World&quot;; string s3 = s1 + s2; // No temporary here. ... }{ string s1 = &quot;Hello&quot;; string s2 = &quot;World&quot;; string s3; s3 = s1 + s2; // Temporary generated here. ... }위의 형태가 임시 객체가 생성되지 않아 아래의 형태보다 좋다.op=()를 사용해 임시 객체 제거{ string s1,s2,s3; ... s3 = s1 + s2; ...}아까 이야기 했던 방법을 이용하면 위와 같은 상황도 임시 객체를 제거할 수 있다.operator+ 대신에 operator+=를 사용하면 된다. s3 = s1 + s2; // Temporary generated here를 다음과 같이 수정하면 된다.s3 = s1; // operator=(). No temporary.s3 += s2; // operator+=(). No temporary.두 코드는 논리적으로 동일하지만 전자는 임시 객체를 생성하지만 후자는 생성하지 않는다. 즉, 후자가 더 효율적인 코드이다.키 포인트 임시 객체는 생성자와 소멸자 실행으로 성능 부하가 생긴다. 생성자에 explicit 키워드를 사용하면 컴파일러가 해당 생성자를 사용해 형식 변환을 할 수 없다. 컴파일러는 형식 불일치를 해결하기 위해서 임시 객체를 생성 가능하면 객체 복사를 방지하고 참조나 포인터로 전달하고 반환하자. op=연산자를 사용해 임시 객체를 제거할 수 있다. op는 +, -, *, /이 될 수 있다." }, { "title": "EFFICIENT C++_반환값 최적화", "url": "/posts/efficient-cebb098ed9998eab092-ecb59ceca0/", "categories": "", "tags": "c++, Efficient C++, Performance, Return Value Optimization, RVO", "date": "2016-07-15 04:05:16 +0900", "snippet": "앞에서 불필요한 객체의 생성과 소멸을 제거할 때 마다 성능이 좋아지는 것을 보았다. 이번에는 속도를 위해서 컴파일러가 수행하는 Return Value Optimization을 살펴 보겠다.값으로 반환의 동작 원리아래는 Complex 클래스로 복소수를 표현하고 있다.class Complex { friend Complex operator+(const Complex&amp;amp;, const Complex&amp;amp;);public: Complex(double r = 0.0, double i = 0.0) : real(r), imag(i) {} Complex(const Complex&amp;amp; c) : real(c.real), imag(c.imag) {} Complex&amp;amp;operator=(const Complex&amp;amp; c); ~Complex() {}private: double real; double imag;};더하기 연산자는 Complex 객체를 값으로 반환한다.Complex operator+(const Complex&amp;amp; lhs, const Complex&amp;amp; rhs){ Complex retVal; retVal.real = lhs.real + rhs.real; retVal.imag = lhs.imag + rhs.imag; return retVal;}다음과 같은 연산을 수행한다. Complex c1(1, 1), c2(2, 2), c3; c3 = c1 + c2;c1 + c2의 값을 어떻게 c3로 대입할 수 있을까? 컴파일러가 사용하는 유명한 방법은 임시 __tempResult 객체를 생성하여 Complex::operator+()의 첫 번째 인자로 전달하는 것이다. 이때 이 임시 객체는 참조로 전달된다. 그래서 컴파일러는 위의 operator+ 함수를 아래와 같이 변경한다.void Complex_Add(Complex&amp;amp; __tempResult, const Complex&amp;amp; lhs, const Complex&amp;amp; rhs){…}c3 = c1 + c2;위의 원래 소스 구문은 아래와 같은 의사 코드로 변환된다.struct Complex __tempResult;Complex_Add(__tempResult, c1, c2);c3 = __tempResult;값으로 반환 구현은 지역객체 retVal(oeprator+ 함수 안에 있는)을 없애고, 반환 값을 __tempResult 임시 객체로 직접 계산하는 형태로 최적화할 수 있다. 이것이 반환 값 최적화이다.반환 값 최적화(RVO)어떠한 최적화도 없다면 Complex_Add()에 대해서 컴파일러가 생성한 의사 코드는 다음과 같다.void Complex_Add(Complex&amp;amp; __tempResult, const Complex&amp;amp; lhs, const Complex&amp;amp; rhs){ struct Complex retVal; retVal.Complex::Complex(); // Construct retVal retVal.real = lhs.real + rhs.real; retVal.imag = lhs.imag + rhs.imag; __tempResult.Complex::Complex(retVal); // Copy-Construct __tempResult retVal.Complex::~Complex(); // Destroy retVal return;}컴파일러는 지역 객체 retVal을 없애고, 이것을 __tempResult로 교체하여 Complex_Add()를 최적화할 수 있다. 이것이 반환 값 최적화이다. 아래는 최적화한 의사 코드이다.void Complex_Add(Complex&amp;amp; __tempResult, const Complex&amp;amp; lhs, const Complex&amp;amp; rhs){ __tempResult.Complex::Complex(); __tempResult.real = lhs.real + rhs.real; __tempResult.imag = lhs.imag + rhs.imag; return;}operator+ 함수를 이용해서 RVO가 적용된 버전과 적용되지 않은 버전의 성능을 비교해 보자.측정 코드는 아래와 같다.TEST(Chapter4, Check_Baisc_Complex_Operator_Plus){ Complex a(1.0), b(2.0), c; struct timeval start, end, running; gettimeofday(&amp;amp;start, NULL); for (int i = 0; i &amp;lt; 90000000; i++) { // 수행 명령 } gettimeofday(&amp;amp;end, NULL); if (end.tv_usec &amp;lt;= start.tv_usec) { end.tv_sec--; end.tv_usec += 1000000; } running.tv_usec=end.tv_usec-start.tv_usec; running.tv_sec=end.tv_sec-start.tv_sec; printf(&quot;Running Time : %d.%06d\\n&quot;, running.tv_sec, running.tv_usec);}위의 측정 코드를 통해서 앞에서 이야기 했던 반환 값 최적화 의사 코드와 최적화 하지 않은 일반 의사 코드의 성능을 측정해 보면 아래와 같다.최적화가 없는 경우 : 약 1.7초최적화가 된 경우 : 약 0.5초반환 값 최적화가 진행된 경우가 약 3배 정도 더 빠르다는 것을 알 수 있다.의사코드가 아닌 실제적으로 컴파일러가 최적화를 진행한 경우와 최적화를 진행하지 않은 경우에 대해서 확인해보자.Complex operator+(const Complex&amp;amp; lhs, const Complex&amp;amp; rhs){ // operator+ 버전1 Complex retVal; retVal.real = lhs.real + rhs.real; retVal.imag = lhs.imag + rhs.imag; return retVal;}Complex operator+(const Complex&amp;amp; lhs, const Complex&amp;amp; rhs){ // operator+ 버전2 double r = lhs.real + rhs.real; double i = lhs.imag + rhs.imag; return Complex(r, i);}Complex operator+(const Complex&amp;amp; lhs, const Complex&amp;amp; rhs){ // operator+ 버전3 Complex retVal(lhs.real + rhs.real, lhs.imag + rhs.imag); return retVal;}Complex operator+(const Complex&amp;amp; lhs, const Complex&amp;amp; rhs){ // operator+ 버전4 return Complex(lhs.real + rhs.real, lhs.imag + rhs.imag);}위와 같이 4가지 버전에 대해서 RVO가 발생하는지 stdout을 통하여 확인을 해보았다. 나의 환경에서는 위에서 말했던 의사코드와 같은 최적화는 발생하지 않았다.단, -fno-elide-constructors 컴파일러 옵션을 사용한 경우 위의 4가지 버전 모두 Copy Construction이 추가적으로 발생했고, 속도가 이전보다 떨어지는 것을 확인했다.  최적화가 책에서 말하는 부분과는 다소 달리 발생했고, 책을 기준으로 버전2~4가 최적화가 발생했지만, Copy Constructor의 발생을 기준으로 본다면 위의 4가지가 모두 동일하게 최적화가 발생했다. 아쉽게도 위에서 이야기된 최적화 의사코드와는 다른 최적화가 발생했다.연산 생성자Complex operator+(const Complex&amp;amp; lhs, const Complex&amp;amp; rhs){ return Complex(lhs, rhs);}Complex(const Complex&amp;amp; lhs, const Complex&amp;amp; rhs) : real(lhs.real + rhs.real), imag(lhs.imag + rhs.imag) { }위와 같이 연산을 생성자에서 수행하는 것이 연산 생성자다. 위와 같은 경우 RVO를 적용할 확률이 높다고 한다. 실험 결과 책에서 말한 최적화는 발생하지 않았다. 하지만 추가적인 Copy Constructor는 발생하지 않았다. 즉 위와 동일한 최적화가 발생했다. 하지만 측정한 속도에서는 위의 버전1~4 보다 약 20%가 더 빠르게 측정됐다.키 포인트 객체를 값으로 반환해야 하는 경우, 반환 값 최적화를 사용해 지역 객체가 생성되고 소멸되는 것을 방지하여 성능이 좋아질 수 있다. 컴파일러 구현에 따라 RVO의 적용 사례가 달라진다. 사용하는 컴파일러 문서를 보거나 직접 실험해 보아야 한다.  연산 생성자를 사용하여 RVO가 적용될 확률을 높일 수 있다." }, { "title": "EFFICIENT C++_가상 함수", "url": "/posts/efficient-ceab080ec8381-ed95a8ec8898/", "categories": "", "tags": "c++, dynamic binding, Efficient C++, inline, Performance, virtual function, vptr, vtbl", "date": "2016-07-12 22:54:40 +0900", "snippet": "동적 바인딩 덕분에 프로그래머는 형식 확인을 컴파일러에게 맡기게 되었고 많이 편해졌다. 반대로 동적 바인딩은 성능에 부정적인 영향을 끼칠 수 있다.가상 함수 기법만약 가상 함수를 사용하고 싶지 않다면, 직접 형식 확인 코드를 작성하여 동적 바인딩을 흉내를 낼수있다.다음은 동물원 동물을 클래스로 표현한 것이다.class ZooAnimal {public: ZooAnimal(int zooType) : myType(zooType) {} virtual void draw() = 0; int resolveType() { return myType; }private: int myType;};동물원 동물 클래스의 파생 클래스로 Bear와 Monkey가 있다.class Bear : public ZooAnimal {public: Bear() : myName(&quot;&quot;), ZooAnimal(BEAR) {} Bear(const char *name) : myName(name), ZooAnimal(BEAR) {} void draw();private: std::string myName;};class Monkey : public ZooAnimal {public: Monkey() : myName(&quot;&quot;), ZooAnimal(MONKEY) {} Monkey(const char *name) : myName(name), ZooAnimal(MONKEY) {} void draw();private: std::string myName;};Bear와 Monkey 뿐만 아니라 앞으로 추가되는 ZooAnimal은 resolveType 메소드를 사용하여 각 객체를 구분할 수 있으며, 이를 위해서 각 동물 클래스의 생성자는 자신의 적절한 타입을 설정해줘야 한다.이제 다양한 종류의 ZooAnimal을 담은 vector를 통해서 각 동물에 맞는 draw 메소드를 사용해서 동물을 그릴 수 있다.아래와 같은 코드를 사용할 수 있다.void drawAllAnimals(std::vector&amp;lt;ZooAnimal *&amp;gt; animalList){ for (auto it = animalList.begin(); it != animalList.end(); ++it) { switch ((*it)-&amp;gt;resolveType()) { case BEAR: (dynamic_cast&amp;lt;Bear*&amp;gt;(*it))-&amp;gt;draw(); break; case MONKEY: /* */ default: break; } }}하지만 위와 같은 코드는 유지보수하기 까다롭다.  ZooAnimal에서 동물이 빠질 때 마다 위의 코드의 switch 구문에서 해당 동물을 제거 해야 한다. 또한 추가된 동물은 switch 구문에서 추가하고, 새로운 동물 타입과 생성자 코드를 추가해 주어야 한다.가상 함수의 동적 바인딩을 사용한다면 위와 같은 의존성 문제점을 해결할 수 있다. 현재 ZooAnimal의 draw 메소드는  가상 함수이기 때문에, 동적 바인딩을 실행 시에 사용할 수 있으며 아래와 같다.void drawAllAnimals(std::vector&amp;lt;ZooAnimal *&amp;gt; animalList) { for (auto it = animalList.begin(); it != animalList.end(); ++it) { (*it)-&amp;gt;draw(); }}가상 함수의 동적 바인딩을 수행하기 위해서 컴파일 타임이 아닌 런타임에 각 객체에 맞는 메소드를 확인할 수 있어야 한다. 이를 위해서 가상함수를 정의하고 있는 클래스이거나 그러한 클래스로부터 파생되었다면, 컴파일러는 해당 클래스를 위한 가상 함수 테이블(vtbl)을 생성한다. 가상 함수 테이블은 이 클래스가 정의한 모든 가상 함수들에 대한 포인터를 가지고 있다. 클래스 마다 하나의 테이블이 존재하고, 각 객체는 자신의 클래스의 가상 함수 테이블에 대한 숨겨진 포인터를 가지게 된다. 컴파일러는 가상 함수 테이블 포인터(vptr)에 대한 오프셋을 알고 있고, 가상 함수 테이블 포인터를 초기화 하기 위해서 객체 생성자에 초기화 코드를 삽입한다.가상 함수는 성능상에 부하가 생기는 부분이 있다. 가상 함수 테이블 포인터를 생성자에서 초기화 해야 한다. 가상 함수는 포인터 간접 참조를 통해서 호출되며 올바른 오프셋을 통해서 함수에 접근해야 한다. 인라인은 컴파일 타임에 결정되지만, 가상 함수는 런타임에 확인할 수 있는 가상 함수는 인라인을 사용할 수 없다.여기에서 처음 2가지 항목은 성능 부하라고 보기 힘들다.가상 함수를 사용하지 않은 상황에서도 가상 함수 테이블을 생성자에서 초기화하는 부하는 동적 바인딩을 피하는 코드에서도 각 동물의 타입을 멤버에 초기화하는 부하와 동일하다.두번째 항목은 switch 구문을 사용한 것과 동일한 성능 부하가 생긴다.즉, 가상 함수의 성능 부하는 인라인으로 해당 함수를 만들지 못 하여 발생하는 부하와 동일하다. 만약 특정 가상 함수가 성능상의 문제가 있다면, 가상 함수 호출을 제거하기 위해서 컴파일러가 함수 바인딩을 컴파일 타임에 수행하도록 해야 한다. 이를 위해서 하드코딩하거나, 클래스를 템플릿 매개변수로 전달하여 동적 바인딩을 무시할 수 있다.키 포인트 가상 함수의 부하는 인라인을 사용할수 없기 때문에 발생 템플릿은 상속 계층보다 더욱 성능에 좋다" }, { "title": "EFFICIENT C++_생성자와 소멸자", "url": "/posts/867/", "categories": "", "tags": "c++, Efficient C++, Performance", "date": "2016-07-12 09:56:34 +0900", "snippet": "상속이상적으로는 생성자와 소멸자는 오버헤드를 가지지 않아야 한다. 생성자와 소멸자는 오직 필수적인 초기화와 정리 작업을 수행하며, 일반적인 컴파일러는 이것들을 인라인 함수로 만들것이다.하지만, 상속과 합성 구현은 가끔 혹은 절대 사용되지 않는 연산을 수행하기도 한다. 상속과 합성 구현은 코드의 재사용을 위한 기술이다. 즉, 코드의 재사용과 성능과의 줄다리기 문제이다.코드의 재사용은 특정 상황에서 실제로 필요하지 않은 연산을 수행한다. 불필요한 연산을 수행하는 함수는 성능에 영향을 주게 된다.상속 기반 디자인과 생성자/소멸자의 부하 사이의 연관성을 살펴보자.이를 위해서 쓰레드 동기화와 관련된 예제를 사용해서 성능을 비교해보자.공유 리소스를 관리하기 위해서 간단한 코드를 보자면 아래와 같다.pthread_mutex_lock(&amp;amp;mutex);sharedCounter++; pthread_mutex_unlock(&amp;amp;mutex);공유 리소스를 보호하기 위해서 sharedCounter 값을 변경시키는 곳 주변에만 잠금을 수행하면 된다.간단하면서 효율적인 코드이긴 하지만 여기에도 단점은 존재한다.유지 보수 관점에서 버그를 양산할 가능성이 높아진다. 사용자가 잠금을 얻었다면 반환구문을 실행하기 전에 잠금을 풀어야 한다.또한 잠금을 얻은 상황에서 예외가 발생한다면 예외를 받아서 수동으로 잠금을 해제해주어야 한다.C++에서는 위의 두가지 문제점에 좋은 해결책을 제공한다. 잠금을 얻고 풀기 위한 루틴을 클래스로 구현하면 위의 문제가 쉽게 해결이 된다.동기화 관련 로직의 다양성을 위해서 Lock 부모 클래스와 구현체인 DerivedMutex로 구성했다.class Lock {public: Lock(pthread_mutex_t&amp;amp; lock) {}; virtual ~Lock() {};};class DerivedMutex : public Lock {public: DerivedMutex(pthread_mutex_t&amp;amp; lock) : Lock(lock), myLock(lock) {acquire();} ~DerivedMutex() {release();}private: int acquire() {return pthread_mutex_lock(&amp;amp;myLock);} int release() {return pthread_mutex_unlock(&amp;amp;myLock);} pthread_mutex_t&amp;amp; myLock;};사용 코드는 아래와 같다.{ DerivedMutex m(mutex); sharedCounter++;} 위와 같이 클래스를 사용할 경우 얻어지는 이점은 다음과 같다. 여러 반환 시점을 포함하고 있는 복잡한 루틴의 유지 보수 예외로부터 복구 잠금의 다형성 로깅의 다형성이제 성능의 차이를 비교해 보자.// 시간 측정for (int i = 0; i &amp;lt; 50000000; i ++) { // 테스트 코드}// 시간 측정 후, 최종 걸린 시간 측정위의 코드로 측정한 결과.클래스 없이 간단하게 잠금을 얻고 해제한 버전의 수행 시간은 약 1.6초가 걸린다.하지만, 클래스에 상속을 사용한 버전의 경우 약 2.3초가 걸리는 것을 확인했다. 즉, 성능이 약 40% 감소한것을 볼 수 있다.상속을 이용한 클래스를 사용한 경우, 한줄의 코드에서 다음의 생성자를 호출한다. Lock DerivedMutex실제적으로 할일을 모두 마치고 소멸자 호출은 다음과 같다. DerivedMutex Lock현재 상황에서 Lock 클래스는 확장성을 위한 인터페이스만 제공하고 있는 상황이다. 하지만 DerivedMutex 외의 구현체가 없다.이런 상황에서 굳이 Lock 클래스를 사용하지 않고 독립적인 클래스를 작성해서 비교해보자.class SimpleMutex {public: SimpleMutex(pthread_mutex_t&amp;amp; lock) : myLock(lock) {acquire();} ~SimpleMutex(){release();}private: int acquire() {return pthread_mutex_lock(&amp;amp;myLock);} int release() {return pthread_mutex_unlock(&amp;amp;myLock);} pthread_mutex_t&amp;amp; myLock;};상속을 사용하지 않고 DerivedMutex와 동일한 기능을 하는 클래스이다. 사용법 또한 동일하다. 하지만 필요없는 Lock 생성자&amp;amp;소멸자 호출은 발생하지 않는다.위의 테스트 코드를 통해서 성능을 측정해보면 약 1.7초가 걸리는 것을 확인했다.부모 클래스의 생성자와 소멸자에서 하는 일이 아무것도 없지만 불필요한 호출은 성능적으로 불이익이 발생함을 알수 있다.합성상속과 같이 객체 합성도 객체 생성과 소멸에 관련된 유사한 성능 문제를 가지고 있다. 객체가 생성(소멸)될 때, 해당 객체가 포함한 모든 객체들도 생성(소멸)되어야 한다.앞에서 이야기한 Trace 클래스를 보면 다음과 같다.class Trace { public:  Trace(const char *name);… private:  string theFunctionName; };위의 예제는 Trace 객체가 생성되면 string 하위 객체도 생성된다. 소멸자도 동일하다. 현재 구현에서는 string 객체의 생성 소멸을 조정 할 수는 없다.class Trace {public: Trace(const char *name); … private:  string theFunctionName;};위의 예제는 string 객체의 생성과 소멸을 사용자가 조정 가능하다.class Trace { public: Trace(const char *name) : theFunctionName(0) { if(…) { theFunctionName = new string(name); } } … private:  string *theFunctionName;};또한 위와 같이 부분 초기화를 하고, 실제로 사용할 경우에 string 객체를 생성 혹은 소멸 시킬 수 있다.위의 세가지 형태는 사용 패턴에 따라서 무엇이 가장 효율적인지는 달라지게 된다. 항상 theFunctionName을 사용한다면 첫번째 형태가, theFunctionName을 종종 사용하게 된다면, 객체를 생성하는것 보다 0을 포인터에 대입하는 것이 훨씬 부담이 적기 때문에 세번째 형태가 효율적이다.지연 생성C++ 언어는 변수를 처음으로 사용하기 전까지 생성하지 않아야 한다. 이 변수는 Primitive Type일 수도 있지만, 클래스일 수도 있다.우리는 지금까지 클래스의 불필요한 생성자와 소멸자의 호출과 불필요한 함수의 호출이 성능에 어떤 영향을 줄 수 있는지 확인했다. 그렇다면, 당연히 우리는 실제로 사용하기 전까지는 변수의 생성을 지연하는 것이 타당하다는 것을 이해할 것이다.중복 생성다음과 같이 string 을 구현한 SuperString이 있다.class SuperString {public: SuperString(const char *s = 0); SuperString(const SuperString &amp;amp;s); SuperString&amp;amp;operator=(const SuperString&amp;amp; s); ~SuperString() {delete [] str;}private: char *str;};inline SuperString::SuperString(const char *s) : str(0) { if (s != 0) { str = new char[strlen(s) + 1]; strcpy(str, s); }}inline SuperString::SuperString(const SuperString &amp;amp;s) : str(0) { if (s.str) { str = new char[strlen(s.str) + 1]; strcpy(str, s.str); }} SuperString&amp;amp; SuperString::operator=(const SuperString &amp;amp;s) { if (str != s.str) { delete [] str; if (s.str) { str = new char[strlen(s.str) + 1]; strcpy(str, s.str); } } else { str = 0; } return *this;}SuperString을 사용하는 Person 클래스는 아래와 같다.class Person {public: Person(const char *s) { name = s; }private: SuperString name;};위와 같은 경우 Person 클래스의 생성자의 실행을 의사코드로 표현하면 아래와 같다.Person::Person(const char *s){ name.SuperString::SuperString(); // 생성자: name 멤버를 초기화한다. SuperString _tmp; // 임시 객체 _tmp.SuperString::SuperString(s); // s로부터 SuperString 객체를 생성 name.SuperString::operator=(_tmp); // _tmp를 name에 대입한다. _tmp.SuperString::~SuperString(); // 임시 객체를 위한 소멸자}버전 1의 실행 의사코드를 보면 불필요한 초기화와 임시객체의 생성 및 소멸 그리고 대입이 수행되고 있다.이는 초기화 리스트를 사용하지 않아서 중복된 생성과 불필요한 대입연산이 추가된 경우이다. 이 경우는 아래와 같이 초기화 리스트를 사용해 해결이 된다.class Person {public: Person(const char *s) : name(s) { }private: SuperString name;};버전 1과 버전 2의 성능을 비교해보면 버전 1이 약 3.5초 버전 2가 약 1.7초로 약 2배의 성능 차이가 발생함을 알수 있다.키 포인트- 생성자와 소멸자는 직접 작성한 C 코드 만큼 효율적이여야 하지만, 실제적으로 과잉 연산의 형태를 가진 오버헤드를 종종 포함하고 있다. 객체의 생성(소멸)은 부모와 멤버 객체의 재귀적인 생성(소멸)을 발생시킨다. 복잡한 계층엥서 객체 생성(소멸)의 조합을 조심해야 한다. 객체의 생성과 소멸은 CPU 주기를 소모한다. 꼭 필요하지 않으면 객체를 생성하지 말자. 객체는 실제로 사용하기 전까지 생성을 지연하는 것이 좋다. 생성자 본문을 들어가기 이전에 객체 멤버를 초기화한다. 이는 초기화 리스트를 사용하여 초기화를 명시적으로 지정할 수 있으며, 이는 임시 객체의 생성과 대입 연산자를 호출하는 오버헤드를 줄일 수 있다." }, { "title": "Efficient C++_로깅과 관련된 성능 이야기", "url": "/posts/efficient-ceba19ceab985eab3bc-eab480eba0/", "categories": "", "tags": "c++, Efficient C++, Performance", "date": "2016-07-11 05:45:08 +0900", "snippet": "소프트웨어를 유지보수를 하다보면 로깅이 매우 중요하다.로깅을 통해서 문제 상황 추적 및 프로그램의 실행 흐름을 파악하는데 많은 도움이 된다.이런 로깅과 관련된 코드는 성능과 관련된 여러가지 문제들을 만나기 쉽다.로깅과 관련된 성능 최적화의 극단적인 방법은 추적 호출을 #ifdef 블록 안에 내장하여 성능 부하를 제거하는 것이다.#ifdef TRACE Trace t(&quot;myFunction&quot;); t.debug(&quot;Some message&quot;);#endif하지만 #ifdef는 로깅을 켜고 끌때마다 컴파일을 새로 해야 한다는 단점이 있다.이를 보완하기 위해서 로깅을 남길지 여부를 로깅을 하기 전에 확인하도록 Trace 클래스를 구현할 수 있다.void Trace::debug(const string &amp;amp;msg){ if (traceIsActive) { // 로그 메시지 기록 }} 해당 코드는 로깅을 수행 중일때의 성능을 고려하지 않은 코드이다.코드가 최고의 성능을 낼 수 있도록 일반적인 동작을 수행하는 동안에는 기본적인 로깅을 꺼야하고, 로깅 오버헤드는 최소가 되어야 한다. 일반적인 로깅 구문은 다음과 같은 형식이 될 것이다.t.debug(&quot;x = &quot; + itoa(x));해당 구문은 성능 이슈가 몇 가지 존재한다. “x = “에서 임시 string 객체를 만든다. itoa(x)를 호출한다. itoa()가 반환한 char 포인터로 부터 임시 string 객체를 만든다. 세 번째 임시 string 객체를 만들어 위 두 string 객체를 연결한다. debug() 호출이 반환한 직후 세 string 임시 객체는 모두 소멸한다.string 객체와 Trace 객체를 생성하고 소멸하는 오버헤드는 많으면 수백 명령까지 차이가 날수 있다.초기 로깅 구현로깅 성능 비교를 위한 간단한 테스트 함수를 작성해보자int addOne(int x){ return x + 1;}해당 함수를 약 1000000회 정도 수행하니 3 millisecond가 걸렸다.아래는 로깅을 위한 함수를 간단하게 작성한것이다.class Trace {public: inline Trace(const string&amp;amp; name) : theFunctionName(name) { if (traceIsActive) { cout &amp;lt;&amp;lt; &quot;Enter Function &quot; &amp;lt;&amp;lt; name &amp;lt;&amp;lt; endl; } } inline ~Trace() { if (traceIsActive) { cout &amp;lt;&amp;lt; &quot;Exit Function &quot; &amp;lt;&amp;lt; theFunctionName &amp;lt;&amp;lt; endl; } }  inline void debug(const string &amp;amp;msg) { if (traceIsActive) { cout &amp;lt;&amp;lt; msg &amp;lt;&amp;lt; endl; } } static bool traceIsActive;private: string theFunctionName;};Trace 클래스를 삽입한 결과 아래와 같다.int addOne(int x){ string name = &quot;addOne&quot;; Trace t(name); return x + 1;}위와 동일하게 addOne을 수행할 경우, 52 millisecond가 걸렸다. Trace 클래스를 삽입한 결과로 17배 정도 성능 저하가 발생한 것이다.C++ 성능과 관련해 각기 다른 의견이 있을 수 있지만, 모두가 동의하는 기본 법칙이 있다. I/O는 부하를 많이 주는 작업이다. 함수 호출도 오버헤드의 원인 중 하나이므로 자주 호출되는 함수는 인라인으로 작성한다. 객체를 복사하는 것은 부하를 많이 주는 작업이다. 값 전달 보다는 참조로 전달하는 방식을 사용하자.하지만 위의 법칙들 모두 Trace 클래스에서 모두 준수하고 있는 상황이다.위의 addOne 함수를 보면 로깅을 사용하지 않는 상황에서는 실제로 사용하지 않는 객체를 생성하고 소멸시키는 부분이 있다.이 부분만 아니면 속도는 더 빨라질수 있다.다음 버전으로 불필요한 객체 생성을 제거하여 보자.int addOne(int x){ char* name = &quot;addOne&quot;; EnhancedTrace t(name); return x + 1;}일단 addOne에서 불필요하게 생성 소멸된 string 객체인 name을 char*로 변경하였다.그리고 로깅이 켜져 있는 경우에만 해당 name 문자열을 담을 메모리를 할당하도록 수정했다.class EnhancedTrace {public: inline EnhancedTrace(const char * const name) : theFunctionName(NULL) { if (traceIsActive) { cout &amp;lt;&amp;lt; &quot;Enter Function1 &quot; &amp;lt;&amp;lt; name &amp;lt;&amp;lt; endl; theFunctionName = (char*)malloc(sizeof(char) * strlen(name)); } } ~EnhancedTrace() { if (traceIsActive) { cout &amp;lt;&amp;lt; &quot;Exit Function1 &quot; &amp;lt;&amp;lt; theFunctionName &amp;lt;&amp;lt; endl; free(theFunctionName); } }  void debug(const string &amp;amp;msg) { if (traceIsActive) { cout &amp;lt;&amp;lt; msg &amp;lt;&amp;lt; endl; } } static bool traceIsActive;private: char* theFunctionName;};아까와 동일하게 addOne 함수를 수행한 결과 12 millisecond가 걸린것을 확인했다.즉 17배의 성능 저하에서 4배의 성능 저하로 많은 오버헤드가 줄어든것을 확인할 수 있다.키포인트 객체를 정의하면 생성자와 소멸자의 형태로 조용한 실행이 발생한다. 대게의 경우 생성자와 소멸자는 부하가 아니기 때문에 조용한 실행이라고 한다. 하지만, 위의 예제에서와 같이 현저한 오버헤드를 발생하는 경우도 존재한다. 객체를 참조로 전달하는 것이 무조건적인 성능을 보장하는 것은 아니다. 일단 불필요한 객체의 생성과 소멸은 막을 수 있다면 성능에 도움이 된다. char 포인터는 가끔 string에 비해서 더 효율적이면서도 단순한 작업을 잘 수행한다. 인라인. 작은 함수를 자주 호출하면 인라인을 통해서 함수 호출 오버헤드를 줄일수 있다." }, { "title": "Functors: Function Objects in C++", "url": "/posts/functors-function-objects-c/", "categories": "", "tags": "c++, function pointer, functor, template, virtual function", "date": "2016-06-20 11:18:23 +0900", "snippet": "C와 C++ 모두 function pointer를 지원한다. function pointer는 특정 명령을 수행하는 함수를 전달할 수 있는 방법 중 하나이다.하지만, function pointer는 매우 제한적인데, function pointer는 컴파일 시점에 해당 함수가 정의되어 있어야 한다. 그럼 왜 이것 때문에 function pointer가 제한적이라고 하는 것일까?수신함을 보는 메일 프로그램을 작성하는 예를 들어보자. 사용자가 다양한 필드(to, from, date 등)를 이용해서 수신함을 정렬을 할 수 있도록 하고 싶다. 메시지를 비교하는 정렬 루틴을 메시지 비교를 하는 function pointer를 사용하고자 할것이다. 메일의 필드만 달리 비교하는 함수를 만들수도 있지만, 이는 하드 코딩된 필드만 정렬할 수 있을 것이다. 결국 정렬 루틴에서 사용할 다양한 함수들을 만들게 된다.비교 함수에 어떤 필드를 비교할지 알려주는 제 3의 인자를 전달 하고 싶을 것이다. 그러나 이렇게 하기 위해서는 제 3의 인자를 아는 정렬 루틴을 만들어야 한다. 그러면 제 3의 인자를 comparator에 전달 할수 없으므로 STL과 같은 generic routine을 사용할 수 없다. 대신, 함수 내부에서 어떤 필드를 정렬할지 아는 함수가 필요 하다.위와 같은 문제를 해결하기 위해서 C++에서 function object(functors)를 사용할 수 있다. functor는 function과 function pointer와 같이 다룰 수 있는 객체이다. 아래와 같은 코드를 작성할 수 있다.myFunctorClass functor; functor(1, 2, 3);C++은 operator()(function call)를 오버로드할 수 있으므로 위의 코드는 작동한다. function call operator는 여러개의 인자와 다양한 타입을 받을 수 있고 어떤 것이든 결과 값으로 전달 할 수 있다. 이것은 operator를 오버로드할 수 있으므로써 생기는 유연성이다. 이후 해당 글에서 객체의 operator()를 호출할 때 객체를 호출했다고 이야기 하겠다.오버로딩한 operator()가 좋지만, functor의 진면목은 functor의 life cycle이 function 보다 더 유연하다는 점이다. functor의 생성자에 추후에 operator()에서 사용할 정보들 삽입할 수 있다.다음 예제는 integer 인자를 받는 생성자를 가진 functor class를 생성한다. 해당 클래스의 객체가 호출되면 저장된 값과 인자 값을 더한 결과를 반환한다.class myFunctorClass{public: myFunctorClass(int x) : _x(x) {} int operator() (int y) { return _x + y; }private: int _x;};TEST(myFunctorClassTest, TestSimpleAdding) { myFunctorClass addFive(5); EXPECT_EQ(11, addFive(6));}결론적으로 생성자에 인자를 넘겨주는면, 이후 해당 인수를 사용하는 함수와 같은 동작을 한다.Sorting Mail이제 정렬 functor를 구현하기 위해서 코드를 어떻게 작성하면 될지 생각해보자.두개의 인자를 받는 operator()가 필요하고 정렬하고자 하는 필드 정보를 저장하는 생성자가 필요하다.class Message{public: std::string getHeader(const std::string&amp;amp; header_name) const;};class MessageSorter{public: MessageSorter (const std::string&amp;amp; field) : _field(field) {} bool operator() (const Message&amp;amp; lhs, const Message&amp;amp; rhs) { return lhs.getHeader(_field) &amp;lt; rhs.getHeader(_field); }private: std::string _field;};이제 메시지 vector가 있다면, 우리는 STL sort 함수를 사용해서 정렬을 할 수 있다.TEST(MessageSorterTest, TestMessageSorter){ std::vector&amp;lt;Message&amp;gt; messages; // read in messages MessageSorter comparator(&quot;to&quot;); std::sort(messages.begin(), messages.end(), comparator);}Functors Compared with Function PointersFunction Pointer를 인자로 받는 함수는 Functor를 인자로 넘길수 없다. 심지어 Functor가 Function Pointer와 동일한 인자와 결과값을 가진다고 해도 넘길수 없다.이와 비슷하게 Functor를 인자로 받는 함수는 Function pointer를 인자로 넘길수 없다.Functors, Function Pointers and TemplatesFunction Pointer와 Fuctor를 동일한 함수에 인자로 넘기고자 한다면, 템플릿을 사용해야 한다. 템플릿 함수는 Functor와 Function Pointer를 적절한 타입으로 추론하고 Functor와 Function Pointer를 동일한 방식으로 사용한다. 둘 다 함수 호출과 같은 형태를 취한다. 그래서 해당 함수는 컴파일이 무사히 된다.예를 들어 보면 아래와 같은 함수가 있다.std::vector&amp;lt;int&amp;gt; find_matching_numbers(std::vector&amp;lt;int&amp;gt; vec, bool (*pred)(int)){ std::vector&amp;lt;int&amp;gt; ret_vec; std::vector&amp;lt;int&amp;gt;::iterator itr = vec.begin(), end = vec.end(); while (itr != end) { if (pred(*itr)) { ret_vec.push_back(*itr); } ++itr; }}위의 함수를 Functor와 Function Pointers를 모두 사용하도록 두번째 인자를 템플릿화하도록 수정했다.template &amp;lt;typename FuncType&amp;gt;std::vector&amp;lt;int&amp;gt; find_matching_numbers(std::vector&amp;lt;int&amp;gt; vec, FuncType pred){ std::vector&amp;lt;int&amp;gt; ret_vec; std::vector&amp;lt;int&amp;gt;::iterator itr = vec.begin(), end = vec.end(); while (itr != end) { if (pred(*itr)) { ret_vec.push_back(*itr); } ++itr; }}Functor vs. Virtual FunctionsFunctor와 Virtual Function은 매우 관련있다고 한다. 이 둘은 어떤 코드가 알고리즘을 어떻게 선택하도록 할지에 대한 문제를 해결 한다.자, 상상해보자. doMath라는 함수가 있다. 이 함수는 3개의 인자를 받는다. 2개의 인자는 integer이고, 나머지 하나는 어떤 연산을 수행하는 루틴이다. Functor로 작성한 예는 아래와 같다.template &amp;lt;typename FuncType&amp;gt;int doMath(int x, int y, FuncType func){ return func(x, y);}다른 방법으로 computeResult 메소드를 가진 인터페이스 클래스를 생성할 수 있다.class MathComputer{public: virtual int computeResult(int x, int y) = 0;};int doMath(int x, int y, MathComputer* p_computer){ return p_computer-&amp;gt;computeResult(x, y);}위의 두 예제는 virtual function과 functor 모두 특정 알고리즘이 실행되는 시점에 동적으로 선택을 할 수 있다.두 개의 주요한 차이점은 virtual function은 템플릿 함수를 사용하더라도 function pointer를 인자로 받을 수 없다." }, { "title": "블로그에 Code Highlighting 적용하기", "url": "/posts/ebb894eba19ceab7b8ec9790-code-highlighting/", "categories": "", "tags": "blogging, code, SyntaxHighlighter", "date": "2016-06-15 00:31:55 +0900", "snippet": "Code Highlight를 적용하기 앞써 어떤 제품들이 있는지 확인해보자. Prism Rainbows Snippet Geshi Syntax Highlighter Google Code Prettify Highlight.js SHJS : Syntax Highlighting in JavaScript Quick Highlighter Ultraviolet Pygments : Python Syntax Highlighter Lighter for MooTools CodePress Beauty of Code Jush JavaScript Syntax Highlighter위와 같이 다양한 제품을 사용할 수 있다. 해당 제품들의 간단한 설명은 아래의 글을 참고하기 바란다.15 Code Syntax Highlighters To Prettify Your Code이번 글은 Syntax Highlighter를 적용해본다.설치는 간단하다.아래와 같이 몇 줄만 추가하면 Code Highlight가 적용이 된다.&amp;lt;!— Syntax Highlighter를 적용하기 위해 추가가 필요한 부분 —&amp;gt;&amp;lt;script type=&quot;text/javascript&quot; src=&quot;js/shCore.js&quot;&amp;gt;&amp;lt;/script&amp;gt;&amp;lt;script type=&quot;text/javascript&quot; src=&quot;css/shBrushJScript.js&quot;&amp;gt;&amp;lt;/script&amp;gt;&amp;lt;link href=&quot;css/shCore.css&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot; /&amp;gt;&amp;lt;link href=&quot;css/shThemeDefault.css&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot; /&amp;gt;&amp;lt;!— Syntax Highlighter를 적용하기 위해 추가가 필요한 부분 —&amp;gt;&amp;lt;pre class=&quot;brush: js&quot;&amp;gt;function foo(){}&amp;lt;/pre&amp;gt;일단 위와 같은 코드를 적용하기 위해서 코드를 다운로드 받는다.직접 운영중인 사이트라고 한다면, 해당 코드들을 서버에 올려서 링크를 걸면 된다.Tumblr의 경우에는 코드들을 서버에 올릴수 있긴 하지만, 테마 변경 시, 모두 리셋이 되어 불편함이 있다.나의 경우에는 Github에 Syntax Highlighter 코드를 모두 올려두고 사용했다.Github에 코드를 올려두고 링크 주소를 아래와 같이 사용하면 된다.https://github.com/아이디.. 와 같은 형태의 주소를 https://cdn.rawgit.com/아이디/.. 와 같은 형태의 주소로 사용하면 된다.Syntax Highlighter는 다양한 Theme을 제공하는데, 다운로드 받은 코드 디렉토리의 styles 디렉토리에 들어 있다.원하는 테마를 css/shThemeDefault.css 대신에 넣어주면 된다." }, { "title": "[CMAKE] TUTORIAL STEP5", "url": "/posts/cmake-tutorial-step5/", "categories": "", "tags": "build, cmake, tutorial", "date": "2016-06-09 10:34:02 +0900", "snippet": "이번에는 생성된 소스 파일을 어플리케이션을 빌드하는 과정에 어떻게 넣을수 있는지 보자.이번 예제에서는 빌드 과정의 한 부분으로서 미리 계산된 제곱근의 테이블을 생성하고, 해당 테이블을 우리 어플리케이션에 컴파일해보자. 이를 위해서는 일단 테이블을 생성하는 프로그램이 필요하다. MathFunctions 의 하위 디렉토리에 이런 작업을 하는 MakeTable.cpp 파일을 생성하자//// Created by appchemist on 2016. 6. 8..//#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;math.h&amp;gt;int main(int argc, char *argv[]){ int i; double result; // make sure we have enough arguments if (argc &amp;lt; 2) { return 1; } // open the output file FILE *fout = fopen(argv[1], &quot;w&quot;); if (!fout) { return 1; } // create a source file with a table of square roots fprintf(fout, &quot;double sqrtTable[] = {\\n&quot;); for (i = 0; i &amp;lt; 10; ++i) { result = sqrt(static_cast&amp;lt;double&amp;gt;(i)); fprintf(fout, &quot;%g,\\n&quot;, result); } // close the table with a zero fprintf(fout, &quot;0};\\n&quot;); fclose(fout); return 0;}테이블은 C++ 코드로 생성된다. 결과 파일 이름은 argument로 전달된다. 다음으로는 MathFunctions CMakeLists 파일에 MakeTable 을 빌드하기 위한 명령을 추가하고, 빌드 과정의 부분으로 이것을 실행할 것이다. 명령 몇개가 필요한데, 아래를 확인해보자.# first we add the executable that generates the tableadd_executable(MakeTable MakeTable.cpp)# add the command to generate the source codeadd_custom_command( OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/Table.h COMMAND MakeTable ${CMAKE_CURRENT_BINARY_DIR}/Table.h DEPENDS MakeTable)# add the binary tree directory to the search path for# include filesinclude_directories(${CMAKE_CURRENT_BINARY_DIR})add_library(MathFunctions mysqrt.cpp ${CMAKE_CURRENT_BINARY_DIR}/Table.h)install (TARGETS MathFunctions DESTINATION bin)install (FILES mysqrt.h DESTINATION include)먼저 다른 executable처럼 MakeTable도 추가를 했다. 그리고 사용자 정의 명령을 추가하여 MakeTable을 실행하여 Table.h를 생성하도록 했다. 다음으로 CMake에 mysql.cpp가 Table.h를 필요하다는 것을 알려줬고 이러면 MathFunction 라이브러리를 위해서 생성한 Table.h를 추가하는 작업은 끝이난다. 그리고 mysqrt.cpp가 Table.h를 찾고 include를 할 수 있도록 현재 바이너리 디렉토리 위치를 include directories에 추가해줘야 한다. 이 프로젝트를 빌드하면, 먼저 MakeTable가 빌드된다. 그리고 MakeTable을 실행하여 Table.h를 생성한다. 마지막으로 mysqrt.cpp를 컴파일하는데, mysqrt.cpp는 Table.h를 포함하고 MathFunctions 라이브러리를 생성한다. 현재까지의 내용은 아래와 같다.include(CTest)set (Tutorial_VERSION_MAJOR 1)set (Tutorial_VERSION_MINOR 0)find_package(PkgConfig REQUIRED)include(CheckFunctionExists)set(CMAKE_REQUIRED_INCLUDES math.h)set(CMAKE_REQUIRED_LIBRARIES m)check_function_exists(log HAVE_LOG)check_function_exists(exp HAVE_EXP)set(CMAKE_EXTRA_INCLUDE_FILES)set(CMAKE_REQUIRED_LIBRARIES)option(USE_MYMATH &quot;Use tutorial provided math implementation&quot; ON)configure_file( &quot;TutorialConfig.h.in&quot; # Input &quot;${PROJECT_BINARY_DIR}/TutorialConfig.h&quot; # Output)include_directories(${CMAKE_BINARY_DIR})# add the MathFunctions library?if (USE_MYMATH) include_directories(&quot;${PROJECT_SOURCE_DIR}/MathFunctions&quot;) add_subdirectory(MathFunctions) set(EXTRA_LIBS ${EXTRA_LIBS} MathFunctions)endif (USE_MYMATH)# add the excutableadd_executable(Tutorial tutorial.cpp)target_link_libraries(Tutorial ${EXTRA_LIBS})# add the install targetsinstall (TARGETS Tutorial DESTINATION bin)install (FILES &quot;${PROJECT_BINARY_DIR}/TutorialConfig.h&quot; DESTINATION include)#does the application runadd_test(TutorialRuns Tutorial 25)# does it handle negative numbersadd_test (TutorialNegative Tutorial -25)set_tests_properties (TutorialNegative PROPERTIES PASS_REGULAR_EXPRESSION &quot;-25 is 0&quot;)# does it handle small numbersadd_test (TutorialSmall Tutorial 0.0001)set_tests_properties (TutorialSmall PROPERTIES PASS_REGULAR_EXPRESSION &quot;0.0001 is 0.01&quot;)# does the usage message work?add_test (TutorialUsage Tutorial)set_tests_properties (TutorialUsage PROPERTIES PASS_REGULAR_EXPRESSION &quot;Usage:.*number&quot;)# define a macro to simplify adding test, then use itmacro(do_test arg result) add_test (TutorialComp${arg} Tutorial ${arg}) set_tests_properties(TutorialComp${arg} PROPERTIES PASS_REGULAR_EXPRESSION ${result})endmacro(do_test)# do a bunch of result based testsdo_test (25 &quot;25 is 5&quot;)do_test (-25 &quot;-25 is 0&quot;)" }, { "title": "[CMAKE] TUTORIAL STEP4", "url": "/posts/cmake-tutorial-step4/", "categories": "", "tags": "build, cmake, tutorial", "date": "2016-06-09 10:30:04 +0900", "snippet": "이번에는 대상 플랫폼이 지원하지 않는 기능에 의존적인 몇몇 코드들을 추가하는 상황에 대해서 알아보자.이번 예제에서는 대상 플랫폼이 log와 exp 함수의 지원여부에 의존적인 코드를 추가할 것이다. 물론 거의 대부분의 플랫폼에서 해당 함수를 지원한다. 하지만 이번 튜토리얼에서는 대부분 지원하지 않는다고 가정한다. 만약 사용하는 플랫폼이 log 함수를 가지고 있고 우리가 만든 mysqrt 함수를 사용한다면, 우리는 먼저 최상위 CmakeLists 파일의 CheckFunctionExists.cmake 메크로를 사용해서 확인할 것이다.# does this system provide the log and exp functions? include(CheckFunctionExists) check_function_exists(log HAVE_LOG) check_function_exists(exp HAVE_EXP)다음으로 우리는 TutorialConfig.h.in 을 수정할 것이다. 만약 CMake 가 해당 플랫폼에서 log와 exp의 존재 여부를 알려주는 변수를 정의할 것이다.#cmakedefine USE_MYMATH #cmakedefine HAVE_LOG #cmakedefine HAVE_EXPTutorialConfig.h를 위한 configure_file 명령을 수행 전에 log와 exp 함수의 존재 여부를 확인하는 것이 중요하다. configure_file 명령은 현재의 CMake의 설정값을 사용하여 즉시 파일을 설정한다. 최종적으로 아래의 코드를 사용하여 log와 exp 함수를 사용해서 mysqrt 함수의 다른 구현을 만들수 있다.#if defined(HAVE_LOG) &amp;amp;&amp;amp; defined(HAVE_EXP)  result = exp(log(x)*0.5); #else" }, { "title": "[CMAKE] TUTORIAL STEP3", "url": "/posts/cmake-tutorial-step3/", "categories": "", "tags": "build, cmake, tutorial", "date": "2016-06-09 10:27:12 +0900", "snippet": "다음 과정으로 설치 규칙과 테스트 관련 정보를 프로젝트에 추가해보자. 설치 규칙은 매우 직관적이다. 아래의 두줄을 라이브러리의 CMakeLists 파일에 다음 두줄을 추가해서 MathFunctions 라이브러리와 헤더 파일을 설치할 수 있다.install (TARGETS MathFunctions DESTINATION bin) install (FILES mysqrt.h DESTINATION include)최상위 CMakeLists 파일에 다음 두 줄을 추가해서 실행파일과 설정 헤더 파일을 설치할 수 있다.# add the install targets install (TARGETS Tutorial DESTINATION bin) install (FILES &quot;${PROJECT_BINARY_DIR}/TutorialConfig.h&quot;  DESTINATION include)이제 Tutorial을 빌드하고, make install 을 실행하면 헤더 파일과 라이브러리, 실행 파일이 설치 된다. CMAKE_INSTALL_PREFIX 변수는 해당 파일들이 설치될 root 디렉토리를 지정한다.Test를 추가하는 것도 매우 직관적이다. 최상위 CMakeLists 파일에 어플리케이션을 확인하는 여러 테스트 코드들을 추가할 수 있다.include(CTest)  #does the application run add_test(TutorialRuns Tutorial 25)  # does it sqrt of 25 add_test(TutorialComp25 Tutorial 25)  set_tests_properties(TutorialComp25 PROPERTIES PASS_REGULAR_EXPRESSION &quot;25 is 5&quot;)  # does it handle negative numbers add_test (TutorialNegative Tutorial -25) set_tests_properties (TutorialNegative  PROPERTIES PASS_REGULAR_EXPRESSION &quot;-25 is 0&quot;)  # does it handle small numbers add_test (TutorialSmall Tutorial 0.0001) set_tests_properties (TutorialSmall  PROPERTIES PASS_REGULAR_EXPRESSION &quot;0.0001 is 0.01&quot;)  # does the usage message work? add_test (TutorialUsage Tutorial) set_tests_properties (TutorialUsage  PROPERTIES  PASS_REGULAR_EXPRESSION &quot;Usage:.*number&quot;)빌딩 이후에 테스트를 실행하기 위해서 ctest 커맨드라인 툴을 실행한다.첫 테스트는 간단하게 어플리케이션이 동작하는지 segfault 또는 크래쉬가 발생하는지 그리고 0을 반환하는 값을 가지고 있는지 확인한다. 이것은 CTest 테스트의 간단한 형태이다. 다음 몇몇 테스트는 테스트의 결과 문자열의 특정 문자열을 포함하고 있는지 확인하기 위해서 PASS_REGULAR_EXPRESSION 테스트 속성을 사용한다. 이 경우에는 제곱근의 결과가 무엇이 나와야 하는지 그리고 잘못된 값을 넣을때 나오는 사용 메시지를 확인한다. 만약에 다른 입력값에 따른 많은 테스트를 추가하고 싶다면 메크로 사용해보자.# define a macro to simplify adding test, then use it macro(do_test arg result)  add_test (TutorialComp${arg} Tutorial ${arg})  set_tests_properties(TutorialComp${arg}  PROPERTIES PASS_REGULAR_EXPRESSION ${result}) endmacro(do_test)  # do a bunch of result based tests do_test (25 &quot;25 is 5&quot;) do_test (-25 &quot;-25 is 0&quot;)" }, { "title": "[CMAKE] TUTORIAL STEP2", "url": "/posts/cmake-tutorial-step2/", "categories": "", "tags": "build, cmake, tutorial", "date": "2016-06-07 02:21:20 +0900", "snippet": "이제 우리 프로젝트에 라이브러리를 추가해보자. 해당 라이브러리는 우리가 앞 서 구현한 제곱근을 계산하는 라이브러리다. 그러면 컴파일러에서 제공하는 기본 제곱근 계산 함수 대신에 이 라이브러리를 사용할 수 있다. 해당 튜토리얼을 위해서 이 라이브러리는 MathFunctions라는 디렉토리에 두도록 한다. 그리고 이 라이브러리의 CMakeLists에는 아래의 한 줄을 추가해야 한다.add_library(MathFunctions mysqrt.cpp)mysqrt.cpp 는 mysqrt 라는 컴파일러의 sort 함수와 유사한 기능을 제공하는 함수를 가지고 있다. 새 라이브러리를 빌드하여 사용하기 위해서 add_subdirectory 함수를 최상위 CMakeLists 파일에 추가해줘야 한다. 또한 Function Prototype을 찾기 위해서 MathFunctions/mysqrt.h 해더 파일 위치를 지정하기 위해서 include directory를 추가해줘야 한다. 최종적으로 아래와 같이 수정되어야 한다.include_directories(&quot;${PROJECT_SOURCE_DIR}/MathFunctions&quot;) add_subdirectory(MathFunctions)  # add the executable add_executable(Tutorial tutorial.cpp) target_link_libraries(Tutorial MathFunctions)자, 이제 MathFunctions 라이브러리를 선택적으로 사용해보자. 해당 튜토리얼에서는 선택적으로 사용할 이유는 없다. 하지만 제 3의 코드에 의존적인 거대한 라이브러리나 여러 라이브러리를 사용해야 할 수도 있다. 최상위 CMakeLists 파일에 선택적으로 라이브러리를 추가하기 위한 첫 과정은 다음과 같다.option(USE_MYMATH  &quot;Use tutorial provided math implementation&quot; ON)CMake GUI에 기본값인 ON이 노출되며, 사용자가 원하는 값으로 변경 가능하다. 여기서 설정한 값은 캐쉬에 저장되며 다음에 사용자가 다시 설정할 필요가 없다. MathFunctions 라이브러리를 선택적으로 빌드하고 링킹하기 위한 다음 변경사항은 최상위 CMakeLists 파일을 수정할 것이며 다음과 같다.# add the MathFunctions library?if (USE_MYMATH) include_directories(&quot;${PROJECT_SOURCE_DIR}/MathFunctions&quot;) add_subdirectory(MathFunctions) set(EXTRA_LIBS ${EXTRA_LIBS} MathFunctions)endif (USE_MYMATH)include_directories(${CMAKE_BINARY_DIR})# add the excutableadd_executable(Tutorial tutorial.cpp)target_link_libraries(Tutorial ${EXTRA_LIBS})MathFunctions를 컴파일하고 사용할지는 USE_MYMATH의 설정을 따른다. EXTRA_LIBS 변수는 이후 추가적인 선택적 라이브러리를 모아서 실행파일에 링크하기 위함이다. 큰 프로젝트에서 많은 선택적 컴포넌트들을 사용하기 위한 일반적 접근방법이다. 위의 대응하는 소스코드의 변화는 매우 직관적이다.#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;math.h&amp;gt;#include &quot;TutorialConfig.h&quot;#ifdef USE_MYMATH#include &amp;lt;mysqrt.h&amp;gt;#endifint main(int argc, char *argv[]){ if (argc &amp;lt; 2) { fprintf(stdout,&quot;%s Version %d.%d\\n&quot;, argv[0], Tutorial_VERSION_MAJOR, Tutorial_VERSION_MINOR); fprintf(stdout,&quot;Usage: %s number\\n&quot;,argv[0]); return 1; } double inputValue = atof(argv[1]);#ifdef USE_MYMATH double outputValue = mysqrt(inputValue);#else double outputValue = sqrt(inputValue);#endif fprintf(stdout, &quot;The square root of %g is %g\\n&quot;, inputValue, outputValue); return 0;}소스코드에서 USE_MYMATH를 또 사용하게 된다. 앞에서 TutorialConfig.h.in을 통해서 설정했듯이 USE_MYMATH는 CMake에서 소스코드로 제공된다. TutorialConfig.h.in에 아래 한줄을 추가해주면 된다.#cmakedefine USE_MYMATH" }, { "title": "[CMake] Tutorial Step1", "url": "/posts/cmake-tutorial-step1/", "categories": "", "tags": "build, cmake, tutorial", "date": "2016-06-03 01:45:14 +0900", "snippet": "항상 필요할때 필요한 부분만 찾아서 사용하던 CMake. 이번에 공부를 해보고자 CMake 사이트의 Tutorial을 번역하면서 예제를 따라 해보기로 했다.A Basic Starting Point(Step1)소스 코드로 부터 실행 파일을 만들수 있는 간다한 프로젝트에서 CMakeLists 파일에 단 2줄만 필요로 한다고 해보자. 이것은 우리 튜토리얼의 시작부분이다. CMakeLists 파일은 아래와 같다.cmake_minimum_required(VERSION 2.6) project(Tutorial) add_executable(Tutorial tutorial.cpp)해당 예제는 CMakeLists 파일에서 소문자 명령을 사용하고 있다. CMake에서는 대문자 소문자 대소문자 명령을 모두 지원한다. tutorial.cpp를 위한 간단한 예제는 아래와 같다.#include &amp;lt;stdio.h&amp;gt; #include &amp;lt;stdlib.h&amp;gt; #include &amp;lt;math.h&amp;gt;  int main(int argc, char *argv[]) {  if (argc &amp;lt; 2)  { fprintf(stdout, &quot;Usage: %s number\\n&quot;, argv[0]);  return 1;  }  double inputValue = atof(argv[1]);  double outputValue = sqrt(inputValue);  fprintf(stdout, &quot;The square root of %g is %g\\n&quot;, inputValue, outputValue); return 0; }Adding a Version Number and Configured Header File우리가 처음에 추가한 기능은 실행 파일과 프로젝트에 버전 정보를 추가하는 것이다. 버전 정보를 소스코드 안에서 제공할수 있지만, 반면 CMakeLists 파일은 좀 더 유연함을 제공할 수 있다. 버전 정보를 추가하기 위해서 CMakeLists 파일을 아래와 같이 수정해야 한다.cmake_minimum_required(VERSION 2.6)project(Tutorial)# The version number.set (Tutorial_VERSION_MAJOR 1)set (Tutorial_VERSION_MINOR 0)# configure a header file to pass some of the CMake settings# to the source codeconfigure_file( &quot;${PROJECT_SOURCE_DIR}/TutorialConfig.h.in&quot; &quot;${PROJECT_BINARY_DIR}/TutorialConfig.h&quot;)# add the binary tree to the search path for include files# so that we will find TutorialConfig.hinclude_directories(&quot;${PROJECT_BINARY_DIR}&quot;)# add the executableadd_executable(Tutorial tutorial.cpp test.cpp test.h)Configured file은 binary tree에 쓰여지기 때문에 include files을 찾기 위한 경로 목록에 디렉토리를 추가해줘야 한다. 그리고 TutorialConfig.h.in 파일을 source tree에 아래의 내용으로 생성한다.#define Tutorial_VERSION_MAJOR @Tutorial_VERSION_MAJOR@#define Tutorial_VERSION_MINOR @Tutorial_VERSION_MINOR@ CMake가 이 해더 파일을 설정했을 때, @Tutorial_VERSION_MAJOR@와 @Tutorial_VERSION_MINOR@의 값이 CMakeLists 파일의 값으로 수정이 된다. 다음으로 tutorial.cpp이 configured 파일을 포함하도록 수정하고 해당 버전 정보를 사용하도록 수정하겠다. 결과 코드는 아래와 같다.#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;math.h&amp;gt;#include &quot;TutorialConfig.h&quot;int main(int argc, char *argv[]){ if (argc &amp;lt; 2) { fprintf(stdout, &quot;%s Version %d.%d\\n&quot;, argv[0], Tutorial_VERSION_MAJOR, Tutorial_VERSION_MINOR); fprintf(stdout, &quot;Usage: %s number\\n&quot;, argv[0]); return 1; } double inputValue = atof(argv[1]); double outputValue = sqrt(inputValue); fprintf(stdout, &quot;The square root of %g is %g\\n&quot;, inputValue, outputValue); return 0;}주요한 변경은 TutorialConfig.h 해더 파일 포함과 버전 정보 출력이다." }, { "title": "Github Gist 코드 공유", "url": "/posts/github-gist-ecbd94eb939c-eab3b5ec9ca0/", "categories": "", "tags": "code highlighting, gist, github, 코드공유", "date": "2016-05-26 00:42:44 +0900", "snippet": "블로그에서 코드 공유를 위해서 WordPress Plugin을 사용했었다.예전 부터 Github에서 Gist란 서비스를 보긴 했지만, 사용해보지 않고 있었다.최근 Jetbrain 사의 IDE를 사용하면서 Gist만들기가 보여 Gist란 무엇인가란 궁금증이 생겨서 사용해봤다.내가 사용하고 느낀 Github Gist는 Code Snippet 공유이다.내가 올린 Code Snippet을 다른 사람들도 볼수 있고(Secret을 설정하지 않은 경우), 해당 Code Snippet 손 쉽게 공유할 수 있도록 도와 준다.1.Embed : 블로그와 같은 사이트에 코드를 손쉽게 볼수 있는 포멧으로 Embed를 해준다.2.Share : URL을 통해서 해당 코드를 공유하는 수단3.Clone via HTTPS : HTTPS를 통해서 Git 혹은 SVN으로 해당 코드를 공유할 수 있는 수단4.Clone via SSH : SSH를 통해서 Git로 해당 코드를 공유할 수 있는 수단위와 같이 간단한 코드 조각들을 블로그로 공유하거나, 예제 코드 같은 종류를 Github을 통해서 간단하게 공유할 수 있는 방법을 제공해준다.일단, Embed 방식이 나에게는 매우 매력적으로 보인다.IDE에서 간단한 코드를 제작 및 테스트 후, IDE를 통해서 Gist를 제작, 이후 블로그를 쓰는 시점에 Embed 방식을 통해서 블로그에 삽입하면 된다.아래는 간단히 테스트해본 것." }, { "title": "ld linker (링킹의 기본 이해)", "url": "/posts/ld-linker-eba781ed82b9ec9d98-eab8b0ebb3b8/", "categories": "", "tags": "", "date": "2013-03-31 08:35:17 +0900", "snippet": "ld는 리눅스 시스템에서 사용하는 링커이다. gcc는 collect2를 호출해 링킹 과정을 수행하는데, collect2는 내부적으로 진짜 링커인 ld를 호출해 링킹 과정을 수행한다. 링킹 과정이란?컴파일과 링킹에서 마지막 과정으로 조각한 오브젝트 파일들을 하나의 바이너리 이미지로 합치는 과정이다.링킹 과정은 결합과 재배치 딱 두마디로 요약할 수 있다. 링킹 과정 절차결합 과정은 ELF 포맷으로 되어 있는 각 오브젝트를 섹션 종류별로 하나의 오브젝트로 합치는 과정main.c#include &amp;amp;lt;stdio.h&amp;amp;gt;void func1();void func2();int var1 = 0x111111;int var2;int var3 = 0;int main() { static int var4 = 0x222222; static int var5; int var6; printf(&quot;This is main() function!n&quot;); func1(); func2(); return 0;}funcs.c#include &amp;amp;lt;stdio.h&amp;amp;gt;extern int var1, var2;int var8 = 0x333333;const int var9 = 0x12345678;int var10;void func1() { printf(&quot;This is func1() function!n&quot;); printf(&quot;var1 = 0x%X, var2=0x%Xn&quot;, var1, var2);}void func2() { printf(&quot;This is func2() function!n&quot;);}위의 소스 파일들을 가지고 아래의 명령을 내리면 다음과 같이 test 실행 파일이 생성된다.$ gcc -o test main.c funcs.c -v -save-tempsUsing built-in specs.Target: x86_64-redhat-linuxConfigured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-libgcj-multifile --enable-languages=c,c++,objc,obj-c++,java,fortran,ada --enable-java-awt=gtk --disable-dssi --disable-plugin --with-java-home=/usr/lib/jvm/java-1.4.2-gcj-1.4.2.0/jre --with-cpu=generic --host=x86_64-redhat-linuxThread model: posixgcc version 4.1.2 20080704 (Red Hat 4.1.2-52) /usr/libexec/gcc/x86_64-redhat-linux/4.1.2/cc1 -E -quiet -v main.c -mtune=generic -fpch-preprocess -o main.iignoring nonexistent directory &quot;/usr/lib/gcc/x86_64-redhat-linux/4.1.2/../../../../x86_64-redhat-linux/include&quot;#include &quot;...&quot; search starts here:#include &amp;amp;lt;...&amp;amp;gt; search starts here: /usr/local/include /usr/lib/gcc/x86_64-redhat-linux/4.1.2/include /usr/includeEnd of search list. /usr/libexec/gcc/x86_64-redhat-linux/4.1.2/cc1 -fpreprocessed main.i -quiet -dumpbase main.c -mtune=generic -auxbase main -version -o main.sGNU C version 4.1.2 20080704 (Red Hat 4.1.2-52) (x86_64-redhat-linux) compiled by GNU C version 4.1.2 20080704 (Red Hat 4.1.2-52).GGC heuristics: --param ggc-min-expand=64 --param ggc-min-heapsize=63690Compiler executable checksum: 0fb434bacb069a61dfb7d474a8bae350 as -V -Qy -o main.o main.sGNU assembler version 2.17.50.0.6-20.el5 (x86_64-redhat-linux) using BFD version 2.17.50.0.6-20.el5 20061020 /usr/libexec/gcc/x86_64-redhat-linux/4.1.2/cc1 -E -quiet -v funcs.c -mtune=generic -fpch-preprocess -o funcs.iignoring nonexistent directory &quot;/usr/lib/gcc/x86_64-redhat-linux/4.1.2/../../../../x86_64-redhat-linux/include&quot;#include &quot;...&quot; search starts here:#include &amp;amp;lt;...&amp;amp;gt; search starts here: /usr/local/include /usr/lib/gcc/x86_64-redhat-linux/4.1.2/include /usr/includeEnd of search list. /usr/libexec/gcc/x86_64-redhat-linux/4.1.2/cc1 -fpreprocessed funcs.i -quiet -dumpbase funcs.c -mtune=generic -auxbase funcs -version -o funcs.sGNU C version 4.1.2 20080704 (Red Hat 4.1.2-52) (x86_64-redhat-linux) compiled by GNU C version 4.1.2 20080704 (Red Hat 4.1.2-52).GGC heuristics: --param ggc-min-expand=64 --param ggc-min-heapsize=63690Compiler executable checksum: 0fb434bacb069a61dfb7d474a8bae350 as -V -Qy -o funcs.o funcs.sGNU assembler version 2.17.50.0.6-20.el5 (x86_64-redhat-linux) using BFD version 2.17.50.0.6-20.el5 20061020 /usr/libexec/gcc/x86_64-redhat-linux/4.1.2/collect2 --eh-frame-hdr -m elf_x86_64 --hash-style=gnu -dynamic-linker /lib64/ld-linux-x86-64.so.2 -o test /usr/lib/gcc/x86_64-redhat-linux/4.1.2/../../../../lib64/crt1.o /usr/lib/gcc/x86_64-redhat-linux/4.1.2/../../../../lib64/crti.o /usr/lib/gcc/x86_64-redhat-linux/4.1.2/crtbegin.o -L/usr/lib/gcc/x86_64-redhat-linux/4.1.2 -L/usr/lib/gcc/x86_64-redhat-linux/4.1.2 -L/usr/lib/gcc/x86_64-redhat-linux/4.1.2/../../../../lib64 -L/lib/../lib64 -L/usr/lib/../lib64 main.o funcs.o -lgcc --as-needed -lgcc_s --no-as-needed -lc -lgcc --as-needed -lgcc_s --no-as-needed /usr/lib/gcc/x86_64-redhat-linux/4.1.2/crtend.o /usr/lib/gcc/x86_64-redhat-linux/4.1.2/../../../../lib64/crtn.o위의 내용을 확인해보면 실제로 호출된 collect2는 실제 링커인 ld를 호출하는데, collect2가 받은 옵션들을 ld에게 그대로 넘겨 링킹한다. 따라서 위에서 collect2만 ld로 변경하면 그대로 링킹됨을 확인할 수 있다.그리고 main.c와 funcs.c를 컴파일해 test 실행 파일을 만드는데, 다음 그림과 같이 실제로는 많은 라이브러리와 오브젝트들이 함께 링킹됨을 확인할 수 있다.여기에서 어셈블된 *.o의 오브젝트 파일은 ELF 바이너리 포맷으로 되어있으며, ELF 바이너리 포맷은 .text 섹션, .data 섹션, bss 섹션, rodata 섹션 등으로 이루어 져 있다.결합 과정에서 각 오브젝트 파일의 각 세션이 종류별로 합쳐저 하나의 ELF 실행 파일을 구상한다. 이렇게 합쳐지는 순서는 별도의 링커 스크립트를 사용하지 않았다면 ld 명령에서 인자로 넣은 오브젝트 파일의 순서를 따른다.링킹 과정에서 합쳐지는 섹션들이 있고, 통합되거나 없어지는 섹션도 있다.두 번째로 재배치 과정이 일어난다. 재배치 과정은 결합 과정에서 합쳐진 각 센셕을 실제 코드에 맞게 조정하는 과정이라고 볼 수 있다.재배치 과정은 메모리에 바이너리 이미지가 로드될 위치를 시작으로 결합 과정이 끝난 바이너리에 각 심볼이 가지게 될 실제 주소를 구하고, 해당 심볼을 참조하는 부분에 대해 구한 주소를 설정하는 과정이다.심볼이란 주소를 가지는 모든 것을 말하는데, 이는 함수일수도 있고 변수일수도 있다.C소스에서 함수와 전역변수 등은 컴파일 과정이 끝난 어셈블리 코드에서 함수와 변수를 참조하기 위한 레이블(label)이란 것을 가진다.레이블은 함수명 또는 변수명 뒤에 콜란(:)이 붙은 형태인데, 해당 함수를 호출하거나 해당 변수를 load/store할 때는 이런 레이블을 참조한다. 이후 레이블은 모두 주소로 변경되고 레이블을 참조하는 부분 역시 레이블의 주소로 변경된다.레이블은 main.c 파일을 gcc -S main.c 명령으로 컴파일하면 다음과 같이 어셈블리 파일이 나오는데, 여기에서 확인할 수 있다. .file &quot;main.c&quot;.globl var1 .data .align 4 .type var1, @object .size var1, 4var1: .long 1118481.globl var3 .bss .align 4 .type var3, @object .size var3, 4var3: .zero 4 .local var5.2131 .comm var5.2131,4,4 .data .align 4 .type var4.2130, @object .size var4.2130, 4var4.2130: .long 2236962 .section .rodata.LC0: .string &quot;This is main() function!&quot; .text.globl main .type main, @functionmain:.LFB2: pushq %rbp.LCFI0: movq %rsp, %rbp...레이블과 같이 c 소스상에서 주소를 표현하는 모든 것을 심볼이라고 한다. 여기에서 심볼에 포함되는 것에는 레이블만 있는 것은 아니다.레이블은 어셈블리상의 주소표현이고, 링커 스크립트에 의해 생성되는 심볼도 있다.재배치 과정까지 끝아면 실행파일이 준비가 된다. ./test 명령을 내리면 bash 셸에서 exec() 시스템 콜을 사용해 test 실행 파일을 메모리에 로드하고, test 프로그램은 ld에 의해 정해진 주소에 로드되어 수행된다." }, { "title": "Proxy Pattern", "url": "/posts/174/", "categories": "", "tags": "", "date": "2012-04-28 12:57:34 +0900", "snippet": "프록시 패턴은 이름에서 알 수 있듯이 대리인 역활을 한다.대리인이라고 하지만 본 객체의 역활을 모두 수행하는 것은 아니다. 프록시는 본질적 작업을 본 객체에게 위임을 하여 수행한다.이를 통해서 본 객체의 본질적 작업을 수행하기 전과 후에 작업을 추가할 수 있다. 또한 본질적 작업이 무겁다면 그 작업이 필요로 할 때 초기화를 수행할 수 있다.Proxy의 종류로는Virtual Proxy : 인스턴스가 필요한 시점에 생성과 초기화를 실행함Remote Proxy : 네트워크 상대 쪽에 있음에도 불구 자신의 메소드인 것 처럼 사용, Java의 RMIAccess Proxy : 액세스 제한을 설정한 것 정해진 사용자이면 메소드 호출을 허가.일반적 구조예제 소스(출처 : Java 언어로 배우는 디자인 패턴 입문. 영진닷컴)public class ProxyPattern { public static void main(String[] args) { Printable p = new PrinterProxy(&quot;Alice&quot;); System.out.println(&quot;이름은 현재&quot; + p.getPrinterName() + &quot;입니다.&quot;); p.setPrinterName(&quot;Bob&quot;); System.out.println(&quot;이름은 현재&quot; + p.getPrinterName() + &quot;입니다.&quot;); p.print(&quot;Hello, world&quot;); }}class Printer implements Printable { private String name; public Printer() { heavyJob(&quot;Printer의 인스턴스를 생성 중&quot;); } public Printer(String name) { this.name = name; heavyJob(&quot;Printer의 인스턴스 (&quot; + name + &quot;)을 생성 중&quot;); } public void setPrinterName(String name) { this.name = name; } public String getPrinterName() { return name; } public void print(String string) { System.out.println(&quot;=== &quot; + name + &quot; ===&quot;); System.out.println(string); } private void heavyJob(String msg) { System.out.print(msg); for (int i = 0; i &amp;amp;amp;lt; 5; i++) { try { Thread.sleep(1000); } catch (InterruptedException e) { } System.out.print(&quot;.&quot;); } System.out.println(&quot;완료.&quot;); }}interface Printable { public void setPrinterName(String name); public String getPrinterName(); public void print(String string);}class PrinterProxy implements Printable { private String name; private Printer real; public PrinterProxy() { } public PrinterProxy(String name) { this.name = name; } public synchronized void setPrinterName(String name) { if (real != null) { real.setPrinterName(name); } this.name = name; } public String getPrinterName() { return name; } public void print(String string) { realize(); real.print(string); } private synchronized void realize() { if (real == null) { real = new Printer(name); } }}" }, { "title": "State Pattern", "url": "/posts/state-pattern/", "categories": "", "tags": "", "date": "2012-04-28 12:56:12 +0900", "snippet": "OOP에서 프로그램 할 대상을 ‘클래스’로 표현한다. 일반적으로 클래스는 구체적인 사물 또는 존재하지 않는 것을 표현한다. 여기에서 State Pattern은 ‘상태’를 클래스로 표현한 패턴이다. divide and conquer : 상태 클래스로 표현하여 복잡한 프로그램을 분할한다.State Pattern은 한 가지 상태에 대해서 처리 할 내용을 한 클래스에 모아둘 수 있다는 장점이 생긴다.이 장점은 C로 상태 전이도를 표현해 본 사람이라면 이 패턴이 매우 매력적으로 느껴질 것 같다. 상태 전이도를 표현하기 위해서는 수 많은 if문을 이용해서 다양한 경우를 분리해 내용을 처리해야 한다. 이러한 코드들도 한 메소드에 모이기 쉽다. 나중에 다시 코드를 들여다 본다면 그 내용을 알아보기 힘들 것이다.상태 전이도를 State Pattern으로 표현한다면, 한 가지 상태에서 처리해야 할 내용을 한 클래스에 모아둘 수 있다. 결국에 if문이 줄어들게 되고 복잡한 상태를 손쉽게 알아보며 코딩을 할 수 있다는 장점이 있다.2.상태 의존 처리Context는 State 인터페이스를 가지고 있다. 즉, 인터페이스는 상황에 따라 다른 상태 클래스를 가지게 되고 그 상태에 따른 처리를 할 수 있다.3.자기 모순에 빠지지 않는다.위에서 상태 전이도에 대해서 이야기를 했다. 여기에서 많은 상태가 존재한다면 다양한 상태에 대해서 처리를 모두 염두에 두고 프로그래밍을 해야 하므로 모순에 빠지기 쉽다.하지만 패턴을 이용한다면 한 상태에 집중하여 처리가 가능하므로 난이도가 낮아 지게 된다. 새로운 상태를 추가하기가 쉽다.모든 상태를 한 곳에 다 모아두었다면, 상태를 추가하거나 삭제하기 위해서는 그 코드에 대해서 정확히 이해를 해야하지만 실수하기도 쉽다.하지만 State 패턴은 상태를 추가하고 삭제하는 것은 State 인터페이스를 구현해 주면 된다.단, State 인터페이스를 구현한 상태 클래스에서 상태를 변경한다면 상태 클래스간 의존성이 높아지게 돼 추가, 삭제하는 것이 힘들어 지게 된다.일반적인 구조예제 소스(출처 : Java 언어로 배우는 디자인 패턴 입문. 영진닷컴)import java.awt.BorderLayout;import java.awt.Button;import java.awt.Color;import java.awt.Frame;import java.awt.Panel;import java.awt.TextArea;import java.awt.TextField;import java.awt.event.ActionEvent;import java.awt.event.ActionListener;public class StatePattern { public static void main(String[] args) { SafeFrame frame = new SafeFrame(&quot;State Sample&quot;); while (true) { for (int hour = 0; hour &amp;amp;lt; 24; hour++) { frame.setClock(hour); try { Thread.sleep(1000); } catch (InterruptedException e) { } } } }}interface State { public void doClock(Context context, int hour); public void doUse(Context context); public void doAlarm(Context context); public void doPhone(Context context);}class DayState implements State { private static DayState singleton = new DayState(); private DayState() { } public static State getInstance() { return singleton; } public void doClock(Context context, int hour) { if (hour &amp;amp;lt; 9 || 17 &amp;amp;lt;= hour) { context.changeState(NightState.getInstance()); } } public void doUse(Context context) { context.recordLog(&quot;금고사용(주간)&quot;); } public void doAlarm(Context context) { context.callSecurityCenter(&quot;비상벨(주간)&quot;); } public void doPhone(Context context) { context.callSecurityCenter(&quot;인반통화(주간)&quot;); } public String toString() { return &quot;(주간)&quot;; }}class NightState implements State { private static NightState singleton = new NightState(); private NightState() { } public static State getInstance() { return singleton; } public void doClock(Context context, int hour) { if (9 &amp;amp;lt;= hour &amp;amp;amp;&amp;amp;amp; hour &amp;amp;lt; 17) { context.changeState(DayState.getInstance()); } } public void doUse(Context context) { context.callSecurityCenter(&quot;비상 : 야간금고 사용!&quot;); } public void doAlarm(Context context) { context.callSecurityCenter(&quot;비상벨(야간)&quot;); } public void doPhone(Context context) { context.recordLog(&quot;야간통화 녹음&quot;); } public String toString() { return &quot;[야간]&quot;; }}interface Context { public void setClock(int hour); public void changeState(State state); public void callSecurityCenter(String msg); public void recordLog(String msg);}class SafeFrame extends Frame implements ActionListener, Context { private TextField textClock = new TextField(60); private TextArea textScreen = new TextArea(10, 60); private Button buttonUse = new Button(&quot;금고사용&quot;); private Button buttonAlarm = new Button(&quot;비상벨&quot;); private Button buttonPhone = new Button(&quot;일반통화&quot;); private Button buttonExit = new Button(&quot;종료&quot;); private State state = DayState.getInstance(); public SafeFrame(String title) { super(title); setBackground(Color.lightGray); setLayout(new BorderLayout()); add(textClock, BorderLayout.NORTH); textClock.setEditable(false); add(textScreen, BorderLayout.CENTER); textScreen.setEditable(false); Panel panel = new Panel(); panel.add(buttonUse); panel.add(buttonAlarm); panel.add(buttonPhone); panel.add(buttonExit); add(panel, BorderLayout.SOUTH); pack(); show(); buttonUse.addActionListener(this); buttonAlarm.addActionListener(this); buttonPhone.addActionListener(this); buttonExit.addActionListener(this); } public void actionPerformed(ActionEvent e) { System.out.println(e.toString()); if (e.getSource() == buttonUse) { state.doUse(this); } else if (e.getSource() == buttonAlarm) { state.doAlarm(this); } else if (e.getSource() == buttonPhone) { state.doPhone(this); } else if (e.getSource() == buttonExit) { System.exit(0); } else { System.out.println(&quot;?&quot;); } } public void setClock(int hour) { String clockstring = &quot;현재 시간은&quot;; if (hour &amp;amp;lt; 10) { clockstring += &quot;0&quot; + hour + &quot;:00&quot;; } else { clockstring += hour + &quot;:00&quot;; } System.out.println(clockstring); textClock.setText(clockstring); state.doClock(this, hour); } public void changeState(State state) { System.out.println(this.state + &quot;에서&quot; + state + &quot;로 상태가 변화했습니다.&quot;); this.state = state; } public void callSecurityCenter(String msg) { textScreen.append(&quot;call! &quot; + msg + &quot;n&quot;); } public void recordLog(String msg) { textScreen.append(&quot;record ...&quot; + msg + &quot;n&quot;); }}" }, { "title": "Common Lisp, Emacs, slime 셋팅하기", "url": "/posts/common-lisp-emacs-slime-ec858bed8c85ed9598eab/", "categories": "", "tags": "", "date": "2012-04-28 12:54:24 +0900", "snippet": "Common Lisp 개발을 위해서 에디터를 Emacs를 사용해보자.처음 사용해보는 에디터 Emacs는 기존 에디터들과 다르게 CL개발을 위해서 환경을 제공해준다. Emacs윈도우 버전 : http://www.gnu.org/software/emacs/windows/Getting-Emacs.html#Getting-Emacs맥 버전 : Carbon Emacs: http://homepage.mac.com/zenitani/emacs-e.htmlAquamacs Emacs: http://aquamacs.org/ CL 구현SBCL : http://sbcl.sourceforge.net/platform-table.html맥에서는 MacPorts 라는 패키지 관리자를 이용하자, 다음 명령을 터미널에서 수행.sudo port install sbcl 맥에서 패키지 관리자를 이용하여 설치하면 기본 설치 위치는/usr/local 밑에 설치가 된다. slimeslime : http://common-lisp.net/project/slime/맥 : sudo port install slime맥에서 패키지 관리자를 이용해 설치하면 기본 설치 위치는/opt/local/share/emacs/site-lisp/ 밑에 설치가 된다 설정Emacs 실행할때 홈디렉토리에서 .emacs 파일을 로딩하여 초기 설정을 한다.윈도우는 c;, 리눅스 계열은 자신의 계정 홈디렉토리 .emacs라는 파일을 참조한다.(add-to-list &#39;load-path &quot;/opt/local/share/emacs/site-lisp/slime/&quot;) (setq inferior-lisp-program &quot;/usr/local/bin/sbcl&quot;) (require &#39;slime) (slime-setup &#39;(slime-fancy slime-fuzzy slime-c-p-c)) (setq slime-net-coding-system &#39;utf-8-unix) 정상적으로 Emacs 가 실행되었다면, Alt+x 혹은 ESC+x 키를 누르면 나오는 프롬프트창에 slime 이라고 입력하고 엔터키를 누르면 몇 몇 파일들이 주욱 로딩되며 아래와 slime listener 창이 뜰 것 이다.이제 CL-USER&amp;gt; 라는 프롬프트를 볼 수 있을것이다.그러면 성공한 것이다." }, { "title": "SICP 연습문제 1.11", "url": "/posts/sicp-ec97b0ec8ab5ebacb8eca09c-1-11/", "categories": "", "tags": "", "date": "2012-04-28 12:53:15 +0900", "snippet": "n &amp;lt; 3 일 때 f(n) = n이고, n &amp;gt;= 3 일 때 f(n) = f(n-1) + 2f(n-2) + 3f(n-3)으로 정의한 함수가 있다.f의 프로시저를 되도는 프로세스를 만들고 반복 프로세스를 만들어 내는 프로시저도 만들어라.Recursive Process(define (f n)(if (&amp;amp;lt; n 3)n(+ (f (- n 1)) (* 2 (f(- n 2))) (* 3 (f(- n 3))))))Iterative Process(define (f2 n)(define (f-iter first second third counter)(if (= counter 3)(+ third (* 2 second) (* 3 first))(f-iter second third (+ third (* 2 second) (* 3 first)) (- counter 1))))(if (&amp;amp;lt; n 3)n(f-iter 0 1 2 n)))" }, { "title": "SICP 연습문제 1.10", "url": "/posts/sicp-ec97b0ec8ab5ebacb8eca09c-1-10/", "categories": "", "tags": "", "date": "2012-04-28 12:52:34 +0900", "snippet": "다음은 애커만 함수를 나타낸 프로시저이다.(define (A x y)(cond ((= y 0) 0)((= x 0) (* 2 y))((= y 1) 2)(else (A (- x 1)(A x (- y 1))))))&amp;amp;amp;nbsp;(define (f n) ( A 0 n))(define (g n) (A 1 n))(define (h n) (A 2 n))다음 f, g, h 프로시저의 기능을 수학으로 정의하라.f 프로시저는 2 * ng 프로시저는 2 ^ nh 프로시저는 2 ^ 2 ^ n" }, { "title": "SICP 연습문제 1.9", "url": "/posts/sicp-ec97b0ec8ab5ebacb8eca09c-1-9/", "categories": "", "tags": "", "date": "2012-04-28 12:51:28 +0900", "snippet": "다음 두 프로시저가 반복하는 프로세스인지 되도는 프로세스인지 구별하고 각 프로시저의 프로세스 과정을 밝혀라.프로시저 1(define (+ a b)(if (= a 0)b(inc (+ (dec a) b))))프로시저 2(define (+ a b)(if (= a 0)b(+ (dec a) (inc b))))우선, 프로시저 1의 프로세스 과정을 보면(+ 4 5)(inc (+ 3 5))(inc (inc (+ 2 5)))(inc (inc (inc (+ 1 5))))(inc (inc (inc (inc (+ 0 5)))))(inc (inc (inc (inc (5)))))(inc (inc (inc 6)))(inc (inc 7))(inc 8)9결과 적으로 프로시저 1은 되도는 프로세스 과정이다.다음으로 프로시저 2의 프로세스 과정을 보면(+ 4 5)(+ 3 6)(+ 2 7)(+ 1 8)(+ 0 9)9결과 적으로 프로시저 2는 반복하는 프로세스 과정이다." }, { "title": "Java I/O Stream", "url": "/posts/java-io-stream/", "categories": "", "tags": "", "date": "2011-12-12 03:22:08 +0900", "snippet": "I/O를 처리하는 방법Byte StreamsInputStream과 OutputStream은 8-bit로 입력과 출력을 한다 생성 입력 및 출력 자원 반환 FileInputStream in = null;FileOutputStream out = null;in = new FileInputStream(“example1.txt”);out = new FileOutputStream(“example2.txt”); int c = in.read();out.write(); in.close();out.close(); Character StreamsJDK 1.1 이후에 16-bit가 필요한 Unicode가 소개 되었지만, 기존의 InputStream과 OutputStream 그리고 그 subclass들은 8-bit의 byte stream만 지원을 했다. 이에 JDK 1.1에서 java.io.Reader와 java.io.Writer 그리고 그 subclass들이 추가 되었고 Character Stream을 지원을 한다. 생성 입력 및 출력 자원 반환 FileReader in = null;FileWriter out = null;in = new FileReader(“example1.txt”);out = new FileWriter(“example2.txt”); int c = in.read();out.write(); in.close();out.close(); Stream ChainingStream Chaining은 I/O stream class의 장점이다.Stream Chaining은 각 stream class에 연결을 하여 데이터를 얻는 방법이다.각 class는 정해진 일을 수행하고, 다음 연결된 class에게 forward한다.예를 들어서 입력 받은 Data를 압축하고, 암호화해서 파일에 저장한다고 하자.그림과 같이 작업은 수행이 된다.그리고 Stream Chaining을 한 코드는 이렇다.GZIPOutputStream gos = new GZIPOutputStream(new CryptOutputStream(new FileOutputStream(“example.txt”)));위의 작업을 수행하는 코드는 이렇다.gos.write(“저장할 내용”);Design PatternStream Chaining은 어떻게 가능할까?Stream Chaining 기법은 Input, OuputStream과 Reader, Writer와 subclass 간의 class 관계에서 가능하게 된다.이러한 관계를 Decorator Pattern이라고 한다. 일반적 Decorator Pattern의 구조 InputStream에서 Decorator Pattern 구조 Reader도 FilterInputStream과 동일하게 FilterReader와 BufferedReader가 Abstract Decorator이다. Decorator Pattern의 Forward 과정결과InputStream에서 Buffer가 달린 InputStream과 각 라인에 0에서부터 카운트하는 LineNumberInputStream 등의 기능들을 InputStream이라는 객체에 각 기능을 장식(Decorator)을 달아서 자신이 원하는 기능의 InputStream을 사용할 수 있다.각 Concrete Decorator Class들은 InputStream의 기능을 사용하여 추가할 기능만 추가 구현된 Class이다.결과적으로 코드 재사용성을 높일 수 있다.기존 Byte Stream과 Character Stream의 차이A. 문제점Java의 Standard Input과 output은 System.in과 System.out으로 미리 정의되어 있다.하지만 System.in과 System.out은 InputStream과 OutputStream 객체이다. 그러면, Byte Stream인데 Character Stream과 다루는 bit의 양이 각 8-bit와 16-bit로 차이가 난다.게다가, 암호화를 위해서 제공되는 CipherInputStream과 압축을 위해서 제공되는 ZipInputStream도 Byte Stream이다.하지만, 기존의 이러한 Byte Stream을 두고 Character Stream을 위해서 Standard Input과 압축, 암호화를 위한 Class를 제공하지 않는다.B. 해결책이러한 차이점이 있지만, 기존의 Class를 버리지 않았다. 오히려 그 Byte Stream Class를 재사용하는 방법으로 Character Stream에도 다양한 기능을 제공한다.그 해결책으로 Bridge Pattern으로 되어있다.일반적 Bridge Pattern의 구조Writer의 Bridge의 구조C. 결과기존의 Byte Stream인 InputStream을 StreamEncoder에 composition을 하고, 그 StreamEncoder를 OutputStreamWriter에 composition을 하였다. Writer와 그 subclass는 이 Bridge Class인 OutputStreamWriter를 인자로 받아서 입/출력 처리를 한다.결과적으로 기존의 Byte Stream과 Character Stream의 차이를 극복하게 됐다." }, { "title": "SICP 연습문제 1.8", "url": "/posts/sicp-ec97b0ec8ab5ebacb8eca09c-1-8/", "categories": "", "tags": "", "date": "2011-12-10 08:52:54 +0900", "snippet": "cube root 를 위한 Newton’s method는 아래의 수식을 기반으로 한다. y의 값은 x의 cube root의 근사 값이고 다음 수식을 수행할때 마다 더욱 근사치에 가까운 근사 값으로 다가간다.위의 수식을 이용해서 cube-root를 구현해라, 단, square-root procedure와 유사하게 cube-root를 구현해라.결과(define (cube-root x)(cube-root-iter 1.0 x))(define (cube-root-iter guess x)(if (good-enough? guess x)guess(cube-root-iter (improve guess x)x)))(define (improve guess x)(one-third (/ x (square guess)) (* 2 guess)))(define (square x)(* x x))(define (cube x)(* x x x))(define (one-third x y)(/ (+ x y) 3))(define (good-enough? guess x)(&amp;amp;lt; (abs (- (improve guess x) guess)) (* guess 0.000001)))" }, { "title": "SICP 연습문제 1.7", "url": "/posts/sicp-ec97b0ec8ab5ebacb8eca09c-1-7/", "categories": "", "tags": "", "date": "2011-12-10 08:52:20 +0900", "snippet": "good-enough? 가 매우 작은 숫자의 square roots를 계산하는데 효과적이지 못 하다고 한다.그리고 real computer에서 산술 연산은 제한된 정확도에서 수행이 된다, 이것 때문에 매우 큰 숫자를 테스트하는 것이 부적당하다고 한다.그렇다면, 큰 숫자나 작은 숫자에서 테스트가 실패하는 경우를 찾아 보기로 했다.값이 작을 경우기존 방법의 결과 정답 결과의 차이가 200%가 넘게 생긴다는 것을 알 수가 있다.값이 클 경우기존의 방법의 결과값을 입력 후 밑에 있는 졸라맨은 계속해서 달리지만, 결과는 볼 수가 없었다.정답의 근사 값 우선 good-enough?를 보면, guess의 값을 제곱하여 실제 값과의 차이가 0.001인지 비교한다.즉, 0.001이란 값은 작은 값을 계산할 경우의 큰 값이므로 오차가 많이 생기게 된다.그리고 큰 값을 계산할 경우에는 컴퓨터의 제한된 정확도의 계산으로 인해서 0.001 차이보다 크게 발생할 경우에 무한 루프에 빠지는 결과를 발생하게 되는 문제점을 가지고 있다.다음은 이러한 문제를 해결하기 위한 good-enough?이다.(define (good-enough? guess x)(&amp;amp;lt; (abs (- (improve guess x) guess)) (abs (* guess 0.00001))))" }, { "title": "SICP 연습문제 1.6", "url": "/posts/sicp-ec97b0ec8ab5ebacb8eca09c-1-6/", "categories": "", "tags": "", "date": "2011-12-10 08:51:45 +0900", "snippet": "제곱 근을 구하기 위해서 뉴튼 법을 사용한다. 여기에 그 예제 소스가 있다.(define (sqrt-iter guess x)(if (good-enough? guess x)guess(sqrt-iter (improve guess x)x)))(define (improve guess x)(average guess (/ x guess)))(define (average x y)(/ (+ x y) 2))(define (good-enough? guess x)(&amp;amp;lt; (abs (- (square guess) x)) 0.001))(define (sqrt2 x)(sqrt-iter 1.0 x))(define (square x)(* x x))여기에서 if문을 cond로 만든 프로시저로 대체 하면 어떤 결과가 나오는가 하는게 문제이다.(define (new-if predicate then-clause else-clause)(cond (predicate then-clause)(else else-clause)))제시한 프로시저는 다음과 같다. 그리고 if를 new-if로 대체 후, 실행한다면 프로시저는 무한 루프에 빠진다. applicative order evaluation이기 때문에 프로시저는 각 인자의 값을 먼저 계산하러 들어 갈 것이다.여기에서 new-if를 사용하는 sqrt-iter는 재귀 호출로 자신의 sqrt-iter을 계속 해서 호출하게 된다. 즉, if문으로 good-enough?의 결과에 따라 sqrt-iter이 계산이 안 되던 것이 sqrt-iter을 계속해서 계산하여 들어가게 되어 무한 루프에 빠지게 된다." }, { "title": "SICP 연습문제 1.5", "url": "/posts/sicp-ec97b0ec8ab5ebacb8eca09c-1-5/", "categories": "", "tags": "", "date": "2011-12-10 08:51:08 +0900", "snippet": "applicative order evaluation과 normal-order evaluation의 차이를 묻는 문제이다.(define (p) (p))(define (test x y)(if (= x 0)0y))위와 같이 2개의 프로시저를 정의한다.(test 0 (p))그리고 다음의 식 실행 시, applicative order evaluation과 normal-order evaluation의 각 결과는 무엇인지를 묻는 문제.applicative order evaluation인 lisp의 경우에는 무한 루프에 빠지게 된다.applicative order evaluation은 인자를 먼저 계산을 하는 계산법이기 때문이다.즉, (test 0 (p))에서 test 프로시저 보다는 p 프로시저를 먼저 계산을 한다. 하지만 p 프로시저는 자기 자신을 종료 조건 없이 호출을 하므로, 무한 루프에 빠지게 된다.nomal-order evaluation은 적합한 언어를 선택을 못 해서 돌려보지는 못 했지만, 보나 마나 결과는 0이 나온다.이 계산법은 바깥 프로시저에서 안으로 모든 프로시저를 풀어 놓고 계산을 하는 계산법이다.(test 0 (p))는 (if (= 0 0) 0 (p))와 동일 하다. if 문은 참이 되므로 0을 return 하게 된다. 즉, p를 계산하지 않는다." }, { "title": "SICP 연습문제 1.4", "url": "/posts/sicp-ec97b0ec8ab5ebacb8eca09c-1-4/", "categories": "", "tags": "", "date": "2011-12-10 08:50:30 +0900", "snippet": "combination에  연산자 자리에 compound expression이 다시 와도 규칙에 따라 식을 구할 수 있다.다음의 식은 연습문제에 나온 식이다.(define (a-plus-abs-b a b)((if (&amp;amp;gt; b 0) + -) a b))위의 식을 살펴 보면 ((if (&amp;gt; b 0) + -) a b)) 부분을 볼 수 있다. (if (&amp;gt; b 0) + -)를 연산자 자리에 위치하며, 이 식의 결과로 연산자가 +나 -를 정해서 a와 b의 값을 계산을 하게 된다. 그 결과로 a + b 의 결과를 얻을 수 있다. 식의 연산자 자리의 복합 식을 사용할 수 있다는 것을 보여주는 흥미로운 예제이다." }, { "title": "ThreadLocal", "url": "/posts/threadlocal/", "categories": "", "tags": "", "date": "2011-12-10 08:49:15 +0900", "snippet": "스레드 내보의 값과 값을 가지고 있는 객체를 연결해 스레드 한정 기법을 적용할수 있도록 도와주는 형식적인 방법으로 ThreadLocal이 있다.이 ThreadLocal은 호출하는 스레드마다 다른 값을 사용할 수 있도록 관리해준다.즉, ThreadLocal의 get 메소드를 호출하면 현재 실행 중인 스레드에서 최근에 set 메소드로 저장했던 값을 가지고 온다.이러한 ThreadLocal은 여러 스레드에서 변수가 임의로 공유되는 상황을 막기 위해서 자주 사용이 된다.예를 들어 데이터베이스에 접속할 때 매번 Connection 인스턴스를 생성하는 부담을 줄이고자, 시작 시점에 Connection 인스턴스를 전역 변수에 넣어두고 계속해서 사용하는 방법을 사용하기도 한다. 하지만 JDBC 연결은 스레드에 안전하지 않기 때문에 적절한 동기화 없이 사용할 수 없다.다음은 이러한 상황에서 ThreadLocal을 이용해서 해결한 예이다.private static ThreadLocal&amp;lt;Connection&amp;gt; connectionHolder = new ThreadLocal&amp;lt;Connection&amp;gt;() {    public Connection initialValue() {        return DriverManager.getConnection(DB_URL);    }};public static Connection getConnection() {    return connectionHolder.get();}개념적으로 본다면, ThreadLocal 클래스는 Map&amp;lt;Thread, T&amp;gt;라는 자료 구조로 구성되어 있다고 생각할 수 있다. 하지만, 실제로 이렇게 구성된 것은 아니다. 결과적으로 ThreadLocal은 스레드 안전성을 보장할 수 있다.ThreadLocal을 사용하면 하나의 스레드에서 동일한 값을 공유하면서, 스레드 한정을 유지할 수 있어서 편리하지만, 이것을 사용하는 코드는 해당 프레임웍에 대한 의존성을 갖게 된다. ThreadLocal 은 전역변수는 아니지만 전역 변수처럼 동작하기 때문에 코드의 재사용성을 떨어트리고 SideEffect를 유발할 수 있다." }, { "title": "병렬프로그램) Stale Data", "url": "/posts/%EB%B3%91%EB%A0%AC%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8)-Stale-Data/", "categories": "", "tags": "", "date": "2011-12-10 08:47:51 +0900", "snippet": "단일 스레드를 사용하는 환경에서 특정 변수를 저장하고,그 값을 읽으면 이전에 저장 했던 값을 가지고올수 있다. 하지만, 여러 스레드가 작동하는 환경에서는 변수에 값을 저장하고 읽어 오는 코드가 여러 스레드에 의해서 실행이 된다면 상황은 다르다.public class NoVisibility { private static boolean ready; private static int number; private static class ReaderThread extends Thread { public void run() { while(!ready) Thread.yield(); System.out.println(number); } } public static void main(String[] args) { new ReaderThread().start(); number = 43; ready = true; }}위의 소스코드를 본다면 43이 출력할 것이라고 생각할 수 있다.하지만, ready 변수의 값을 ReaderThread에서 영원히 false로 확인을 해서 무한 루프에 돌 수도 있다.아니면, ready의 값을 먼저 읽어들여 number의 값이 지정이 안 되어있을 수도 있다.이러한 현상을 재배치라고 하며, 동기화를 하지 않는다면, 컴파일러나 프로세서, JVM이 실행되는 순서를 임의로 바꿔 실행하는 이상한 경우가 발생하기도 한다." }, { "title": "Memento Pattern", "url": "/posts/memento-pattern/", "categories": "", "tags": "", "date": "2011-12-10 08:44:03 +0900", "snippet": "Memento Pattern 은 객체의 이전 상태를 저장하기 위한 패턴이다.객체의 상태를 저장하거나 복원하기 위해서는 객체 내부의 정보를 자유롭게 액세스할 수 있어야 한다.특히 복원하기 위해서는 Visibility가 객체 밖으로 공개되지 않은 Attribute는 쓸수가 없으므로 복원할 수가 없다. 그렇다고 Visibility를 넓힌다면 캡슐화를 약하게 만드는 요인이 된다.Memento Pattern은 객체의 캡슐화를 강화시키면서 상태 값을 저장하고 복원할 수 있도록 해준다.Memento Pattern은 세 가지 역활이 등장한다.Originator : State를 가지고 있는 객체로 자신의 상태를 저장하기 위해서 Memento를 사용한다.Memento : Originator의 상태를 저장하지만, 내부 정보를 외부에 공개하지 않는다. Originator의 내부 클래스로 구현할 수도 있다.CareTaker : Originator의 저장된 상태인 Memento를 저장하여 관리해 준다. 하지만 Memento의 내부 정보를 액세스할 수 없다.** 아래의 예제 소스에서는 Main이 Originator의 역활이고 Memento와 Originator는 다른 페키지에 존재한다. 편집 상 패키지가 표시되어 있지 않다.일반적인 구조예제 소스(출처 : Java 언어로 배우는 디자인 패턴 입문. 영진닷컴)public class MementoPattern { public static void main(String[] args) { Gamer gamer = new Gamer(100); Memento memento = gamer.createMemento(); for(int i = 0; i &amp;amp;lt; 100; i++) { System.out.println(&quot;==== &quot; + i); System.out.println(&quot;현상:&quot; + gamer); gamer.bet(); System.out.println(&quot;소지금은&quot; + gamer.getMoney() + &quot;원이 되었습니다.&quot;); if (gamer.getMoney() &amp;amp;gt; memento.getMoney()) { System.out.println(&quot; (많이 증가했으므로 현재의 상태를 저장하자)&quot;); memento = gamer.createMemento(); } else if (gamer.getMoney() &amp;amp;lt; memento.getMoney() / 2) { System.out.println(&quot; (많이 감소했으므로 이전의 상태로 복원하자)&quot;); gamer.restoreMemento(memento); } try { Thread.sleep(1000); } catch (InterruptedException e) { } System.out.println(&quot;&quot;); } }}public class Memento { int money; ArrayList&amp;amp;lt;String&amp;amp;gt; fruits; public int getMoney() { return money; } Memento(int money) { this.money = money; this.fruits = new ArrayList&amp;amp;lt;String&amp;amp;gt;(); } void addFruit(String fruit) { fruits.add(fruit); } List getFruits() { return (List)fruits.clone(); }}public class Gamer { private int money; private ArrayList&amp;amp;lt;String&amp;amp;gt; fruits = new ArrayList&amp;amp;lt;String&amp;amp;gt;(); private Random random = new Random(); private static String[] fruitsname = { &quot;사과&quot;, &quot;포도&quot;, &quot;바나나&quot;, &quot;귤&quot;, }; public Gamer(int money) { this.money = money; } public int getMoney() { return money; } public void bet() { int dice = random.nextInt(6) + 1; if(dice == 1) { money += 100; System.out.println(&quot;소지금이 증가했습니다.&quot;); } else if (dice == 2) { money /= 2; System.out.println(&quot;소지금이 절반이 되었습니다.&quot;); } else if (dice == 6) { String f = getFruit(); System.out.println(&quot;과일(&quot; + f + &quot;)을 받았습니다.&quot;); fruits.add(f); } else { System.out.println(&quot;변한 것이 없습니다.&quot;); } } public Memento createMemento() { Memento m = new Memento(money); Iterator&amp;amp;lt;String&amp;amp;gt; it = fruits.iterator(); while(it.hasNext()) { String f = (String)it.next(); if (f.startsWith(&quot;맛있는 &quot;)) { m.addFruit(f); } } return m; } public void restoreMemento(Memento memento) { this.money = memento.money; this.fruits = (ArrayList)memento.getFruits(); } public String toString() { return &quot;[money = &quot; + money + &quot;, fruits = &quot; + fruits + &quot;]&quot;; } private String getFruit() { String prefix = &quot;&quot;; if (random.nextBoolean()) { prefix = &quot;맛있는 &quot;; } return prefix + fruitsname[random.nextInt(fruitsname.length)]; }}" }, { "title": "Observer Pattern", "url": "/posts/observer-pattern/", "categories": "", "tags": "", "date": "2011-12-10 08:43:17 +0900", "snippet": "Observer Pattern은 말 그대로 무언가 관찰 하는데 유용한 패턴이다.Subject라는 자신의 상태 값을 가지고 있는 객체가 존재 한다. 그리고 Observer라는 Subject의 상태 값을 관찰하는 개체가 존재한다.Observer가 Subject 객체를 관찰한다고 생각할 수 있지만, 실제로는 Subject가 자신의 상태가 변경이 되면 Observer에게 통보를 한다. 이렇게 통보를 받은 Observer는 Subject의 상태가 변경됐다는 것을 알고 Subject의 상태를 읽어올 수 있게 된다.일반적으로 분산 이벤트 처리를 위해서 많이 사용된다고 한다.Java API에서 Oserver 패턴을 지원한다.Observer : java.util.ObserverSubject : java.util.ObservableJava API를 사용하여 구현 시 참고사항1. java.util.Observer-update(Observable o, Object arg) :Observable은 어떤 Subject에서 상태가 변했는지 알 수 있다.Object는 변경 된 상태라고 생각할 수 있다.2. java.util.Observable-addObserver(Obserber o) :이 메소드를 통해서 이 subject를 관찰할 Observer를 등록-setChanged() :이 메소드를 통해서 현제 subject의 상태가 변경 됐다는 것을 표시, 호출하지 않으면 알려지지 않음-notifyObserver() :이 메소드를 통해서 등록된 모든 Observer에게 통보함 일반적인 구조 &amp;lt;a href=&quot;http://i0.wp.com/appchemist.net/wp-content/uploads/2011/12/observer.png&quot;&amp;gt;&amp;lt;img src=&quot;http://i0.wp.com/appchemist.net/wp-content/uploads/2011/12/observer.png?resize=720%2C298&quot; alt=&quot;observer&quot; class=&quot;aligncenter size-full wp-image-640&quot; data-recalc-dims=&quot;1&quot;/&amp;gt;&amp;lt;/a&amp;gt;예제소스(출처 : Java 언어로 배우는 디자인 패턴 입문. 영진닷컴)public class ObserverPattern { public static void main(String[] args) { NumberGenerator generator = new RandomNumberGenerator(); Observer observer1 = new DigitObserver(); Observer observer2 = new GraphObserver(); generator.addObserver(observer1); generator.addObserver(observer2); generator.execute(); }}interface Observer { public void update(NumberGenerator generator);}abstract class NumberGenerator { private List&amp;amp;lt;Observer&amp;amp;gt; observers = new ArrayList&amp;amp;lt;Observer&amp;amp;gt;(); public void addObserver(Observer observer) { observers.add(observer); } public void deleteObserver(Observer observer) { observers.remove(observer); } public void notifyObservers() { Iterator&amp;amp;lt;Observer&amp;amp;gt; it = observers.iterator(); while(it.hasNext()) { Observer o = it.next(); o.update(this); } } public abstract int getNumber(); public abstract void execute();}class RandomNumberGenerator extends NumberGenerator { private Random random = new Random(); private int number; public int getNumber() { return number; } public void execute() { for(int i = 0; i &amp;amp;lt; 20; i++) { number = random.nextInt(50); notifyObservers(); } }}class DigitObserver implements Observer { public void update(NumberGenerator generator) { System.out.println(&quot;DigitObserver:&quot; + generator.getNumber()); try { Thread.sleep(100); } catch(InterruptedException e) { } }}class GraphObserver implements Observer { public void update(NumberGenerator generator) { System.out.print(&quot;GraphObserver:&quot;); int count = generator.getNumber(); for(int i = 0; i &amp;amp;lt; count; i++) { System.out.print(&quot;*&quot;); } System.out.println(&quot;&quot;); try { Thread.sleep(100); } catch (InterruptedException e) { } }}" }, { "title": "Mediator Pattern", "url": "/posts/mediator-pattern/", "categories": "", "tags": "", "date": "2011-12-10 08:42:35 +0900", "snippet": "여러 객체들이 서로 협력을 할 필요가 있을 때, Mediator Pattern이 유용하게 사용할 수 있다.만약 Mediator Pattern을 사용하지 않고 여러 객체들이 서로 협력을 하기 위해서는 서로간의 연결이 필요하게 되고 이 연결은 복잡해지기 쉽다.Mediator Pattern을 이용한다면, 복잡한 연결을 Mediator라는 중재자를 통해서 여러 객체가 협력하도록 할 수있다. 즉 1:N 연결이 되므로 협력이 더욱 쉬워진다.Mediator Pattern에서 객체 간의 협력과 관련된 부분은 Mediator에 한정이 되어 있게 된다. 여기에서 협력과 관련된 부분은 프로그램에 의존적인 부분이며, 재이용성이 낮아진다.하지만, Mediator가 관리하는 Colleague들 즉 서로 협력하기 위한 객체들은 재이용성이 높아져 다른 프로그램에서도 재사용할 수가 있게 된다.일반적인 구조예제 소스 (출처 : Java 언어로 배우는 디자인 패턴 입문. 영진닷컴)public class MediatorPattern { static public void main(String args[]) { new LoginFrame(&quot;Mediator Sample&quot;); }}interface Mediator { public void createColleagues(); public void colleagueChanged();}interface Colleague { public void setMediator(Mediator mediator); public void setColleagueEnabled(boolean enabled);}class ColleagueButton extends Button implements Colleague { private Mediator mediator; public ColleagueButton(String caption) { super(caption); } public void setMediator(Mediator mediator) { this.mediator = mediator; } public void setColleagueEnabled(boolean enabled) { setEnabled(enabled); }}class ColleagueTextField extends TextField implements TextListener, Colleague { private Mediator mediator; public ColleagueTextField(String text, int columns) { super(text, columns); } public void setMediator(Mediator mediator) { this.mediator = mediator; } public void setColleagueEnabled(boolean enabled) { setEnabled(enabled); setBackground(enabled ? Color.white : Color.lightGray); } public void textValueChanged(TextEvent e) { mediator.colleagueChanged(); }}class ColleagueCheckbox extends Checkbox implements ItemListener, Colleague { private Mediator mediator; public ColleagueCheckbox(String caption, CheckboxGroup group, boolean state) { super(caption, group, state); } public void setMediator(Mediator mediator) { this.mediator = mediator; } public void setColleagueEnabled(boolean enabled) { setEnabled(enabled); } public void itemStateChanged(ItemEvent e) { mediator.colleagueChanged(); }}class LoginFrame extends Frame implements ActionListener, Mediator { private ColleagueCheckbox checkGuest; private ColleagueCheckbox checkLogin; private ColleagueTextField textUser; private ColleagueTextField textPass; private ColleagueButton buttonOk; private ColleagueButton buttonCancel; public LoginFrame(String title) { super(title); setBackground(Color.lightGray); setLayout(new GridLayout(4, 2)); createColleagues(); add(checkGuest); add(checkLogin); add(new Label(&quot;Username : &quot;)); add(textUser); add(new Label(&quot;Password : &quot;)); add(textPass); add(buttonOk); add(buttonCancel); colleagueChanged(); pack(); show(); } public void createColleagues() { CheckboxGroup g = new CheckboxGroup(); checkGuest = new ColleagueCheckbox(&quot;Guest&quot;, g, true); checkLogin = new ColleagueCheckbox(&quot;Login&quot;, g, false); textUser = new ColleagueTextField(&quot; &quot;, 10); textPass = new ColleagueTextField(&quot; &quot;, 10); textPass.setEchoChar(&#39;*&#39;); buttonOk = new ColleagueButton(&quot;OK&quot;); buttonCancel = new ColleagueButton(&quot;Cancel&quot;); checkGuest.setMediator(this); checkLogin.setMediator(this); textUser.setMediator(this); textPass.setMediator(this); buttonOk.setMediator(this); buttonCancel.setMediator(this); checkGuest.addItemListener(checkGuest); checkLogin.addItemListener(checkLogin); textUser.addTextListener(textUser); textPass.addTextListener(textPass); buttonOk.addActionListener(this); buttonCancel.addActionListener(this); } public void colleagueChanged() { if(checkGuest.getState()) { textUser.setColleagueEnabled(false); textPass.setColleagueEnabled(false); buttonOk.setColleagueEnabled(true); } else { textUser.setColleagueEnabled(true); userpassChanged(); } } private void userpassChanged() { if(textUser.getText().length() &amp;amp;gt; 0) { textPass.setColleagueEnabled(true); if(textPass.getText().length() &amp;amp;gt; 0) { buttonOk.setColleagueEnabled(true); } else { buttonOk.setColleagueEnabled(false); } } else { textPass.setColleagueEnabled(false); buttonOk.setColleagueEnabled(false); } } public void actionPerformed(ActionEvent e) { System.out.println(e.toString()); System.exit(0); }}" }, { "title": "Chain Of Responsibility Pattern", "url": "/posts/chain-of-responsibility-pattern/", "categories": "", "tags": "", "date": "2011-12-10 08:41:44 +0900", "snippet": "Chain Of Responsibility Pattern은 복수의 객체를 연결하여, 연결한 객체들을 차례로 돌며 처리하는 방법이다.여기에서 연결된 객체들은 넘어오는 요구 객체를 처리할 수 있을 때 까지 다음에 연결된 객체에게 일을 넘깁니다. 즉, 요구 객체를 적절하게 처리할 수 있는 처리 객체가 적절하게 처리를 할 수 있습니다.몇몇 경우에, 처리 객체가 상위의 처리 객체와 명령을 호출하여 작은 파트의 명령을 해결하기 위해 재귀적으로 실행되기도 한다. 이 경우에 재귀는 명령이 처리되거나 모든 트리가 탐색될때까지 진행이 됩니다. 예를 들어 XML 인터프리터를 들 수가 잇다.즉, 요청하는 쪽과 처리하는 쪽의 연결을 우연하게 해서 각 객체를 부품으로 독립시킬 수 있습니다. 그리고 상황에 따라 처리할 객체가 변하는 프로그램도 작성가능합니다.일반적인 구조예제 소스(출처 : Java 언어로 배우는 디자인 패턴 입문. 영진닷컴)class Trouble { private int number; public Trouble(int number) { this.number = number; } public int getNumber() { return number; } public String toString() { return &quot;[Trouble &quot; + number + &quot;]&quot;; }}abstract class Support { private String name; private Support next; public Support(String name) { this.name = name; } public Support setNext(Support next) { this.next = next; return next; } public final void support(Trouble trouble) { if(resolve(trouble)) { done(trouble); } else if (next != null) { next.support(trouble); } else { fail(trouble); } } protected abstract boolean resolve(Trouble trouble); protected void done(Trouble trouble) { System.out.println(trouble + &quot; is resolved by &quot; + this + &quot;.&quot;); } protected void fail(Trouble trouble) { System.out.println(trouble + &quot; cannot be resolved&quot;); }}class NoSupport extends Support { public NoSupport(String name) { super(name); } protected boolean resolve(Trouble trouble) { return false; }}class LimitSupport extends Support { private int limit; public LimitSupport(String name, int limit) { super(name); this.limit = limit; } protected boolean resolve(Trouble trouble) { if(trouble.getNumber() &amp;amp;lt; limit) { return true; } else { return false; } }}class OddSupport extends Support { public OddSupport(String name) { super(name); } protected boolean resolve(Trouble trouble) { if(trouble.getNumber() % 2 == 1) { return true; } else { return false; } }}class SpecialSupport extends Support { private int number; public SpecialSupport(String name, int number) { super(name); this.number = number; } protected boolean resolve(Trouble trouble) { if(trouble.getNumber() == number) { return true; } else { return false; } }}" }, { "title": "Visitor Pattern", "url": "/posts/visitor-pattern/", "categories": "", "tags": "", "date": "2011-12-10 08:41:09 +0900", "snippet": "Visitor Pattern은 알고리즘이 처리하는 객체 집합에서 알고리즘은 분리한 Pattern이다.알고리즘을 분리한 결과 새로운 Operation을 추가하기 위해서 객체 집합을 수정할 필요가 없어졌다.즉, Open-Closed Principle을 만족할 수 있습니다. Open-Closed Principle은 처리 연산에 대해서는 확장할 수 있지만, 기존 클래스를 수정하지 않아도 된다.장점이 있으면 단점이 있듯이 Visitor Pattern을 보면 처리의 흐름을 이해하기가 힘들다. 그리고 Visitor Pattern에서 Visitor 역활의 클래스와 Element 역활의 클래스를 살펴보자.Element 클래스는 Accept 함수를 가지고 Client에게서 작업 객체(Visitor)를 전달받는다.여기에서 Accept 함수는 전달받은 객체를 다시 작업 수행을 요청한다.여기에서 Visitor 객체와 Element 객체의 자료형에 따라서 수행되는 작업이 결정이 된다.이것을 Double-Dispatch라 한다.일반적인 구조예제 소스(출처 : Java 언어로 배우는 디자인 패턴 입문. 영진닷컴)abstract class Visitor { public abstract void visit(File file); public abstract void visit(Directory directory);}interface Element { public abstract void accept(Visitor v);}abstract class Entry implements Element { public abstract String getName(); public abstract int getSize(); public Entry add(Entry entry) throws FileTreatmentException { throw new FileTreatmentException(); } public String toString() { return getName() + &quot; (&quot; + getSize() + &quot;)&quot;; } public Iterator&amp;amp;lt;Entry&amp;amp;gt; iterator() throws FileTreatmentException { throw new FileTreatmentException(); }}class File extends Entry { private String name; private int size; public File(String name, int size) { this.name = name; this.size = size; } public String getName() { return name; } public int getSize() { return size; } public void accept(Visitor v) { v.visit(this); }}class Directory extends Entry { private String name; private ArrayList&amp;amp;lt;Entry&amp;amp;gt; directory = new ArrayList&amp;amp;lt;Entry&amp;amp;gt;(); public Directory(String name) { this.name = name; } public String getName() { return name; } public int getSize() { int size = 0; Iterator&amp;amp;lt;Entry&amp;amp;gt; it = directory.iterator(); while (it.hasNext()) { Entry entry = it.next(); size += entry.getSize(); } return size; } public Entry add(Entry entry) { directory.add(entry); return this; } public Iterator&amp;amp;lt;Entry&amp;amp;gt; iterator() { return directory.iterator(); } public void accept(Visitor v) { v.visit(this); }}class ListVisitor extends Visitor { private String currentdir = &quot;&quot;; public void visit(File file) { System.out.println(currentdir + &quot;/&quot; + file); } public void visit(Directory directory) { System.out.println(currentdir + &quot;/&quot; + directory); String savedir = currentdir; currentdir = currentdir + &quot;/&quot; + directory.getName(); Iterator&amp;amp;lt;Entry&amp;amp;gt; it = directory.iterator(); while (it.hasNext()) { Entry entry = it.next(); entry.accept(this); } currentdir = savedir; }}class FileTreatmentException extends RuntimeException { public FileTreatmentException() { } public FileTreatmentException(String msg) { super(msg); }}" }, { "title": "Decorator Pattern", "url": "/posts/decorator-pattern/", "categories": "", "tags": "", "date": "2011-12-10 08:38:43 +0900", "snippet": "새로운 기능을 추가하귀 위해서는 SubClass를 많이 이용을 한다. SubClass는 Compile Time에 기능을 추가할 수 있다.그리고 추가된 기능은 Original Class의 모든 객체들에게 적용이 된다.사실 설계시에 추후에 어떤 기능과 기능들의 조합이 더 필요할지 알기는 힘들다.이 말은 추후에 새롭게 필요로 하는 기능과 그 기능들의 조합을 모두 구현해야 한다는 말이다.이것은 OOP(Object Oriented Programming)에서 DRY(Don’t repeat yourself)에 위반된다고 볼 수 있다.그렇다면, Decorator Pattern에 대해서 알아보자.Decorator Pattern은 어떤 객체에 Runtime에 기능을 추가할 후 있다. 그리고 여러개의 Decorator를 추가 할 수 있는데, 추가된 Decorator는 Stack에 쌓이듯이 Override 된 Decorator Method들이 호출이 된다.즉, 새롭게 필요로 하는 기능을 기존의 기능과 더하여 추가할 수 있다.기존 JDK의 API 중에서 Decorator Pattern으로 구성이 된 것은, I/O관련 Library에서 찾아 볼 수 있다. (InputStream, OutputStream, Reader, Writer 등)기본적인 구조예제 소스(출처 : Java 언어로 배우는 디자인 패턴 입문. 영진닷컴)abstract class Display { public abstract int getColumns(); public abstract int getRows(); public abstract String getRowText(int row); public final void show() { for(int i = 0; i &amp;amp;lt; getRows(); i++) { System.out.println(getRowText(i)); } }}class StringDisplay extends Display { private String string; public StringDisplay(String string) { this.string = string; } @Override public int getColumns() { return string.getBytes().length; } @Override public int getRows() { return 1; } @Override public String getRowText(int row) { if(row == 0) { return string; } else { return null; } }}abstract class Border extends Display { protected Display display; protected Border(Display display) { this.display = display; }}class SideBorder extends Border { private char borderChar; public SideBorder(Display display, char ch) { super(display); this.borderChar = ch; } @Override public int getColumns() { return 1 + display.getColumns() + 1; } @Override public int getRows() { return display.getRows(); } @Override public String getRowText(int row) { return borderChar + display.getRowText(row) + borderChar; }}class FullBorder extends Border { public FullBorder(Display display) { super(display); } @Override public int getColumns() { return 1 + display.getColumns() + 1; } @Override public int getRows() { return 1 + display.getRows() + 1; } @Override public String getRowText(int row) { if(row == 0) { return &quot;+&quot; + makeLine(&#39;-&#39;, display.getColumns()) + &quot;+&quot; ; } else if(row == display.getRows() + 1) { return &quot;+&quot; + makeLine(&#39;-&#39;, display.getColumns()) + &quot;+&quot; ; } else { return &quot;|&quot; + display.getRowText(row - 1) + &quot;|&quot;; } } private String makeLine(char ch, int count) { StringBuffer buf = new StringBuffer(); for(int i = 0; i &amp;amp;lt; count; i++) { buf.append(ch); } return buf.toString(); }}" }, { "title": "Composite Pattern", "url": "/posts/composite-pattern/", "categories": "", "tags": "", "date": "2011-12-10 08:37:59 +0900", "snippet": "Composite Pattern은 하나의 객체와 같이 동일한 방법으로 다양한 객체 그룹들을 다룰 수 있다.이러한 Composite Pattern의 목적은 객체들을 Tree 구조로 part-whole hierarchy를 표현하는 것이다.이러한 목적을 달성하기 위해서 그룻(composite)와 내용물(leaf)을 동일시해서 재귀적인 구조를 구성을 한다.사실 일반적인 Tree 구조를 다루다 보면, Programmer는 leaf node와 branch를 구분을 해야하만 하는 경우가 많다. 이것은 코드를 더욱 복잡하게 만들고, Error를 발생 시키기 쉽다.이러한 문제의 해결법은 그릇과 내용물을 동일한 방식으로 다룰 수 있는 interface이다. 그릇과 내용물이 interface를 구현하므로써, 모두 동일한 Operation을 가지고 있다.When to use 계층 구조(Part-Whole Hierarchy)를 사용해야 하는 경우 Composition Object와 각 Object의 차이를 무시해야 하는 경우 각 Object를 동일한 code로 컨트롤해야 하는 경우일반적인 구조abstract class Entry { public abstract String getName(); public abstract int getSize(); public Entry add(Entry entry) throws FileTreatmentException { throw new FileTreatmentException(); } public void printList() { printList(&quot;&quot;); } protected abstract void printList(String prefix); public String toString() { return getName() + &quot; (&quot; + getSize() + &quot;)&quot;; }}class File extends Entry { private String name; private int size; public File(String name, int size) { this.name = name; this.size = size; } public String getName() { return name; } public int getSize() { return size; } protected void printList(String prefix) { System.out.println(prefix + &quot;/&quot; + this); }}class Directory extends Entry { private String name; private ArrayList directory = new ArrayList(); public Directory(String name) { this.name = name; } public String getName() { return name; } public int getSize() { int size = 0; Iterator it = directory.iterator(); while(it.hasNext()) { Entry entry = it.next(); size += entry.getSize(); } return size; } public Entry add(Entry entry) { directory.add(entry); return this; } protected void printList(String prefix) { System.out.println(prefix + &quot;/&quot; + this); Iterator it = directory.iterator(); while(it.hasNext()) { Entry entry = it.next(); entry.printList(prefix + &quot;/&quot; + name); } }}class FileTreatmentException extends RuntimeException { public FileTreatmentException() { } public FileTreatmentException(String msg) { super(msg); }}" }, { "title": "Bridge Pattern", "url": "/posts/bridge-pattern/", "categories": "", "tags": "", "date": "2011-12-10 08:33:51 +0900", "snippet": "객체지향 설계는 기본적으로 인터페이스와 구현을 분리한 접근 방법이다. 이렇게 되면, 객체의 구현 방식이 바뀌더라도 그 객체를 사용하는 프로그램은 수정하지 않아도 되기 때문에 변경를 한정할 수 있다.그렇다면, Bridge Pattern을 언제 사용하면 좋을까? 새로운 ‘기능’을 추가하고 싶은 경우 새로운 ‘구현’을 추가하고 싶은 경우기능을 추가한다는 것은 검색에서 본다면, 웹 검색 기능과 컴퓨터 내부 검색 등과 같이 여러 기능을 들 수가 있다. 이러한 기능들은 자신이 추가할려고 하는 기능의 목적과 가까운 클래스를 찾아 그 클래스의 하위 클래스를 만들면 된다.구현을 추가한다는 것은 같은 검색을 한다고 하더라도 OS에 따라 검색 구현이 달라지게 된다. 즉, 실제적으로 작동하는 OS에 따라서 그 구현이 다른 것인데 이것을 따로 구현한다면, 수정과 추가 구현사항이 생긴다면 일은 배가 될 것이다. 그리고, OS가 바뀔 때 마다 프로그램은 수정이 되어야 한다.하지만, 인터페이스를 만들고 그 하위 클래스 들이 추상 메소드들을 실제로 구현한다면 위와 같은 상황을 방지할 수 있다. 결과적으로 하위 클래스의 역할 분담에 의해서 교환 가능성을 높일 수 있다.Bridge Pattern의 특징은 ‘기능 클래스 계층’과 ‘구현의 클래스 계층’을 분리하는 것이다.기능과 구현을 분리해 두면 각각의 계층을 독립적으로 확장할 수 있다. 즉, 기능을 추가하고 싶으면 기능 클래스 계층에 클래스를 추가하지만, 구현 클래스 계층은 전혀 수정할 필요가 없다.Bridge Pattern vs Adapter PatternBridge Pattern과 Adapter Pattern이 비슷해 보일 수도 있다.하지만, 두 Pattern은 서로 다른 목적을 가진다. Bridge Pattern은 위에서와 같이 기능과 구현을 나누고 결합시키는 패턴이지만, Adapter Pattern은 인터페이스가 다른 클래스를 결합시키는 패턴이다.일반적인 Bridge Pattern의 구조예제 소스(출처 : Java 언어로 배우는 디자인 패턴 입문. 영진닷컴)class Display { private DisplayImpl impl; public Display(DisplayImpl impl){ this.impl = impl; } public void open() { impl.rawOpen(); } public void print() { impl.rawPrint(); } public void close() { impl.rawClose(); } public final void display() { open(); print(); close(); }}class CountDisplay extends Display { public CountDisplay(DisplayImpl impl) { super(impl); } public void multiDisplay(int times) { open(); for(int i = 0; i &amp;amp;lt; times; i++) { print(); } close(); }}interface DisplayImpl { public void rawOpen(); public void rawPrint(); public void rawClose();}class StringDisplayImpl implements DisplayImpl { private String string; private int width; public StringDisplayImpl(String string) { this.string = string; this.width = string.getBytes().length; } public void rawOpen() { printLine(); } public void rawPrint() { System.out.println(&quot;|&quot; + string + &quot;|&quot;); } public void rawClose() { printLine(); } private void printLine() { System.out.print(&quot;+&quot;); for(int i = 0; i &amp;amp;lt; width; i++) { System.out.print(&quot;-&quot;); } System.out.println(&quot;+&quot;); }}" }, { "title": "Builder Pattern", "url": "/posts/builder-pattern/", "categories": "", "tags": "", "date": "2011-12-10 08:30:44 +0900", "snippet": "Builder Pattern은 객체 생성을 위한 Design Pattern이다.이 Pattern의 목적은 다른 구현을 통해서 다른 형태의 Object를 조립 과정을 추상화 시키는 것이다.종종 Design은 Factory Method(덜 복잡하고, 더욱 보편적이다.)에서 시작을 해서, Abstract Factory, Prototype, Builder와 같은 Pattern으로 변화시킬수 있다. 복잡한 객체를 생성하는 과정에 사용될 수 있다. 종종 Composite Pattern을 조립하는데 사용 Method Chaining을 이용하여 객체를 구성하는데 유용하다.Method Chaining을 이용한 객체 생성 예)em.createNamedQuery(&quot;Student.findByNameAgeGender&quot;) .setParameter(&quot;name&quot;, name) .setParameter(&quot;age&quot;, age) .setParameter(&quot;gender&quot;, gender) .setFirstResult(1) .setMaxResults(30) .setHint(&quot;hintName&quot;, &quot;hintValue&quot;) .getResultList();예제 코드(출처 : Java 언어로 배우는 디자인 패턴 입문. 영진닷컴)import java.io.FileWriter;import java.io.IOException;import java.io.PrintWriter;public class BuilderPattern { public static void main(String[] args) { TextBuilder textBuilder = new TextBuilder(); Director director = new Director(textBuilder); director.construct(); String result = textBuilder.getResult(); System.out.println(result); HTMLBuilder htmlBuilder = new HTMLBuilder(); director = new Director(htmlBuilder); director.construct(); String filename = htmlBuilder.getResult(); }}abstract class Builder { public abstract void makeTitle(String title); public abstract void makeString(String str); public abstract void makeItems(String[] items); public abstract void close();}class Director { private Builder builder; public Director(Builder builder) { this.builder = builder; } public void construct() { builder.makeTitle(&quot;Greeting&quot;); builder.makeString(&quot;아침과 낮에&quot;); builder.makeItems(new String[] { &quot;좋은 아침입니다.&quot;, &quot;안녕하세요.&quot;, }); builder.makeString(&quot;밤에&quot;); builder.makeItems(new String[] { &quot;안녕하세요.&quot;, &quot;안녕히 주무세요.&quot;, &quot;안녕히 계세요.&quot; }); builder.close(); }}class TextBuilder extends Builder { private StringBuffer buffer = new StringBuffer(); @Override public void makeTitle(String title) { buffer.append(&quot;======================n&quot;); buffer.append(&quot;(&quot; +title + &quot;)n&quot;); buffer.append(&quot;n&quot;); } @Override public void makeString(String str) { buffer.append(&#39;*&#39; +str + &quot;n&quot;); buffer.append(&quot;n&quot;); } @Override public void makeItems(String[] items) { for(int i = 0; i &amp;amp;lt; items.length; i++) { buffer.append(&quot; -&quot; + items[i] + &quot;n&quot;); } buffer.append(&quot;n&quot;); } @Override public void close() { buffer.append(&quot;=======================n&quot;); } public String getResult() { return buffer.toString(); }}class HTMLBuilder extends Builder { private String filename; private PrintWriter writer; @Override public void makeTitle(String title) { filename = title + &quot;.html&quot;; try { writer = new PrintWriter(new FileWriter(filename)); }catch(IOException e) { e.printStackTrace(); } writer.println(&quot;&amp;amp;lt;html&amp;amp;gt;&amp;amp;lt;head&amp;amp;gt;&amp;amp;lt;title&amp;amp;gt;&quot; + title + &quot;&amp;amp;lt;/title&amp;amp;gt;&amp;amp;lt;/head&amp;amp;gt;&amp;amp;lt;body&amp;amp;gt;&quot;); writer.println(&quot;&amp;amp;lt;h1&amp;amp;gt;&quot; + title + &quot;&amp;amp;lt;/h1&amp;amp;gt;&quot;); } @Override public void makeString(String str) { writer.println(&quot;&amp;amp;lt;p&amp;amp;gt;&quot; + str + &quot;&amp;amp;lt;/p&amp;amp;gt;&quot;); } @Override public void makeItems(String[] items) { writer.println(&quot;&amp;amp;lt;ul&amp;amp;gt;&quot;); for(int i = 0; i &amp;amp;lt; items.length; i++) { writer.println(&quot;&amp;amp;lt;li&amp;amp;gt;&quot; + items[i] + &quot;&amp;amp;lt;/li&amp;amp;gt;&quot;); } writer.println(&quot;&amp;amp;lt;/ul&amp;amp;gt;&quot;); } @Override public void close() { writer.println(&quot;&amp;amp;lt;/body&amp;amp;gt;&amp;amp;lt;/html&amp;amp;gt;&quot;); writer.close(); } public String getResult() { return filename; }}" }, { "title": "Prototype Pattern", "url": "/posts/prototype-pattern/", "categories": "", "tags": "", "date": "2011-12-10 08:30:24 +0900", "snippet": "이 패턴은 생성할 객체들의 타입이 Prototype인 객체로 부터 결정이 된다.그렇다면 언제 사용하면 좋을까? 종류가 너무 많아 클래스로 정리되지 않는 경우다루는 Object의 종류가 너무 많아 각가의 클래스로 만들어 다수의 소스 파일을 작성해야하는 경우 클래스로 부터 인스턴스 생성이 어려운 경우생성 과정이 복작한 작업이 많아 클래스로부터 인스턴스 생성이 어려운 경우 framework와 생성할 인스턴스를 분리하고 싶은 경우 객체 생성 비용이 클 경우객체는 일반적인 방법(예를 들어, new를 사용해서라든지)으로 객체를 생성하는 고유의 비용이 주어진 응용 프로그램 상황에 있어서 불가피하게 매우 클 때, 이 비용을 줄여준다.일반적 구조예제 코드(출처 : Java 언어로 배우는 디자인 패턴 입문. 영진닷컴)import java.util.HashMap;public class PrototypePattern { public static void main(String[] args){ Manager manager = new Manager(); UnderlinePen upen = new UnderlinePen(&#39;~&#39;); MessageBox mbox = new MessageBox(&#39;*&#39;); MessageBox sbox = new MessageBox(&#39;/&#39;); manager.register(&quot;strong message&quot;, upen); manager.register(&quot;warning box&quot;, mbox); manager.register(&quot;slash box&quot;, sbox); Product p1 = manager.create(&quot;strong message&quot;); p1.use(&quot;Hello, world&quot;); Product p2 = manager.create(&quot;warning box&quot;); p2.use(&quot;Hello, world&quot;); Product p3 = manager.create(&quot;slash box&quot;); p3.use(&quot;Hello, world&quot;); }}interface Product extends Cloneable { public abstract void use(String s); public abstract Product createClone();}class Manager { private HashMap&amp;amp;lt;String, Product&amp;amp;gt; showcase = new HashMap&amp;amp;lt;String, Product&amp;amp;gt;(); public void register(String name, Product proto) { showcase.put(name, proto); } public Product create(String protoname){ Product p = (Product)showcase.get(protoname); return p.createClone(); }}class MessageBox implements Product { private char decochar; public MessageBox(char decochar) { this.decochar = decochar; } public void use(String s){ int length = s.getBytes().length; for(int i = 0; i &amp;amp;lt;length + 4; i++) { System.out.print(decochar); } System.out.println(&quot; &quot;); System.out.println(decochar + &quot; &quot; + s + &quot; &quot; + decochar); for(int i = 0; i &amp;amp;lt; length + 4; i++) { System.out.print(decochar); } System.out.println(&quot; &quot;); } @Override public Product createClone() { Product p = null; try { p = (Product)clone(); }catch(CloneNotSupportedException e){ e.printStackTrace(); } return p; }}class UnderlinePen implements Product { private char ulchar; public UnderlinePen(char ulchar) { this.ulchar = ulchar; } public void use(String s) { int length = s.getBytes().length; System.out.println(&quot;&quot;&quot; + s + &quot;&quot;&quot;); System.out.print(&quot; &quot;); for(int i = 0; i &amp;amp;lt; length; i++) { System.out.print(ulchar); } System.out.println(&quot;&quot;); } @Override public Product createClone() { Product p = null; try { p = (Product)clone(); }catch(CloneNotSupportedException e) { e.printStackTrace(); } return p; }}" }, { "title": "Factory Method Pattern", "url": "/posts/factory-method-pattern/", "categories": "", "tags": "", "date": "2011-12-10 08:10:34 +0900", "snippet": "Factory Method Pattern은Factory 개념을 구현한 Object-oriented design pattern이다.다른 생성 패턴과 같이, 이것도 생성될 정확한 객체의 class를 명시하지 않으며, 이러한 객체의 생성 문제를 다룬다.그렇다면, 기존의 객체 생성의 문제점은 무엇일까? 객체의 생성은 종종 많은 code의 중복을 야기한다. 객체를 구성하기 위해서 접근할 수 없는 정보를 요구하기도 한다. 충분한 추상 Level을 제공하지 못 하기도 한다. 생성하는 부분이 객체 생성과 무관한 부분이기도 하다.그리고 객체 생성에서 어떤 객체의 생성과 객체의 Lifetime의 관리, build-up 관리, 객체의 tear-down 문제를 요구하기도 한다.이러한 요구사항과 문제점들의 해결을 위해서, Factory Method pattern이 사용될 수 있으며, 이름에서 보듯이 객체의 생성을 위한 목적임을 외부에서 보더라도 한 눈에 확인 할 수 있는 장점이 생긴다.기본 class diagram예제 소스(출처 : Java 언어로 배우는 디자인 패턴 입문. 영진닷컴)import java.util.ArrayList;import java.util.List;public class FactoryMethodPattern { public static void main(String[] args) { Factory factory = new IDCardFactory(); Product card1 = factory.create(&quot;길동&quot;); Product card2 = factory.create(&quot;철수&quot;); Product card3 = factory.create(&quot;영희&quot;); card1.use(); card2.use(); card3.use(); }}abstract class Product { public abstract void use();}abstract class Factory { public final Product create(String owner) { Product p = createProduct(owner); registerProduct(p); return p; } protected abstract Product createProduct(String owner); protected abstract void registerProduct(Product product);}class IDCard extends Product { private String owner; IDCard(String owner) { System.out.println(owner + &quot;의 카드를 만듭니다.&quot;); this.owner = owner; } public void use() { System.out.println(owner + &quot;의 카드를 사용합니다.&quot;); } public String getOwner() { return owner; }}class IDCardFactory extends Factory { private List&amp;amp;lt;String&amp;amp;gt; owners = new ArrayList&amp;amp;lt;String&amp;amp;gt;(); protected Product createProduct(String owner) { return new IDCard(owner); } protected void registerProduct(Product product) { owners.add(((IDCard)product).getOwner()); } public List getOwners() { return owners; }}" }, { "title": "Template Method Pattern", "url": "/posts/template-method-pattern/", "categories": "", "tags": "", "date": "2011-12-10 08:08:36 +0900", "snippet": "Template Method는 algorithm에서 program skeleton을 정의합니다. 하나 이상의 algorithm 과정들을 subclass에서 그 행동을 재정의합니다. 반면 재정의된 algorithm의 단계를 구성하는 최상위 알고리즘은 그대로 따르게 됩니다.우선 algorithm의 뼈대를 제공하는 첫 class를 생성합니다.이 과정에서는 abstract method를 사용해서 algorithm 뼈대를 구현합니다. 이후에 subclass에서 abstract method의 실제 행동을 정의함으로써 그 내용을 변경할 수 있습니다.즉, 일반적인 algorithm은 한 장소에서 보존하지만, 구체적인 과정은 subclass에서 변경이 될 수 있습니다.이와 같이 상위 클래스에서 처리의 뼈대를 결정하고, 하위 클래스에서 그 구체적인 내용을 결정하는 디자인 패턴을 Template Method Pattern이라고 한다.기본적인 Class Diagram예제 소스(출처 : Java 언어로 배우는 디자인 패턴 입문. 영진닷컴)public class TemplateMethodPattern { public static void main(String[] args) { AbstractDisplay d1 = new CharDisplay(&#39;H&#39;); AbstractDisplay d2 = new StringDisplay(&quot;Hello, Template&quot;); d1.display(); d2.display(); }}abstract class AbstractDisplay { public abstract void open(); public abstract void print(); public abstract void close(); public final void display() { open(); for(int i = 0; i &amp;amp;lt; 5; i++) { print(); } close(); }}class CharDisplay extends AbstractDisplay { private char ch; public CharDisplay(char ch) { this.ch = ch; } public void open() { System.out.print(&quot;&amp;amp;lt;&amp;amp;lt;&quot;); } public void print() { System.out.print(ch); } public void close() { System.out.println(&quot;&amp;amp;gt;&amp;amp;gt;&quot;); }}class StringDisplay extends AbstractDisplay { private String string; private int width; public StringDisplay(String string) { this.string = string; this.width = string.getBytes().length; } public void open() { printLine(); } public void print() { System.out.println(&quot;|&quot; + string + &quot;|&quot;); } public void close() { printLine(); } public void printLine() { System.out.print(&quot;+&quot;); for(int i = 0; i &amp;amp;lt; width; i++) { System.out.print(&quot;-&quot;); } System.out.println(&quot;+&quot;); }}" }, { "title": "Adapter Pattern", "url": "/posts/adapter-pattern/", "categories": "", "tags": "", "date": "2011-12-10 08:07:15 +0900", "snippet": "Adapter Pattern은 “이미 제공되고 있는것”과 “제공할것” 사이의 차이를 없애주는 Pattern이다.기존의 Interface를 사용하는 interface를 client에 제공하는 방법을 통해서, Adapter Pattern은 일반적으로 interface 호환성 때문에 함께 사용할 수 없는 class들을 함께 작동하게 한다.adapter는 새 interface의 호출을 기존의 interface 호출로 해석해준다. 그리고 Data를 자신이 원하는 적절한 형태로 변경도 할 수 있다.Adapter Pattern은 구현을 크게 두가지 방법으로 나눌 수 있다. 상속을 통한 구현 위임을 통한 구현-상속을 통한 구현예제 소스(출처 : Java 언어로 배우는 디자인 패턴 입문. 영진닷컴)public class AdapterPattern { public static void main(String[] args) { Print p = new PrintBanner(&quot;Hello&quot;); p.printStrong(); p.printWeak(); }}adapteeclass Banner { private String string; public Banner(String string) { this.string = string; } public void showWithParen() { System.out.println(&quot;(&quot; + string + &quot;)&quot;); } public void showWithAster() { System.out.println(&quot;*&quot; + string + &quot;*&quot;); }}targetinterface Print { public void printWeak(); public void printStrong();}adapterclass PrintBanner implements Print { private Banner banner; public PrintBanner(String string) { banner = new Banner(string); } public void printWeak() { banner.showWithParen(); } public void printStrong() { banner.showWithAster(); }}" } ]
